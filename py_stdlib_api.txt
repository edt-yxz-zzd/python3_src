e ../../python3_src/py_stdlib_api.txt
view ../../python3_src/自己的相关数据/py_modules.txt
    exception-hierarchy
        BaseException
        /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/exceptions.html
help(math)
    交互对话式，太长就难以复制
    py -c 'import math;help(math)' | cat
      #输出到文件
    ---
    py -m nn_ns.app.py_help  nn_ns.app.py_help@py_help_
    py_help  xxx.yyy@CCC.MMM.fff

semantics:发现未知用法
  location.endswith(tuple(suffixes))
syntax:发现未知语法
  raise e from e
  raise e from None
syntax:发现未知语法
  >>> (a:=1)
  1
  >>> if a:=0:pass
  ...
  >>> a
  0


print(value, ..., sep=' ', end='\n', file=sys.stdout, flush=False)
super(__class__, ...obj/cls)
  sf = super(__class__, cls).__new__(cls, *args, **kwargs)
    #as-if staticmethod
  super(__class__, cls).__init_subclass__(*args, **kwargs)
    #as-if classmethod

Table of Contents
[[template:goto
generator_iterator:goto

itertools:islice,chain
functools:reduce
collections:deque

str__bytes__float__int
bisect
doctest
unittest
importlib
  [importlib___contents]#here
  [importlib__xxx]#goto
    [def____is_pkg___is_ns_pkg]#goto
    [def____module__attributes]#goto
  [importlib__abc]#goto
    [自定义模块导入囗囗概要]#goto
    [def____spec__ModuleSpec]#goto
      [importlib____mk____spec]#goto
    [importlib_____usage]#goto

  [importlib__util]#goto
      [importlib____PathFinder____find_spec]#goto
      [importlib____FileFinder____path_hook]#goto

  [importlib__machinery]#goto
  [importlib__resources]#goto
    虚拟路径、基本文件名
    枚举子文件子文件夹、过滤掉子文件夹、临时文件
    .read_text
    .open_binary
operator
argparse
decimal
heapq
super
colorsys
pickle
enum
dict__update
collections_abc
reference__datamodel
  3_3_8__Emulating_numeric_types:goto
    __xxx__:goto
    __rxxx__:goto
    __ixxx__:goto
  3_4__Coroutines
    abc__Generator_Types
    8_8_1__Coroutine_function_definition
  3_3_8__Emulating_numeric_types
  3_3_7__Emulating_container_types

  3_3_5__Emulating_generic_types
    __class_getitem__
  3_3_6__Emulating_callable_objects
  3_3_9__With_Statement_Context_Managers
  3_3_10__Special_method_lookup
    __getattribute__

io:IOBase:goto
  io__newline__newlines:goto
fractions:Fraction:分数加减乘除囗可以更快点:goto
math:cmp_api_of__math__cmath:goto
cmath
help()
re
  re____exports:goto
  re_doc___spec_char____spec_seq____api_short____flag:goto
    [re_doc___spec_char]:goto
    [re_doc____spec_seq]:goto
    [re_doc____api_short]:goto
    [re_doc____flag]:goto
  re____api_long:goto
    re____split:goto

inspect
warnings__logging
contextlib.contextmanager
pathlib
bz2__gzip__lzma__zlib__header4compress
sqlite3
]]
[[
view ../../../unzip/py_doc/python-3.8.1-docs-html/library/index.html


Python »
en 3.8.1 Documentation »
|
The Python Standard Library¶
While The Python Language Reference describes the exact syntax and semantics of the Python language, this library reference manual describes the standard library that is distributed with Python. It also describes some of the optional components that are commonly included in Python distributions.

Python’s standard library is very extensive, offering a wide range of facilities as indicated by the long table of contents listed below. The library contains built-in modules (written in C) that provide access to system functionality such as file I/O that would otherwise be inaccessible to Python programmers, as well as modules written in Python that provide standardized solutions for many problems that occur in everyday programming. Some of these modules are explicitly designed to encourage and enhance the portability of Python programs by abstracting away platform-specifics into platform-neutral APIs.

The Python installers for the Windows platform usually include the entire standard library and often also include many additional components. For Unix-like operating systems Python is normally provided as a collection of packages, so it may be necessary to use the packaging tools provided with the operating system to obtain some or all of the optional components.

In addition to the standard library, there is a growing collection of several thousand components (from individual programs and modules to packages and entire application development frameworks), available from the Python Package Index.

  +Introduction
    Notes on availability
  +Built-in Functions
  +Built-in Constants
    Constants added by the site module
  +Built-in Types
    Truth Value Testing
    Boolean Operations — and, or, not
    Comparisons
    Numeric Types — int, float, complex
    Iterator Types
    Sequence Types — list, tuple, range
    Text Sequence Type — str
    Binary Sequence Types — bytes, bytearray, memoryview
    Set Types — set, frozenset
    Mapping Types — dict
    Context Manager Types
    Other Built-in Types
    Special Attributes
  +Built-in Exceptions
    Base classes
    Concrete exceptions
    Warnings
    Exception hierarchy
  +Text Processing Services
    string — Common string operations
    re — Regular expression operations
    difflib — Helpers for computing deltas
    textwrap — Text wrapping and filling
    unicodedata — Unicode Database
    stringprep — Internet String Preparation
    readline — GNU readline interface
    rlcompleter — Completion function for GNU readline
  +Binary Data Services
    struct — Interpret bytes as packed binary data
    codecs — Codec registry and base classes
  +Data Types
    datetime — Basic date and time types
    calendar — General calendar-related functions
    collections — Container datatypes
    collections.abc — Abstract Base Classes for Containers
    heapq — Heap queue algorithm
    bisect — Array bisection algorithm
    array — Efficient arrays of numeric values
    weakref — Weak references
    types — Dynamic type creation and names for built-in types
    copy — Shallow and deep copy operations
    pprint — Data pretty printer
    reprlib — Alternate repr() implementation
    enum — Support for enumerations
  +Numeric and Mathematical Modules
    numbers — Numeric abstract base classes
    math — Mathematical functions
    cmath — Mathematical functions for complex numbers
    decimal — Decimal fixed point and floating point arithmetic
    fractions — Rational numbers
    random — Generate pseudo-random numbers
    statistics — Mathematical statistics functions
  +Functional Programming Modules
    itertools — Functions creating iterators for efficient looping
    functools — Higher-order functions and operations on callable objects
    operator — Standard operators as functions
  +File and Directory Access
    pathlib — Object-oriented filesystem paths
    os.path — Common pathname manipulations
    fileinput — Iterate over lines from multiple input streams
    stat — Interpreting stat() results
    filecmp — File and Directory Comparisons
    tempfile — Generate temporary files and directories
    glob — Unix style pathname pattern expansion
    fnmatch — Unix filename pattern matching
    linecache — Random access to text lines
    shutil — High-level file operations
  +Data Persistence
    pickle — Python object serialization
    copyreg — Register pickle support functions
    shelve — Python object persistence
    marshal — Internal Python object serialization
    dbm — Interfaces to Unix “databases”
    sqlite3 — DB-API 2.0 interface for SQLite databases
  +Data Compression and Archiving
    zlib — Compression compatible with gzip
    gzip — Support for gzip files
    bz2 — Support for bzip2 compression
    lzma — Compression using the LZMA algorithm
    zipfile — Work with ZIP archives
    tarfile — Read and write tar archive files
  +File Formats
    csv — CSV File Reading and Writing
    configparser — Configuration file parser
    netrc — netrc file processing
    xdrlib — Encode and decode XDR data
    plistlib — Generate and parse Mac OS X .plist files
  +Cryptographic Services
    hashlib — Secure hashes and message digests
    hmac — Keyed-Hashing for Message Authentication
    secrets — Generate secure random numbers for managing secrets
  +Generic Operating System Services
    os — Miscellaneous operating system interfaces
    io — Core tools for working with streams
    time — Time access and conversions
    argparse — Parser for command-line options, arguments and sub-commands
    getopt — C-style parser for command line options
    logging — Logging facility for Python
    logging.config — Logging configuration
    logging.handlers — Logging handlers
    getpass — Portable password input
    curses — Terminal handling for character-cell displays
    curses.textpad — Text input widget for curses programs
    curses.ascii — Utilities for ASCII characters
    curses.panel — A panel stack extension for curses
    platform — Access to underlying platform’s identifying data
    errno — Standard errno system symbols
    ctypes — A foreign function library for Python
  +Concurrent Execution
    threading — Thread-based parallelism
    multiprocessing — Process-based parallelism
    multiprocessing.shared_memory — Provides shared memory for direct access across processes
    The concurrent package
    concurrent.futures — Launching parallel tasks
    subprocess — Subprocess management
    sched — Event scheduler
    queue — A synchronized queue class
    _thread — Low-level threading API
    _dummy_thread — Drop-in replacement for the _thread module
    dummy_threading — Drop-in replacement for the threading module
  +contextvars — Context Variables
    Context Variables
    Manual Context Management
    asyncio support
  +Networking and Interprocess Communication
    asyncio — Asynchronous I/O
    socket — Low-level networking interface
    ssl — TLS/SSL wrapper for socket objects
    select — Waiting for I/O completion
    selectors — High-level I/O multiplexing
    asyncore — Asynchronous socket handler
    asynchat — Asynchronous socket command/response handler
    signal — Set handlers for asynchronous events
    mmap — Memory-mapped file support
  +Internet Data Handling
    email — An email and MIME handling package
    json — JSON encoder and decoder
    mailcap — Mailcap file handling
    mailbox — Manipulate mailboxes in various formats
    mimetypes — Map filenames to MIME types
    base64 — Base16, Base32, Base64, Base85 Data Encodings
    binhex — Encode and decode binhex4 files
    binascii — Convert between binary and ASCII
    quopri — Encode and decode MIME quoted-printable data
    uu — Encode and decode uuencode files
  +Structured Markup Processing Tools
    html — HyperText Markup Language support
    html.parser — Simple HTML and XHTML parser
    html.entities — Definitions of HTML general entities
    XML Processing Modules
    xml.etree.ElementTree — The ElementTree XML API
    xml.dom — The Document Object Model API
    xml.dom.minidom — Minimal DOM implementation
    xml.dom.pulldom — Support for building partial DOM trees
    xml.sax — Support for SAX2 parsers
    xml.sax.handler — Base classes for SAX handlers
    xml.sax.saxutils — SAX Utilities
    xml.sax.xmlreader — Interface for XML parsers
    xml.parsers.expat — Fast XML parsing using Expat
  +Internet Protocols and Support
    webbrowser — Convenient Web-browser controller
    cgi — Common Gateway Interface support
    cgitb — Traceback manager for CGI scripts
    wsgiref — WSGI Utilities and Reference Implementation
    urllib — URL handling modules
    urllib.request — Extensible library for opening URLs
    urllib.response — Response classes used by urllib
    urllib.parse — Parse URLs into components
    urllib.error — Exception classes raised by urllib.request
    urllib.robotparser — Parser for robots.txt
    http — HTTP modules
    http.client — HTTP protocol client
    ftplib — FTP protocol client
    poplib — POP3 protocol client
    imaplib — IMAP4 protocol client
    nntplib — NNTP protocol client
    smtplib — SMTP protocol client
    smtpd — SMTP Server
    telnetlib — Telnet client
    uuid — UUID objects according to RFC 4122
    socketserver — A framework for network servers
    http.server — HTTP servers
    http.cookies — HTTP state management
    http.cookiejar — Cookie handling for HTTP clients
    xmlrpc — XMLRPC server and client modules
    xmlrpc.client — XML-RPC client access
    xmlrpc.server — Basic XML-RPC servers
    ipaddress — IPv4/IPv6 manipulation library
  +Multimedia Services
    audioop — Manipulate raw audio data
    aifc — Read and write AIFF and AIFC files
    sunau — Read and write Sun AU files
    wave — Read and write WAV files
    chunk — Read IFF chunked data
    colorsys — Conversions between color systems
    imghdr — Determine the type of an image
    sndhdr — Determine type of sound file
    ossaudiodev — Access to OSS-compatible audio devices
  +Internationalization
    gettext — Multilingual internationalization services
    locale — Internationalization services
  +Program Frameworks
    turtle — Turtle graphics
    cmd — Support for line-oriented command interpreters
    shlex — Simple lexical analysis
  +Graphical User Interfaces with Tk
    tkinter — Python interface to Tcl/Tk
    tkinter.ttk — Tk themed widgets
    tkinter.tix — Extension widgets for Tk
    tkinter.scrolledtext — Scrolled Text Widget
    IDLE
    Other Graphical User Interface Packages
  +Development Tools
    typing — Support for type hints
    pydoc — Documentation generator and online help system
    doctest — Test interactive Python examples
    unittest — Unit testing framework
    unittest.mock — mock object library
    unittest.mock — getting started
    2to3 - Automated Python 2 to 3 code translation
    test — Regression tests package for Python
    test.support — Utilities for the Python test suite
    test.support.script_helper — Utilities for the Python execution tests
  +Debugging and Profiling
    Audit events table
    bdb — Debugger framework
    faulthandler — Dump the Python traceback
    pdb — The Python Debugger
    The Python Profilers
    timeit — Measure execution time of small code snippets
    trace — Trace or track Python statement execution
    tracemalloc — Trace memory allocations
  +Software Packaging and Distribution
    distutils — Building and installing Python modules
    ensurepip — Bootstrapping the pip installer
    venv — Creation of virtual environments
    zipapp — Manage executable Python zip archives
  +Python Runtime Services
    sys — System-specific parameters and functions
    sysconfig — Provide access to Python’s configuration information
    builtins — Built-in objects
    __main__ — Top-level script environment
    warnings — Warning control
    dataclasses — Data Classes
    contextlib — Utilities for with-statement contexts
    abc — Abstract Base Classes
    atexit — Exit handlers
    traceback — Print or retrieve a stack traceback
    __future__ — Future statement definitions
    gc — Garbage Collector interface
    inspect — Inspect live objects
    site — Site-specific configuration hook
  +Custom Python Interpreters
    code — Interpreter base classes
    codeop — Compile Python code
  +Importing Modules
    zipimport — Import modules from Zip archives
    pkgutil — Package extension utility
    modulefinder — Find modules used by a script
    runpy — Locating and executing Python modules
    importlib — The implementation of import
    Using importlib.metadata
  +Python Language Services
    parser — Access Python parse trees
    ast — Abstract Syntax Trees
    symtable — Access to the compiler’s symbol tables
    symbol — Constants used with Python parse trees
    token — Constants used with Python parse trees
    keyword — Testing for Python keywords
    tokenize — Tokenizer for Python source
    tabnanny — Detection of ambiguous indentation
    pyclbr — Python class browser support
    py_compile — Compile Python source files
    compileall — Byte-compile Python libraries
    dis — Disassembler for Python bytecode
    pickletools — Tools for pickle developers
  +Miscellaneous Services
    formatter — Generic output formatting
  +MS Windows Specific Services
    msilib — Read and write Microsoft Installer files
    msvcrt — Useful routines from the MS VC++ runtime
    winreg — Windows registry access
    winsound — Sound-playing interface for Windows
  +Unix Specific Services
    posix — The most common POSIX system calls
    pwd — The password database
    spwd — The shadow password database
    grp — The group database
    crypt — Function to check Unix passwords
    termios — POSIX style tty control
    tty — Terminal control functions
    pty — Pseudo-terminal utilities
    fcntl — The fcntl and ioctl system calls
    pipes — Interface to shell pipelines
    resource — Resource usage information
    nis — Interface to Sun’s NIS (Yellow Pages)
    syslog — Unix syslog library routines
  +Superseded Modules
    optparse — Parser for command line options
    imp — Access the import internals
  +Undocumented Modules
    Platform specific modules



Python »
en 3.8.1 Documentation »
|
© Copyright 2001-2020, Python Software Foundation.
The Python Software Foundation is a non-profit corporation. Please donate.

Last updated on Jan 14, 2020. Found a bug?
Created using Sphinx 2.3.1.
]]
[[py 3_10_5
py_adhoc_call builtins  ,str.sorted  %sys:stdlib_module_names =stdlib_module_names
__future__
_abc
_aix_support
_ast
_asyncio
_bisect
_blake2
_bootsubprocess
_bz2
_codecs
_codecs_cn
_codecs_hk
_codecs_iso2022
_codecs_jp
_codecs_kr
_codecs_tw
_collections
_collections_abc
_compat_pickle
_compression
_contextvars
_crypt
_csv
_ctypes
_curses
_curses_panel
_datetime
_dbm
_decimal
_elementtree
_frozen_importlib
_frozen_importlib_external
_functools
_gdbm
_hashlib
_heapq
_imp
_io
_json
_locale
_lsprof
_lzma
_markupbase
_md5
_msi
_multibytecodec
_multiprocessing
_opcode
_operator
_osx_support
_overlapped
_pickle
_posixshmem
_posixsubprocess
_py_abc
_pydecimal
_pyio
_queue
_random
_scproxy
_sha1
_sha256
_sha3
_sha512
_signal
_sitebuiltins
_socket
_sqlite3
_sre
_ssl
_stat
_statistics
_string
_strptime
_struct
_symtable
_thread
_threading_local
_tkinter
_tracemalloc
_uuid
_warnings
_weakref
_weakrefset
_winapi
_zoneinfo
abc
aifc
antigravity
argparse
array
ast
asynchat
asyncio
asyncore
atexit
audioop
base64
bdb
binascii
binhex
bisect
builtins
bz2
cProfile
calendar
cgi
cgitb
chunk
cmath
cmd
code
codecs
codeop
collections
colorsys
compileall
concurrent
configparser
contextlib
contextvars
copy
copyreg
crypt
csv
ctypes
curses
dataclasses
datetime
dbm
decimal
difflib
dis
distutils
doctest
email
encodings
ensurepip
enum
errno
faulthandler
fcntl
filecmp
fileinput
fnmatch
fractions
ftplib
functools
gc
genericpath
getopt
getpass
gettext
glob
graphlib
grp
gzip
hashlib
heapq
hmac
html
http
idlelib
imaplib
imghdr
imp
importlib
inspect
io
ipaddress
itertools
json
keyword
lib2to3
linecache
locale
logging
lzma
mailbox
mailcap
marshal
math
mimetypes
mmap
modulefinder
msilib
msvcrt
multiprocessing
netrc
nis
nntplib
nt
ntpath
nturl2path
numbers
opcode
operator
optparse
os
ossaudiodev
pathlib
pdb
pickle
pickletools
pipes
pkgutil
platform
plistlib
poplib
posix
posixpath
pprint
profile
pstats
pty
pwd
py_compile
pyclbr
pydoc
pydoc_data
pyexpat
queue
quopri
random
re
readline
reprlib
resource
rlcompleter
runpy
sched
secrets
select
selectors
shelve
shlex
shutil
signal
site
smtpd
smtplib
sndhdr
socket
socketserver
spwd
sqlite3
sre_compile
sre_constants
sre_parse
ssl
stat
statistics
string
stringprep
struct
subprocess
sunau
symtable
sys
sysconfig
syslog
tabnanny
tarfile
telnetlib
tempfile
termios
textwrap
this
threading
time
timeit
tkinter
token
tokenize
trace
traceback
tracemalloc
tty
turtle
turtledemo
types
typing
unicodedata
unittest
urllib
uu
uuid
venv
warnings
wave
weakref
webbrowser
winreg
winsound
wsgiref
xdrlib
xml
xmlrpc
zipapp
zipfile
zipimport
zlib
zoneinfo
]]


[[[template:xxx
xxx
===
view ~/../usr/lib/python3.10/xxx.py
cp ~/../usr/lib/python3.10/xxx.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/xxx.py

view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/xxx.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/xxx.html > $my_tmp/out4py/html2text/py_38_doc/xxx.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/xxx.html.txt


import xxx
xxx.__all__
help(xxx)

py_help xxx > ~/my_tmp/out4py/py_help.xxx.out.txt
view /sdcard/0my_files/tmp/out4py/py_help.xxx.out.txt

]]]
sqlite3
[[[template:sqlite3
sqlite3
===
view ~/../usr/lib/python3.10/sqlite3.py
cp -r ~/../usr/lib/python3.10/sqlite3/ /sdcard/0my_files/tmp/out4py/py_src/sqlite3
[[
view /sdcard/0my_files/tmp/out4py/py_src/sqlite3/__init__.py
===
import sqlite3
cx = sqlite3.connect("test.db")
    # test.db will be created or opened
cx = sqlite3.connect(":memory:")
    # connect to a database in RAM
cu = cx.cursor()

cu.execute("create table lang(name, first_appeared)")
cu.execute("insert into lang values (?, ?)", ("C", 1972))
for row in cu.execute("select * from lang"):
    print(row)
cx.close()

]]
[[
view /sdcard/0my_files/tmp/out4py/py_src/sqlite3/dump.py
===
not cmd
but impl of cx.iterdump()
===

    # sqlite_master table contains the SQL CREATE statements for the database.
    q = """
        SELECT "name", "type", "sql"
        FROM "sqlite_master"
            WHERE "sql" NOT NULL AND
            "type" == 'table'
            ORDER BY "name"
        """

    # Now when the type is 'index', 'trigger', or 'view'
    q = """
        SELECT "name", "type", "sql"
        FROM "sqlite_master"
            WHERE "sql" NOT NULL AND
            "type" IN ('index', 'trigger', 'view')
        """
    schema_res = cu.execute(q)
    for name, type, sql in schema_res.fetchall():
        yield('{0};'.format(sql))
]]



#view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/sqlite3.html
#html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/sqlite3.html > $my_tmp/out4py/html2text/py_38_doc/sqlite3.html.txt
#view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/sqlite3.html.txt
[[
#view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/sqlite3.html
===
To use the module, you must first create a Connection object that represents the database. Here the data will be stored in the example.db file:
import sqlite3
conn = sqlite3.connect('example.db')

You can also supply the special name :memory: to create a database in RAM.

Once you have a Connection, you can create a Cursor object and call its execute() method to perform SQL commands:
c = conn.cursor()

# Create table
c.execute('''CREATE TABLE stocks
             (date text, trans text, symbol text, qty real, price real)''')

# Insert a row of data
c.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)")

# Save (commit) the changes
conn.commit()

# We can also close the connection if we are done with it.
# Just be sure any changes have been committed or they will be lost.
conn.close()

The data you’ve saved is persistent and is available in subsequent sessions:

import sqlite3
conn = sqlite3.connect('example.db')
c = conn.cursor()

Usually your SQL operations will need to use values from Python variables. You shouldn’t assemble your query using Python’s string operations because doing so is insecure; it makes your program vulnerable to an SQL injection attack (see https://xkcd.com/327/ for humorous example of what can go wrong).

Instead, use the DB-API’s parameter substitution. Put ? as a placeholder wherever you want to use a value, and then provide a tuple of values as the second argument to the cursor’s execute() method. (Other database modules may use a different placeholder, such as %s or :1.) For example:

# Never do this -- insecure!
symbol = 'RHAT'
c.execute("SELECT * FROM stocks WHERE symbol = '%s'" % symbol)

# Do this instead
t = ('RHAT',)
c.execute('SELECT * FROM stocks WHERE symbol=?', t)
print(c.fetchone())

# Larger example that inserts many records at a time
purchases = [('2006-03-28', 'BUY', 'IBM', 1000, 45.00),
             ('2006-04-05', 'BUY', 'MSFT', 1000, 72.00),
             ('2006-04-06', 'SELL', 'IBM', 500, 53.00),
            ]
c.executemany('INSERT INTO stocks VALUES (?,?,?,?,?)', purchases)

To retrieve data after executing a SELECT statement, you can either treat the cursor as an iterator, call the cursor’s fetchone() method to retrieve a single matching row, or call fetchall() to get a list of the matching rows.

This example uses the iterator form:

>>> for row in c.execute('SELECT * FROM stocks ORDER BY price'): print(row)
('2006-01-05', 'BUY', 'RHAT', 100, 35.14)
('2006-03-28', 'BUY', 'IBM', 1000, 45.0)
('2006-04-06', 'SELL', 'IBM', 500, 53.0)
('2006-04-05', 'BUY', 'MSFT', 1000, 72.0)

]]

import sqlite3
sqlite3.__all__
help(sqlite3)

#py_help sqlite3 > ~/my_tmp/out4py/py_help.sqlite3.out.txt
#view /sdcard/0my_files/tmp/out4py/py_help.sqlite3.out.txt


[[
nn_ns.fileformat.sqlite3_dump_cmd
view ../../python3_src/nn_ns/fileformat/sqlite3_dump_cmd.py
===
#builtin table
py_adhoc_call   nn_ns.fileformat.sqlite3_dump_cmd   @sqlite3_dump_cmd --ipath:/sdcard/hugh.android/GHY.DAT --nm4table:sqlite_master
('table', 'android_metadata', 'android_metadata', 2, 'CREATE TABLE android_metadata(locale text)')
('table', 'ghy_yunghugh', 'ghy_yunghugh', 3, 'CREATE TABLE ghy_yunghugh (\r\n_id INTEGER primary key,\r\nzi text,\r\nyinjie text,\r\nbs text,\r\nbsbh text,\r\nzbh text,\r\nbsh text,\r\nshiyi text)')


#userdef table
py_adhoc_call   nn_ns.fileformat.sqlite3_dump_cmd   @sqlite3_dump_cmd --ipath:/sdcard/hugh.android/GHY.DAT --nm4table:ghy_yunghugh =600 =602
(1881, '诗', 'shi', '讠', '2', '8', '45121124', 'shī\r\n①< 名>一种文学体裁；诗歌。《孔雀东南飞》：“时人伤之，为～云尔 。”\r\n②<名>指《诗经》。《齐桓晋文之事》：“～云：‘他人有心 ，予忖度之。’”\r\n\r\n【诗馀】词的别称。')
(1882, '试', 'shi', '讠', '2', '8', '45112154', 'shì\r\n①< 动>用；任用。《礼记·乐记》：“兵革不～，五刑不用。”\r\n②<动>尝试；试探。《世态炎凉》：“守邸曰：‘～来视之。’”\r\n③<动>试验；检验。《促织》：“又～之鸡，果如成言。”\r\n④<动>考试。《左忠毅公逸事》：“及～，吏呼名史公，公瞿然注视。”\r\n\r\n【 试守】犹言试用。在正在任用之前试用。')


]]



]]]
[[[[[[[[[[
bz2__gzip__lzma__zlib__header4compress
is_zipfile_____is_tarfile
zipfile_header
sqlite3__header
===
===
sqlite3__header
#see:nn_ns.bin.find_zlib_objs_in_file
header4sqlite3 = b'SQLite format 3\0'
===
zipfile_header
from py-src:zipfile.py:
  stringFileHeader = b"PK\003\004"
is_zipfile_____is_tarfile
  from tarfile import is_tarfile
  from zipfile import is_zipfile

??gz_file_header:
  b'\x1f\x8b\x08\x00\x02\x191d\x02\xff'
    #from tarfile.open(mode='w:gz', fileobj=ofile)
  vs:xxx header<gzip> = b'\x1f\x8b\x08\x00'
  vs: header4gzip = b'\x1F\x8B' # <<== src code:gzip.py

cp ~/../usr/lib/python3.10/zipfile.py /sdcard/0my_files/tmp/out4py/py_src/
cp ~/../usr/lib/python3.10/tarfile.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/zipfile.py
view /sdcard/0my_files/tmp/out4py/py_src/tarfile.py


import zipfile
import tarfile
tarfile.open::mode=:
  w:gz
  w:xz
  w:bz2

from io import BytesIO
ofile = BytesIO()
tf = tarfile.open(mode='w:gz', fileobj=ofile)
>>> ofile.getvalue()
b'\x1f\x8b\x08\x00\x02\x191d\x02\xff'
tf = tarfile.open(mode='w:xz', fileobj=ofile)
>>> ofile.getvalue()
b''
tf = tarfile.open(mode='w:bz2', fileobj=ofile)
>>> ofile.getvalue()
b''
tf = tarfile.open(mode='w:', fileobj=ofile)
>>> ofile.getvalue()
b''

from tarfile import is_tarfile
from zipfile import is_zipfile
is_zipfile(filename)
    Quickly see if a file is a ZIP file by checking the magic number.
stringEndArchive = b"PK\005\006"
stringCentralDir = b"PK\001\002"
stringFileHeader = b"PK\003\004"
stringEndArchive64Locator = b"PK\x06\x07"
stringEndArchive64 = b"PK\x06\x06"




===
===
bz2, gzip, lzma, zlib
#补偿: [[[[[[[[
===

buggy:
  chr(0x78) == 'x'
  chr(0x5e) == '^'
  header<zlib,level=-1=>6> = b'x\x9c'
  header<zlib,level=1> = b'x\x01'
  header<zlib,level=2..=5> = b'x^'
  header<zlib,level=6> = b'x\x9c'
  header<zlib,level=7..=9> = b'x\xda'
zlib.compress(data, /, level=-1)
  zlib_66_headers:goto
  一共66个！

buggy:
  header<gzip> = b'\x1f\x8b\x08\x00'
gzip.compress(data, compresslevel=9, *, mtime=None)
  gzip_only1_header:goto
  gzip_only1_header = '1F 8B'

header<bz2> = b'BZh'+压缩等级
bz2.compress(data, compresslevel=9)

chr(0x5d) == ']'
header<lzma,FORMAT_ALONE=2> = b']\x00\x00\x80\x00\xff\xff\xff\xff\xff\xff\xff\xff\x00'
header<lzma,FORMAT_XZ=1> = b'\xfd7zXZ\x00'
tail<lzma,FORMAT_XZ=1> = b'\x00\x04YZ'
lzma.compress(data, format=1, check=-1, preset=None, filters=None)




======
import zlib
mk = zlib.decompressobj().copy
dobj = zlib.decompressobj()
dir(dobj)
[..., 'copy', 'decompress', 'eof', 'flush', 'unconsumed_tail', 'unused_data']
help(dobj)
decompressobj.decompress :: bytes -> bytes
decompressobj.flush :: () -> bytes
decompressobj.eof :: bool
decompressobj.unused_data :: bytes
decompressobj.unconsumed_tail :: bytes
==>> zlib same as bz2,gzip,lzma:
  * classes for incremental (de)compression
  * functions for one-shot (de)compression

======



====
lzma.compress(data, format=1, check=-1, preset=None, filters=None)
FORMAT_ALONE = 2
FORMAT_AUTO = 0
FORMAT_RAW = 3
FORMAT_XZ = 1

CHECK_CRC32 = 1
CHECK_CRC64 = 4
CHECK_ID_MAX = 15
CHECK_NONE = 0
CHECK_SHA256 = 10
CHECK_UNKNOWN = 16

header<lzma,FORMAT_XZ=1> = b'\xfd7zXZ\x00'
tail<lzma,FORMAT_XZ=1> = b'\x00\x04YZ'

>>> import lzma as l
FORMAT_XZ = 1
>>> l.compress(b'')
b'\xfd7zXZ\x00\x00\x04\xe6\xd6\xb4F\x00\x00\x00\x00\x1c\xdfD!\x1f\xb6\xf3}\x01\x00\x00\x00\x00\x04YZ'
>>> l.compress(b'045tfgui')
b'\xfd7zXZ\x00\x00\x04\xe6\xd6\xb4F\x02\x00!\x01\x16\x00\x00\x00t/\xe5\xa3\x01\x00\x07045tfgui\x00\xc1\xdd\x077j\xdc\xbdI\x00\x01 \x08\xbb\x19\xd9\xbb\x1f\xb6\xf3}\x01\x00\x00\x00\x00\x04YZ'
>>> l.compress(b'045tfgueyyuhchi'*5+'非靠借口，港囧帅府'.encode('u8'))
b'\xfd7zXZ\x00\x00\x04\xe6\xd6\xb4F\x02\x00!\x01\x16\x00\x00\x00t/\xe5\xa3\xe0\x00e\x001]\x00\x18\r\x03\x01\xcf8\x8c\xe1`\x86\xaf po={\xc1\t\x88\xe2\t)xQ\xc1\x7fZ\xa1\xa5\xe9\x9abK\xdd\xba\x05\xdd\xa6W\x12\x82\xd4\xed\x90\xa1`\x1b`\x00\x00\x00\x00\x00H\xe9wV\x0fw\x1c\xe7\x00\x01Mf\x0e@\x80\xc1\x1f\xb6\xf3}\x01\x00\x00\x00\x00\x04YZ'
>>> l.compress('非靠借口，港囧帅府'.encode('u8'))
b'\xfd7zXZ\x00\x00\x04\xe6\xd6\xb4F\x02\x00!\x01\x16\x00\x00\x00t/\xe5\xa3\x01\x00\x1a\xe9\x9d\x9e\xe9\x9d\xa0\xe5\x80\x9f\xe5\x8f\xa3\xef\xbc\x8c\xe6\xb8\xaf\xe5\x9b\xa7\xe5\xb8\x85\xe5\xba\x9c\x00\x00\xb7\xe3; \x91dT\xaa\x00\x013\x1b\xf7\x19\x88^\x1f\xb6\xf3}\x01\x00\x00\x00\x00\x04YZ'


header<lzma,FORMAT_ALONE=2> = b']\x00\x00\x80\x00\xff\xff\xff\xff\xff\xff\xff\xff\x00'
FORMAT_ALONE = 2
>>> l.compress(b'', 2)
b']\x00\x00\x80\x00\xff\xff\xff\xff\xff\xff\xff\xff\x00\x83\xff\xfb\xff\xff\xc0\x00\x00\x00'
>>> l.compress(b'045tfgui',2)
b']\x00\x00\x80\x00\xff\xff\xff\xff\xff\xff\xff\xff\x00\x18\r\x03\x01\xcf8\x8c\xe1k\xc2\x1bS\xff\xffv|\x00\x00'
>>> l.compress(b'045tfgueyyuhchi'*5+'非靠借口，港囧帅府'.encode('u8'),2)
b']\x00\x00\x80\x00\xff\xff\xff\xff\xff\xff\xff\xff\x00\x18\r\x03\x01\xcf8\x8c\xe1`\x86\xaf po={\xc1\t\x88\xe2\t)xQ\xc1\x7fZ\xa1\xa5\xe9\x9abK\xdd\xba\x05\xdd\xa6W\x12\x82\xd4\xed\x90\xa1j\xa0m|\x7f\xfa\xc1d\x00'
>>> l.compress('非靠借口，港囧帅府'.encode('u8'),2)
b']\x00\x00\x80\x00\xff\xff\xff\xff\xff\xff\xff\xff\x00t\xa7O\xd0\x04\xa0r\x9f\x15\xc0g6\xaa\xf6\xa2\xfa#\xc4X\xad\x1e\x9d?\x89\tx\x9e\xab\xcd9\x9f\xff\xf6#(\x00'



header<bz2> = b'BZh'+压缩等级
bz2.compress(data, compresslevel=9)
>>> import bz2 as b
>>> b.compress(b'045tfgueyyuhchi'*5+'非靠借口，港囧帅府'.encode('u8'))
b'BZh91AY&SY\x0f\xa8\xfd\xb6\x00\x00\x00\t\xf9F\x00\x0b\xe0\x06 B\x04\x80\x0f\xc8\x80\x80T\x03 \xa0\x00Tc&\x99\x190C\x08~\xa9\xe4\x12T\xd0\x1e\xa6 \x004\x18\xb09\x13\xa1\x90\xf4=\x16\xa1\xc8dP\x86C\xd1\x01\x10D\xba\x93\x89\x16V\xe9\x15\xb6\xcc$\x18\x06c\xf0G\x81w$S\x85\t\x00\xfa\x8f\xdb`'
>>> b.compress('非靠借口，港囧帅府'.encode('u8'))
b'BZh91AY&SY?\x9b\xe7\xb7\x00\x00\x0c\x00yB\x04\x80\x0f\xc8\x80\x80T\x03 \xa0\x001L&\x9a\x03LB&\x80\x06\x8fSj\x0e\x08\xa0t\xd5W\x19\xbd\x9dH\x04\xf4y\xcf\xc5\xdc\x91N\x14$\x0f\xe6\xf9\xed\xc0'
>>> b.compress(b'045tfgui')
b'BZh91AY&SY\xa7^\xae\r\x00\x00\x00\t\x80F\x00\x01\xa0\x06\x00 \x00!\x90\xc2\x10\xc0\x87\x9b\x1d\x97\xc5\xdc\x91N\x14$)\xd7\xab\x83@'
>>> b.compress(b'')
b'BZh9\x17rE8P\x90\x00\x00\x00\x00'
>>> b.compress(b'',1)
b'BZh1\x17rE8P\x90\x00\x00\x00\x00'


header<gzip> = b'\x1f\x8b\x08\x00'
gzip.compress(data, compresslevel=9, *, mtime=None)
>>> import gzip as g
>>> g.compress(b'045tfgueyyuhchi'*5+'非靠借口，港囧帅府'.encode('u8'))
b'\x1f\x8b\x08\x00\xd4\x01(d\x02\xff301-IK/M\xad\xac,\xcdH\xce\xc84\xa0\x80\xfbr\xee\xbc\x97s\x17<m\x98\xff\xb4\x7f\xf1\xfb==\xcfv\xac\x7f:{\xf9\xd3\x1d\xadOw\xcd\x01\x00KJZ\xa2f\x00\x00\x00'
>>> g.compress(b'045tfgui')
b'\x1f\x8b\x08\x00\xc5\x01(d\x02\xff301-IK/\xcd\x04\x00q\xfc\xd5\xd1\x08\x00\x00\x00'
>>> g.compress('非靠借口，港囧帅府'.encode('u8'),2)
b'\x1f\x8b\x08\x00m\x01(d\x00\xff\x01\x1b\x00\xe4\xff\xe9\x9d\x9e\xe9\x9d\xa0\xe5\x80\x9f\xe5\x8f\xa3\xef\xbc\x8c\xe6\xb8\xaf\xe5\x9b\xa7\xe5\xb8\x85\xe5\xba\x9c(}\xd7\xb4\x1b\x00\x00\x00'
>>> g.compress('非靠借口，港囧帅府'.encode('u8'))
b'\x1f\x8b\x08\x00\x81\x01(d\x02\xff\x01\x1b\x00\xe4\xff\xe9\x9d\x9e\xe9\x9d\xa0\xe5\x80\x9f\xe5\x8f\xa3\xef\xbc\x8c\xe6\xb8\xaf\xe5\x9b\xa7\xe5\xb8\x85\xe5\xba\x9c(}\xd7\xb4\x1b\x00\x00\x00'
>>> g.compress(b'',1)
b'\x1f\x8b\x08\x00\x97\x01(d\x04\xff\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00'
>>> g.compress(b'')
b'\x1f\x8b\x08\x00\xb5\x01(d\x02\xff\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00'



header<zlib,level=-1=>6> = b'x\x9c'
header<zlib,level=1> = b'x\x01'
header<zlib,level=2..=5> = b'x^'
header<zlib,level=6> = b'x\x9c'
header<zlib,level=7..=9> = b'x\xda'
zlib.compress(data, /, level=-1)
>>> import zlib as z
>>> z.compress(b'045tfgueyyuhchi'*5+'非靠借口，港囧帅府'.encode('u8'))
b'x\x9c301-IK/M\xad\xac,\xcdH\xce\xc84\xa0\x80\xfbr\xee\xbc\x97s\x17<m\x98\xff\xb4\x7f\xf1\xfb==\xcfv\xac\x7f:{\xf9\xd3\x1d\xadOw\xcd\x01\x00?F0\x01'
>>> z.compress(b'045tfgui')
b'x\x9c301-IK/\xcd\x04\x00\n\x96\x02\xb9'
>>> z.compress(b'')
b'x\x9c\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',3)
b'x^\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',9)
b'x\xda\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',1)
b'x\x01\x03\x00\x00\x00\x00\x01'
header<zlib,level=1> = b'x\x01'
header<zlib,level=2..=5> = b'x^'
>>> z.compress(b'',2)
b'x^\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',3)
b'x^\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',4)
b'x^\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',5)
b'x^\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',6)
b'x\x9c\x03\x00\x00\x00\x00\x01'
header<zlib,level=6> = b'x\x9c'
header<zlib,level=7..=9> = b'x\xda'
>>> z.compress(b'',7)
b'x\xda\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',8)
b'x\xda\x03\x00\x00\x00\x00\x01'
>>> z.compress(b'',9)
b'x\xda\x03\x00\x00\x00\x00\x01'
>>> z.compress('非靠借口，港囧帅府'.encode('u8'))
b'x\x9c\x01\x1b\x00\xe4\xff\xe9\x9d\x9e\xe9\x9d\xa0\xe5\x80\x9f\xe5\x8f\xa3\xef\xbc\x8c\xe6\xb8\xaf\xe5\x9b\xa7\xe5\xb8\x85\xe5\xba\x9c\x10Y\x13n'

import zlib
mk = zlib.decompressobj().copy
rngs = range(0x100)
ls = []
for i in rngs:
  for j in rngs:
    header = bytes([i,j])
    try:
      __ = mk().decompress(header)
    except zlib.error:
      pass
    else:
      ls.append(header)
hs=[h.hex(' ') for h in ls]
for h in hs:h
len(hs)

>>> len(ls)
66
>>> ls
[b'\x08\x1d', b'\x08<', b'\x08[', b'\x08z', b'\x08\x99', b'\x08\xb8', b'\x08\xd7', b'\x08\xf6', b'\x18\x19', b'\x188', b'\x18W', b'\x18v', b'\x18\x95', b'\x18\xb4', b'\x18\xd3', b'\x18\xf2', b'(\x15', b'(4', b'(S', b'(r', b'(\x91', b'(\xb0', b'(\xcf', b'(\xee', b'8\x11', b'80', b'8O', b'8n', b'8\x8d', b'8\xac', b'8\xcb', b'8\xea', b'H\r', b'H,', b'HK', b'Hj', b'H\x89', b'H\xa8', b'H\xc7', b'H\xe6', b'X\t', b'X(', b'XG', b'Xf', b'X\x85', b'X\xa4', b'X\xc3', b'X\xe2', b'h\x05', b'h$', b'hC', b'hb', b'h\x81', b'h\xa0', b'h\xbf', b'h\xde', b'h\xfd', b'x\x01', b'x ', b'x?', b'x^', b'x}', b'x\x9c', b'x\xbb', b'x\xda', b'x\xf9']
>>> hs=[h.hex(' ') for h in ls]
>>> for h in hs:h
...
'08 1d'
'08 3c'
'08 5b'
'08 7a'
'08 99'
'08 b8'
'08 d7'
'08 f6'
'18 19'
'18 38'
'18 57'
'18 76'
'18 95'
'18 b4'
'18 d3'
'18 f2'
'28 15'
'28 34'
'28 53'
'28 72'
'28 91'
'28 b0'
'28 cf'
'28 ee'
'38 11'
'38 30'
'38 4f'
'38 6e'
'38 8d'
'38 ac'
'38 cb'
'38 ea'
'48 0d'
'48 2c'
'48 4b'
'48 6a'
'48 89'
'48 a8'
'48 c7'
'48 e6'
'58 09'
'58 28'
'58 47'
'58 66'
'58 85'
'58 a4'
'58 c3'
'58 e2'
'68 05'
'68 24'
'68 43'
'68 62'
'68 81'
'68 a0'
'68 bf'
'68 de'
'68 fd'
'78 01'
'78 20'
'78 3f'
'78 5e'
'78 7d'
'78 9c'
'78 bb'
'78 da'
'78 f9'
zlib_66_headers:here
>>> len(hs)
66
>>>
view ../../python3_src/nn_ns/bin/find_zlib_objs_in_file.py
zlib_66_headers__str = '081d 083c 085b 087a 0899 08b8 08d7 08f6 1819 1838 1857 1876 1895 18b4 18d3 18f2 2815 2834 2853 2872 2891 28b0 28cf 28ee 3811 3830 384f 386e 388d 38ac 38cb 38ea 480d 482c 484b 486a 4889 48a8 48c7 48e6 5809 5828 5847 5866 5885 58a4 58c3 58e2 6805 6824 6843 6862 6881 68a0 68bf 68de 68fd 7801 7820 783f 785e 787d 789c 78bb 78da 78f9'

=====
=====
import lzma
help(lzma)
LZMACompressor(format=FORMAT_XZ, check=-1, preset=None, filters=None)
LZMADecompressor(format=0, memlimit=None, filters=None)
  decompress(self, /, data, max_length=-1)
FORMAT_XZ
FORMAT_ALONE

=====
=====
import gzip
help(gzip)
GzipFile(filename=None, mode=None, compresslevel=9, fileobj=None, mtime=None)

gzip.decompress(b'0')
File "/data/data/com.termux/files/usr/lib/python3.10/gzip.py", line 436, in _read_gzip_header
    raise BadGzipFile('Not a gzipped file (%r)' % magic)
cp ~/../usr/lib/python3.10/gzip.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/gzip.py

class _GzipReader(_compression.DecompressReader):
    def _read_gzip_header(self):
        magic = self._fp.read(2)
        if magic == b'':
            return False

        if magic != b'\037\213':
            raise BadGzipFile('Not a gzipped file (%r)' % magic)
>>> gzip.decompress(b'\037\213')
EOFError: Compressed file ended before the end-of-stream marker was reached
>>> b'\037\213'
b'\x1f\x8b'
>>>
gzip_only1_header:here
  gzip_only1_header = '1F 8B'

=====
=====
import bz2
help(bz2)
bz2.decompress(b'0')
OSError: Invalid data stream
cp ~/../usr/lib/python3.10/bz2.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/bz2.py
from _bz2 import BZ2Compressor, BZ2Decompressor
  无代码



=====
=====
=====
=====
=====
=====

补偿: ]]
]]]]]]]]]]
[[[
pathlib
===
#view ~/../usr/lib/python3.10/pathlib.py
#cp ~/../usr/lib/python3.10/pathlib.py /sdcard/0my_files/tmp/out4py/py_src/
#view /sdcard/0my_files/tmp/out4py/py_src/pathlib.py
#
#view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/pathlib.html
#html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/pathlib.html > $my_tmp/out4py/html2text/py_38_doc/pathlipathlipathlib.txt
#view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/pathlib.html.txt


from pathlib import Path
import pathlib
pathlib.__all__
['PurePath', 'PurePosixPath', 'PureWindowsPath', 'Path', 'PosixPath', 'WindowsPath']

help(pathlib)

py_help pathlib > ~/my_tmp/out4py/py_help.pathlib.out.txt
view /sdcard/0my_files/tmp/out4py/py_help.pathlib.out.txt

PurePath
    PurePosixPath
    PureWindowsPath
    Path
        PosixPath(Path, PurePosixPath)
        WindowsPath(Path, PureWindowsPath)

Path__onlys:goto
PurePath__commons:goto



Path.expanduser(self)
  # 『~』-->home otherwise may ^FileNotFoundError:
Path.exists(self)
Path.resolve(self, strict=False)
Path.samefile(self, other_path)


PurePath.as_posix(self) -> str
PurePath.joinpath(self, *args)



『ctrl+v』select prefix; 『s』replace prefix by 『Path.』/『PurePath.』/
%s/^Path\. /      /
%s/^Path\.$/----/
%s/^PurePath\. /          /
%s/^PurePath\.$/----/
  [[
Path__onlys:[[
  最后是classmethod
----
----
Path.__enter__(self)
----
Path.__exit__(self, t, v, tb)
----
Path.absolute(self)
         Return an absolute version of this path.  This function works
         even if the path doesn't point to anything.
         
         No normalization is done, i.e. all '.' and '..' will be kept along.
         Use resolve() to get the canonical path to a file.
----
Path.chmod(self, mode, *, follow_symlinks=True)
         Change the permissions of the path, like os.chmod().
----
Path.exists(self)
         Whether this path exists.
----
Path.expanduser(self)
         Return a new path with expanded ~ and ~user constructs
         (as returned by os.path.expanduser)
----
Path.glob(self, pattern)
         Iterate over this subtree and yield all existing files (of any
         kind, including directories) matching the given relative pattern.
----
Path.group(self)
         Return the group name of the file gid.
----
Path.hardlink_to(self, target)
         Make this path a hard link pointing to the same file as *target*.
         
         Note the order of arguments (self, target) is the reverse of os.link's.
----
Path.is_block_device(self)
         Whether this path is a block device.
----
Path.is_char_device(self)
         Whether this path is a character device.
----
Path.is_dir(self)
         Whether this path is a directory.
----
Path.is_fifo(self)
         Whether this path is a FIFO.
----
Path.is_file(self)
         Whether this path is a regular file (also True for symlinks pointing
         to regular files).
----
Path.is_mount(self)
         Check if this path is a POSIX mount point
----
Path.is_socket(self)
         Whether this path is a socket.
----
Path.is_symlink(self)
         Whether this path is a symbolic link.
----
Path.iterdir(self)
         Iterate over the files in this directory.  Does not yield any
         result for the special paths '.' and '..'.
----
Path.lchmod(self, mode)
         Like chmod(), except if the path points to a symlink, the symlink's
         permissions are changed, rather than its target's.
----
Path.link_to(self, target)
         Make the target path a hard link pointing to this path.
         
         Note this function does not make this path a hard link to *target*,
         despite the implication of the function and argument names. The order
         of arguments (target, link) is the reverse of Path.symlink_to, but
         matches that of os.link.
         
         Deprecated since Python 3.10 and scheduled for removal in Python 3.12.
         Use `hardlink_to()` instead.
----
Path.lstat(self)
         Like stat(), except if the path points to a symlink, the symlink's
         status information is returned, rather than its target's.
----
Path.mkdir(self, mode=511, parents=False, exist_ok=False)
         Create a new directory at this given path.
----
Path.open(self, mode='r', buffering=-1, encoding=None, errors=None, newline=None)
         Open the file pointed by this path and return a file object, as
         the built-in open() function does.
----
Path.owner(self)
         Return the login name of the file owner.
----
Path.read_bytes(self)
         Open the file in bytes mode, read it, and close the file.
----
Path.read_text(self, encoding=None, errors=None)
         Open the file in text mode, read it, and close the file.
----
Path.readlink(self)
         Return the path to which the symbolic link points.
----
Path.rename(self, target)
         Rename this path to the target path.
         
         The target path may be absolute or relative. Relative paths are
         interpreted relative to the current working directory, *not* the
         directory of the Path object.
         
         Returns the new Path instance pointing to the target path.
----
Path.replace(self, target)
         Rename this path to the target path, overwriting if that path exists.
         
         The target path may be absolute or relative. Relative paths are
         interpreted relative to the current working directory, *not* the
         directory of the Path object.
         
         Returns the new Path instance pointing to the target path.
----
Path.resolve(self, strict=False)
         Make the path absolute, resolving all symlinks on the way and also
         normalizing it (for example turning slashes into backslashes under
         Windows).
----
Path.rglob(self, pattern)
         Recursively yield all existing files (of any kind, including
         directories) matching the given relative pattern, anywhere in
         this subtree.
----
Path.rmdir(self)
         Remove this directory.  The directory must be empty.
----
Path.samefile(self, other_path)
         Return whether other_path is the same or not as this file
         (as returned by os.path.samefile()).
----
Path.stat(self, *, follow_symlinks=True)
         Return the result of the stat() system call on this path, like
         os.stat() does.
----
Path.symlink_to(self, target, target_is_directory=False)
         Make this path a symlink pointing to the target path.
         Note the order of arguments (link, target) is the reverse of os.symlink.
----
Path.touch(self, mode=438, exist_ok=True)
         Create this file with the given access mode, if it doesn't exist.
----
Path.unlink(self, missing_ok=False)
         Remove this file or link.
         If the path is a directory, use rmdir() instead.
----
Path.write_bytes(self, data)
         Open the file in bytes mode, write to it, and close the file.
----
Path.write_text(self, data, encoding=None, errors=None, newline=None)
         Open the file in text mode, write to it, and close the file.
----
#Path.Class methods defined here:
----
@classmethod
Path.cwd() from builtins.type
         Return a new path pointing to the current working directory
         (as returned by os.getcwd()).
----
@classmethod
Path.home() from builtins.type
         Return a new path pointing to the user's home directory (as
         returned by os.path.expanduser('~')).
----
]]

PurePath__commons:[[
  最后是property
PurePath.__bytes__(self)
             Return the bytes representation of the path.  This is only
             recommended to use under Unix.
----
PurePath.__eq__(self, other)
             Return self==value.
----
PurePath.__fspath__(self)
----
PurePath.__ge__(self, other)
             Return self>=value.
----
PurePath.__gt__(self, other)
             Return self>value.
----
PurePath.__hash__(self)
             Return hash(self).
----
PurePath.__le__(self, other)
             Return self<=value.
----
PurePath.__lt__(self, other)
             Return self<value.
----
PurePath.__reduce__(self)
             Helper for pickle.
----
PurePath.__repr__(self)
             Return repr(self).
----
PurePath.__rtruediv__(self, key)
----
PurePath.__str__(self)
             Return the string representation of the path, suitable for
             passing to system calls.
----
PurePath.__truediv__(self, key)
----
PurePath.as_posix(self)
             Return the string representation of the path with forward (/)
             slashes.
----
PurePath.as_uri(self)
             Return the path as a 'file' URI.
----
PurePath.is_absolute(self)
             True if the path is absolute (has both a root and, if applicable,
             a drive).
----
PurePath.is_relative_to(self, *other)
             Return True if the path is relative to another path or False.
----
PurePath.is_reserved(self)
             Return True if the path contains one of the special names reserved
             by the system, if any.
----
PurePath.joinpath(self, *args)
             Combine this path with one or several arguments, and return a
             new path representing either a subpath (if all arguments are relative
             paths) or a totally different path (if one of the arguments is
             anchored).
----
PurePath.match(self, path_pattern)
             Return True if this path matches the given pattern.
----
PurePath.relative_to(self, *other)
             Return the relative path to another path identified by the passed
             arguments.  If the operation is not possible (because this is not
             a subpath of the other path), raise ValueError.
----
PurePath.with_name(self, name)
             Return a new path with the file name changed.
----
PurePath.with_stem(self, stem)
             Return a new path with the stem changed.
----
PurePath.with_suffix(self, suffix)
             Return a new path with the file suffix changed.  If the path
             has no suffix, add given suffix.  If the given suffix is an empty
             string, remove the suffix from the path.
----
#PurePath.Readonly properties defined here:
----
@property
PurePath.anchor
             The concatenation of the drive and root, or ''.
----
@property
PurePath.drive
             The drive prefix (letter or UNC path), if any.
----
@property
PurePath.name
             The final path component, if any.
----
@property
PurePath.parent
             The logical parent of the path.
----
@property
PurePath.parents
             A sequence of this path's logical parents.
----
@property
PurePath.parts
             An object providing sequence-like access to the
             components in the filesystem path.
----
@property
PurePath.root
             The root of the path, if any.
----
@property
PurePath.stem
             The final path component, minus its last suffix.
----
@property
PurePath.suffix
             The final component's last suffix, if any.
             
             This includes the leading period. For example: '.txt'
----
@property
PurePath.suffixes
             A list of the final component's suffixes, if any.
             
             These include the leading periods. For example: ['.tar', '.gz']
----
----
]]
  ]]


]]]
[[[
contextlib
@contextlib.contextmanager

import contextlib

contextlib.__all__
['asynccontextmanager', 'contextmanager', 'closing', 'nullcontext', 'AbstractContextManager', 'AbstractAsyncContextManager', 'AsyncExitStack', 'ContextDecorator', 'ExitStack', 'redirect_stdout', 'redirect_stderr', 'suppress', 'aclosing']

help(contextlib)

py_help contextlib > ~/my_tmp/out4py/py_help.contextlib.out.txt
view /sdcard/0my_files/tmp/out4py/py_help.contextlib.out.txt

contextmanager(func)
    @contextmanager decorator.
    ######################
    Typical usage:
        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>
        with some_generator(<arguments>) as <variable>:
            <body>
    ######################
    equivalent to this:
        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    ######################



from contextlib import contextmanager
from contextlib import redirect_stdout, redirect_stderr
py_help contextlib@redirect_stdout
py_help contextlib@redirect_stderr
class redirect_stderr(_RedirectStream)
 |  redirect_stderr(new_target)
 |
 |  Context manager for temporarily redirecting stderr to another file.

]]]
[[[
warnings__logging
warnings,logging


warnings.warn(message, UserWarning)
  default to print once
  <==> warnings.warn(message)
warnings.warn(message, DeprecationWarning)
  default not to print

warnings.warn(message, category=None, stacklevel=1, source=None)
    Issue a warning, or maybe ignore it or raise an exception.


logging.log(level, msg, *args, **kwargs)
    Log 'msg % args' with the integer severity 'level' on the root logger.
    If the logger has no handlers, call basicConfig() to add a console handler with a pre-defined format.






Python 3.10.5 (main, Jun  7 2022, 03:52:12)
logging::VERSION
    0.5.1.2
logging::DATE
    07 February 2010

>>> import warnings
>>> help(warnings)
>>> help(warnings.warn)

>>> import logging
>>> help(logging)
>>> help(logging.log)

>>> warnings.__all__
['warn', 'warn_explicit', 'showwarning', 'formatwarning', 'filterwarnings', 'simplefilter', 'resetwarnings', 'catch_warnings']

>>> logging.__all__
['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR', 'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO', 'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler', 'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig', 'captureWarnings', 'critical', 'debug', 'disable', 'error', 'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass', 'info', 'log', 'makeLogRecord', 'setLoggerClass', 'shutdown', 'warn', 'warning', 'getLogRecordFactory', 'setLogRecordFactory', 'lastResort', 'raiseExceptions']

logging::DATA::
    BASIC_FORMAT = '%(levelname)s:%(name)s:%(message)s'
    __all__ = [...]
    __status__ = 'production'
    lastResort = <_StderrHandler <stderr> (WARNING)>
    raiseExceptions = True
    ===log-level:
    CRITICAL = 50
        xxx FATAL = 50
    DEBUG = 10
    ERROR = 40
    INFO = 20
    NOTSET = 0
    WARNING = 30
        xxx WARN = 30
logging::log-FUNCTIONS::
    critical
        xxx fatal #Don't use this function, use critical() instead.
    debug
    error
    info
    log
    warning
        xxx warn



]]]
[[[
import inspect
py_help inspect | more
py_help inspect > ~/my_tmp/out4py/py_help.inspect.out.txt
view /sdcard/0my_files/tmp/out4py/py_help.inspect.out.txt

html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/inspect.html > $my_tmp/out4py/html2text/py_38_doc/inspect.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/inspect.html.txt

view ../../python3_src/seed/for_libs/for_inspect.py




getfullargspec只用于py2代码维护，应当使用signature()
#from py3_10_5__help_func
def getfullargspec(func) -> (args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations)/?FullArgSpec?
    (*args%defaults, *varargs, **kwonlyargs%kwonlydefaults, **varkw) : annotations
    SHOILD BE named as nm4param, not arg
    not distinguishing POSITIONAL_ONLY,POSITIONAL_OR_KEYWORD
      see:signature(f)->Signature
    === ***
    Notable differences from inspect.signature():
      - the "self" parameter is always reported, even for bound methods
      - wrapper chains defined by __wrapped__ *not* unwrapped automatically
    === ***

FullArgSpec(args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations)
    who return THIS??
      not found, manually??
      getfullargspec(func)?? yes!! see:py3_8_1__doc_html

[[
#from py3_8_1__doc_html
下面inspect.getfullargspec::Note ==>> getfullargspec()只用于py2代码维护，不如signature()
下面inspect.getargspec::Deprecated声明==>> getargspec@py2  vs  getfullargspec@py3_0
======
#from py3_8_1__doc_html
inspect.getfullargspec(func) -> FullArgSpec(args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations)

Note that signature() and Signature Object provide the recommended API for callable introspection, and support additional behaviours (like positional-only arguments) that are sometimes encountered in extension module APIs. This function is retained primarily for use in code that needs to maintain compatibility with the Python 2 inspect module API.
  getfullargspec()只用于py2代码维护，不如signature()

Changed in version 3.4: This function is now based on signature(), but still ignores __wrapped__ attributes and includes the already bound first parameter in the signature output for bound methods.


Changed in version 3.6: This method was previously documented as deprecated in favour of signature() in Python 3.5, but that decision has been reversed in order to restore a clearly supported standard interface for single-source Python 2/3 code migrating away from the legacy getargspec() API.


Changed in version 3.7: Python only explicitly guaranteed that it preserved the declaration order of keyword-only parameters as of version 3.7, although in practice this order had always been preserved in Python 3.
=========================
=========================
=========================
inspect.getargspec(func) -> ArgSpec(args, varargs, keywords, defaults)
  # *varargs, **keywords
  args :: [name]
      no POSITIONAL_ONLY
      all POSITIONAL_OR_KEYWORD
  varargs :: may name
      no KEYWORD_ONLY
  keywords :: may name
  defaults :: may tuple<py_obj>
      for .args[len(.args)-len(defaults):]
      no any for .keywords
        <<== no KEYWORD_ONLY


Deprecated since version 3.0: Use getfullargspec() for an updated API that is usually a drop-in replacement, but also correctly handles function annotations and keyword-only parameters.
  Alternatively, use signature() and Signature Object, which provide a more structured introspection API for callables.


]]










#from py3_10_5__help_func
def signature(obj:callable *, follow_wrapped=True, globals=None, locals=None, eval_str=False) -> Signature
[[
#from py3_8_1__doc_html
inspect.signature(callable, *, follow_wrapped=True) -> Signature

Accepts a wide range of Python callables, from plain functions and classes to functools.partial() objects.
    Raises ValueError if no signature can be provided, and
    TypeError if that type of object is not supported.

A slash(/) in the signature of a function denotes that the parameters prior to it are positional-only.
    For more info, see the FAQ entry on positional-only parameters.

New in version 3.5: follow_wrapped parameter. Pass False to get a signature of callable specifically (callable.__wrapped__ will not be used to unwrap decorated callables.)


Note
    Some callables may not be introspectable in certain implementations of Python.  For example, in CPython, some built-in functions defined in C provide no metadata about their arguments.


]]


Signature:
    -> return_annotation
    -> Signature.empty
    ===
    .parameters :: OrderedDict<name,Parameter>
    .return_annotation :: Signature.empty|object
    .bind(*args, **kwargs) -> BoundArguments
    .bind_partial(*args, **kwargs) -> BoundArguments
    ===

Parameter:
    name:annotation=default
    name:Parameter.empty=Parameter.empty
    kind <- def _(POSITIONAL_ONLY:0, /, POSITIONAL_OR_KEYWORD:1, *VAR_POSITIONAL:2, KEYWORD_ONLY:3, **VAR_KEYWORD:4)
    ===
    .kind : str
    .name : str
    .annotation :: Parameter.empty|object
    .default :: Parameter.empty|object
    ===

BoundArguments:
    # .arguments <==> (*.args, **.kwargs)
    ===
    .signature : Signature
    .args : tuple
    .kwargs : dict
    .arguments : OrderedDict<name,arg>
         args4calling_api
         func.locals at start except defaults
            vs: getcallargs()
    ===


def getcallargs(func, /, *positional, **named) -> {nm:v} #?fixed defaults?

def getargvalues(frame) -> (args, varargs, varkw, locals)

def getattr_static(obj, attr, default=_) -> descriptor








DESCRIPTION
CLASSES
FUNCTIONS
    attributes (co_*, im_*, tb_*, etc.)

[[
DESCRIPTION
  ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(), isgenerator(), istraceback(), isframe(), iscode(), isbuiltin(), isroutine() - check object types
  getmembers() - get members of an object that satisfy a given condition

  getfile(), getsourcefile(), getsource() - find an object`s source code
  getdoc(), getcomments() - get documentation on an object
  getmodule() - determine the module that an object came from
  getclasstree() - arrange classes so as to represent their hierarchy

  getargvalues(), getcallargs() - get info about function arguments
  getfullargspec() - same, with support for Python 3 features
  formatargvalues() - format an argument spec
  getouterframes(), getinnerframes() - get info about frames
  currentframe() - get the current stack frame
  stack(), trace() - get info about frames on the stack or in a traceback

  signature() - get a Signature object for the callable

  get_annotations() - safely compute an object`s annotations
]]




[[
CLASSES
begin-CLASSES

CLASSES
    builtins.Exception(builtins.BaseException)
        ClassFoundException
        EndOfBlock
    builtins.object
        BlockFinder
        BoundArguments
        Parameter
        Signature
    builtins.tuple(builtins.object)
        ArgInfo
        ArgSpec
        Arguments
        Attribute
        ClosureVars
        FrameInfo
        FullArgSpec
        Traceback

?namedtuple?:
     |  ArgInfo(args, varargs, keywords, locals)
     |  ArgSpec(args, varargs, keywords, defaults)
     |  Arguments(args, varargs, varkw)
     |  Attribute(name, kind, defining_class, object)
     ...
     |  ClosureVars(nonlocals, globals, builtins, unbound)
     ...
     |  FrameInfo(frame, filename, lineno, function, code_context, index)
     ...
     |  FullArgSpec(args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations)
     ...
     |  Traceback(filename, lineno, function, code_context, index)



    class BlockFinder(builtins.object)
     |  Provide a tokeneater() method to detect the end of a code block.
BoundArguments:
    # .arguments <==> (*.args, **.kwargs)
    ===
     .signature : Signature
     .args : tuple
     .kwargs : dict
     .arguments : OrderedDict<name,arg>
          args4calling_api
          func.locals at start except defaults
      ===
    class BoundArguments(builtins.object)
     |  BoundArguments(signature, arguments)
     |  
     |  Result of `Signature.bind` call.  Holds the mapping of arguments
     |  to the function`s parameters.
     |  
     |  Has the following public attributes:
     |  
     |  * arguments : dict
     |      An ordered mutable mapping of parameters` names to arguments` values.
     |      Does not contain arguments` default values.
     |  * signature : Signature
     |      The Signature object that created this instance.
     |  * args : tuple
     |      Tuple of positional arguments values.
     |  * kwargs : dict
     |      Dict of keyword arguments values.

Parameter:
    name:annotation=default
    name:Parameter.empty=Parameter.empty
    kind <- def _(POSITIONAL_ONLY:0, /, POSITIONAL_OR_KEYWORD:1, *VAR_POSITIONAL:2, KEYWORD_ONLY:3, **VAR_KEYWORD:4)
    ===
     .kind : str
     .name : str
     .annotation :: Parameter.empty|object
     .default :: Parameter.empty|object
    ===
    class Parameter(builtins.object)
     |  Parameter(name, kind, *, default, annotation)
     |  
     |  Represents a parameter in a function signature.
     |  
     |  Has the following public attributes:
     |  
     |  * name : str
     |      The name of the parameter as a string.
     |  * default : object
     |      The default value for the parameter if specified.  If the
     |      parameter has no default value, this attribute is set to
     |      `Parameter.empty`.
     |  * annotation
     |      The annotation for the parameter if specified.  If the
     |      parameter has no annotation, this attribute is set to
     |      `Parameter.empty`.
     |  * kind : str
     |      Describes how argument values are bound to the parameter.
     |      Possible values: `Parameter.POSITIONAL_ONLY`,
     |      `Parameter.POSITIONAL_OR_KEYWORD`, `Parameter.VAR_POSITIONAL`,
     |      `Parameter.KEYWORD_ONLY`, `Parameter.VAR_KEYWORD`.
     |  

Signature:
    -> return_annotation
    -> Signature.empty
    ===
    .parameters :: OrderedDict<name,Parameter>
     .return_annotation :: Signature.empty|object
     .bind(*args, **kwargs) -> BoundArguments
     .bind_partial(*args, **kwargs) -> BoundArguments
    ===
    class Signature(builtins.object)
     |  Signature(parameters=None, *, return_annotation, __validate_parameters__=True)
     |  
     |  A Signature object represents the overall signature of a function.
     |  It stores a Parameter object for each parameter accepted by the
     |  function, as well as information specific to the function itself.
     |  
     |  A Signature object has the following public attributes and methods:
     |  
     |  * parameters : OrderedDict
     |      An ordered mapping of parameters` names to the corresponding
     |      Parameter objects (keyword-only arguments are in the same order
     |      as listed in `code.co_varnames`).
     |  * return_annotation : object
     |      The annotation for the return type of the function if specified.
     |      If the function has no annotation for its return type, this
     |      attribute is set to `Signature.empty`.
     |  * bind(*args, **kwargs) -> BoundArguments
     |      Creates a mapping from positional and keyword arguments to
     |      parameters.
     |  * bind_partial(*args, **kwargs) -> BoundArguments
     |      Creates a partial mapping from positional and keyword arguments
     |      to parameters (simulating `functools.partial` behavior.)
     |  
end-CLASSES
]]




[[
FUNCTIONS
begin-FUNCTIONS
    getfullargspec(func)
        Get the names and default values of a callable object`s parameters.
        
        A tuple of seven things is returned:
        (args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations).
        'args' is a list of the parameter names.
        'varargs' and 'varkw' are the names of the * and ** parameters or None.
        'defaults' is an n-tuple of the default values of the last n parameters.
        'kwonlyargs' is a list of keyword-only parameter names.
        'kwonlydefaults' is a dictionary mapping names from kwonlyargs to defaults.
        'annotations' is a dictionary mapping parameter names to annotations.
        
        Notable differences from inspect.signature():
          - the "self" parameter is always reported, even for bound methods
          - wrapper chains defined by __wrapped__ *not* unwrapped automatically

    getcallargs(func, /, *positional, **named)
        Get the mapping of arguments to values.
        
        A dict is returned, with keys the function argument names (including the
        names of the * and ** arguments, if any), and values the respective bound
        values from 'positional' and 'named'.
    
    getargvalues(frame)
        Get information about arguments passed into a particular frame.
        
        A tuple of four things is returned: (args, varargs, varkw, locals).
        'args' is a list of the argument names.
        'varargs' and 'varkw' are the names of the * and ** arguments or None.
        'locals' is the locals dictionary of the given frame.
    
    getattr_static(obj, attr, default=<object object at 0x78e408cbf0>)
        Retrieve attributes without triggering dynamic lookup via the
        descriptor protocol,  __getattr__ or __getattribute__.
        
        Note: this function may not be able to retrieve all attributes
        that getattr can fetch (like dynamically created attributes)
        and may find attributes that getattr can't (like descriptors
        that raise AttributeError). It can also return descriptor objects
        instead of instance members in some cases. See the
        documentation for details.
    

    getclasstree(classes, unique=False)
        Arrange the given list of classes into a hierarchy of nested lists.
        
        Where a nested list appears, it contains classes derived from the class
        whose entry immediately precedes the list.  Each entry is a 2-tuple
        containing a class and a tuple of its base classes.  If the 'unique'
        argument is true, exactly one entry appears in the returned structure
        for each class in the given list.  Otherwise, classes using multiple
        inheritance and their descendants will appear multiple times.
    
    getclosurevars(func)
        Get the mapping of free variables to their current values.
        
        Returns a named tuple of dicts mapping the current nonlocal, global
        and builtin references as seen by the body of the function. A final
        set of unbound names that could not be resolved is also provided.
    
    getmodule(object, _filename=None)
        Return the module an object was defined in, or None if not found.
    
    getmodulename(path)
        Return the module name for a given file, or None.
    
    getmro(cls)
        Return tuple of base classes (including cls) in method resolution order.


    indentsize(line)
        Return the indent size, in spaces, at the start of a line of text.
    
    isabstract(object)
        Return true if the object is an abstract base class (ABC).
    

    isawaitable(object)
        Return true if object can be passed to an ``await`` expression.
    
    isbuiltin(object)
        Return true if the object is a built-in function or method.
        
        Built-in functions and methods provide these attributes:
            __doc__         documentation string
            __name__        original name of this function or method
            __self__        instance to which a method is bound, or None
    
    isclass(object)
        Return true if the object is a class.
        
        Class objects provide these attributes:
            __doc__         documentation string
            __module__      name of module in which this class was defined
    
    iscode(object)
        Return true if the object is a code object.
        
        Code objects provide these attributes:
            co_argcount         number of arguments (not including *, ** args
                                or keyword only arguments)
            co_code             string of raw compiled bytecode
            co_cellvars         tuple of names of cell variables
            co_consts           tuple of constants used in the bytecode
            co_filename         name of file in which this code object was created
            co_firstlineno      number of first line in Python source code
            co_flags            bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg
                                | 16=nested | 32=generator | 64=nofree | 128=coroutine
                                | 256=iterable_coroutine | 512=async_generator
            co_freevars         tuple of names of free variables
            co_posonlyargcount  number of positional only arguments
            co_kwonlyargcount   number of keyword only arguments (not including ** arg)
            co_lnotab           encoded mapping of line numbers to bytecode indices
            co_name             name with which this code object was defined
            co_names            tuple of names other than arguments and function locals
            co_nlocals          number of local variables
            co_stacksize        virtual machine stack space required
            co_varnames         tuple of names of arguments and local variables
    
    iscoroutine(object)
        Return true if the object is a coroutine.

    isframe(object)
        Return true if the object is a frame object.
        
        Frame objects provide these attributes:
            f_back          next outer frame object (this frame`s caller)
            f_builtins      built-in namespace seen by this frame
            f_code          code object being executed in this frame
            f_globals       global namespace seen by this frame
            f_lasti         index of last attempted instruction in bytecode
            f_lineno        current line number in Python source code
            f_locals        local namespace seen by this frame
            f_trace         tracing function for this frame, or None
    
    isfunction(object)
        Return true if the object is a user-defined function.
        
        Function objects provide these attributes:
            __doc__         documentation string
            __name__        name with which this function was defined
            __code__        code object containing compiled function bytecode
            __defaults__    tuple of any default values for arguments
            __globals__     global namespace in which this function was defined
            __annotations__ dict of parameter annotations
            __kwdefaults__  dict of keyword only parameters with defaults
    
    isgenerator(object)
        Return true if the object is a generator.
        
        Generator objects provide these attributes:
            __iter__        defined to support iteration over container
            close           raises a new GeneratorExit exception inside the
                            generator to terminate the iteration
            gi_code         code object
            gi_frame        frame object or possibly None once the generator has
                            been exhausted
            gi_running      set to 1 when generator is executing, 0 otherwise
            next            return the next item from the container
            send            resumes the generator and "sends" a value that becomes
                            the result of the current yield-expression
            throw           used to raise an exception inside the generator
    
    isgeneratorfunction(obj)
        Return true if the object is a user-defined generator function.

    ismethod(object)
        Return true if the object is an instance method.
        
        Instance method objects provide these attributes:
            __doc__         documentation string
            __name__        name with which this method was defined
            __func__        function object containing implementation of method
            __self__        instance to which this method is bound
    
    ismodule(object)
        Return true if the object is a module.
        
        Module objects provide these attributes:
            __cached__      pathname to byte compiled file
            __doc__         documentation string
            __file__        filename (missing for built-in modules)
    
    isroutine(object)
        Return true if the object is any kind of function or method.
    
    istraceback(object)
        Return true if the object is a traceback.
        
        Traceback objects provide these attributes:
            tb_frame        frame object at this level
            tb_lasti        index of last attempted instruction in bytecode
            tb_lineno       current line number in Python source code
            tb_next         next inner traceback object (called by this level)
    
    signature(obj, *, follow_wrapped=True, globals=None, locals=None, eval_str=False)
        Get a signature object for the passed callable.
    
    stack(context=1)
        Return a list of records for the stack above the caller`s frame.
    
    trace(context=1)
        Return a list of records for the stack below the current exception.
    
    unwrap(func, *, stop=None)
        Get the object wrapped by *func*.
        
        Follows the chain of :attr:`__wrapped__` attributes returning the last
        object in the chain.
        
        *stop* is an optional callback accepting an object in the wrapper chain
        as its sole argument that allows the unwrapping to be terminated early if
        the callback returns a true value. If the callback never returns a true
        value, the last object in the chain is returned as usual. For example,
        :func:`signature` uses this to stop unwrapping if any object in the
        chain has a ``__signature__`` attribute defined.
        
        :exc:`ValueError` is raised if a cycle is encountered.
    

end-FUNCTIONS
]]




]]]
[[[
re
  re____exports
  re_doc___spec_char____spec_seq____api_short____flag
    [re_doc___spec_char]
    [re_doc____spec_seq]
    [re_doc____api_short]
    [re_doc____flag]
  re____api_long
    re____split
      匹配则被切掉，但所有 捕获部分 都加入结果
===
>>> import re
>>> ' '.join(re.__all__)
'match fullmatch search sub subn split findall finditer compile purge template escape error Pattern Match A I L M S X U ASCII IGNORECASE LOCALE MULTILINE DOTALL VERBOSE UNICODE'

===
re.__all__
[[re____exports
match
fullmatch
search
sub
subn
split
findall
finditer
compile
purge
template
escape
error
Pattern
Match
A
I
L
M
S
X
U
ASCII
IGNORECASE
LOCALE
MULTILINE
DOTALL
VERBOSE
UNICODE
]]re____exports:end
===
view ~/../usr/lib/python3.10/re.py
cp ~/../usr/lib/python3.10/re.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/re.py
===
re.__doc__
[[re_doc___spec_char____spec_seq____api_short____flag
[re_doc___spec_char]
[re_doc____spec_seq]
[re_doc____api_short]
[re_doc____flag]

r"""Support for regular expressions (RE).

This module provides regular expression matching operations similar to
those found in Perl.  It supports both 8-bit and Unicode strings; both
the pattern and the strings being processed can contain null bytes and
characters outside the US ASCII range.

Regular expressions can contain both special and ordinary characters.
Most ordinary characters, like "A", "a", or "0", are the simplest
regular expressions; they simply match themselves.  You can
concatenate ordinary characters, so last matches the string 'last'.

[re_doc___spec_char]
The special characters are:
    "."      Matches any character except a newline.
    "^"      Matches the start of the string.
    "$"      Matches the end of the string or just before the newline at
             the end of the string.
    "*"      Matches 0 or more (greedy) repetitions of the preceding RE.
             Greedy means that it will match as many repetitions as possible.
    "+"      Matches 1 or more (greedy) repetitions of the preceding RE.
    "?"      Matches 0 or 1 (greedy) of the preceding RE.
    *?,+?,?? Non-greedy versions of the previous three special characters.
    {m,n}    Matches from m to n repetitions of the preceding RE.
    {m,n}?   Non-greedy version of the above.
    "\\"     Either escapes special characters or signals a special sequence.
    []       Indicates a set of characters.
             A "^" as the first character indicates a complementing set.
    "|"      A|B, creates an RE that will match either A or B.
    (...)    Matches the RE inside the parentheses.
             The contents can be retrieved or matched later in the string.
    (?aiLmsux) The letters set the corresponding flags defined below.
    (?:...)  Non-grouping version of regular parentheses.
    (?P<name>...) The substring matched by the group is accessible by name.
    (?P=name)     Matches the text matched earlier by the group named name.
    (?#...)  A comment; ignored.
    (?=...)  Matches if ... matches next, but doesn't consume the string.
    (?!...)  Matches if ... doesn't match next.
    (?<=...) Matches if preceded by ... (must be fixed length).
    (?<!...) Matches if not preceded by ... (must be fixed length).
    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,
                       the (optional) no pattern otherwise.

[re_doc____spec_seq]
The special sequences consist of "\\" and a character from the list
below.  If the ordinary character is not on the list, then the
resulting RE will match the second character.
    \number  Matches the contents of the group of the same number.
    \A       Matches only at the start of the string.
    \Z       Matches only at the end of the string.
    \b       Matches the empty string, but only at the start or end of a word.
    \B       Matches the empty string, but not at the start or end of a word.
    \d       Matches any decimal digit; equivalent to the set [0-9] in
             bytes patterns or string patterns with the ASCII flag.
             In string patterns without the ASCII flag, it will match the whole
             range of Unicode digits.
    \D       Matches any non-digit character; equivalent to [^\d].
    \s       Matches any whitespace character; equivalent to [ \t\n\r\f\v] in
             bytes patterns or string patterns with the ASCII flag.
             In string patterns without the ASCII flag, it will match the whole
             range of Unicode whitespace characters.
    \S       Matches any non-whitespace character; equivalent to [^\s].
    \w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]
             in bytes patterns or string patterns with the ASCII flag.
             In string patterns without the ASCII flag, it will match the
             range of Unicode alphanumeric characters (letters plus digits
             plus underscore).
             With LOCALE, it will match the set [0-9_] plus characters defined
             as letters for the current locale.
    \W       Matches the complement of \w.
    \\       Matches a literal backslash.

[re_doc____api_short]
This module exports the following functions:
    match     Match a regular expression pattern to the beginning of a string.
    fullmatch Match a regular expression pattern to all of a string.
    search    Search a string for the presence of a pattern.
    sub       Substitute occurrences of a pattern found in a string.
    subn      Same as sub, but also return the number of substitutions made.
    split     Split a string by the occurrences of a pattern.
    findall   Find all occurrences of a pattern in a string.
    finditer  Return an iterator yielding a Match object for each match.
    compile   Compile a pattern into a Pattern object.
    purge     Clear the regular expression cache.
    escape    Backslash all non-alphanumerics in a string.

[re_doc____flag]
Each function other than purge and escape can take an optional 'flags' argument
consisting of one or more of the following module constants, joined by "|".
A, L, and U are mutually exclusive.
    A  ASCII       For string patterns, make \w, \W, \b, \B, \d, \D
                   match the corresponding ASCII character categories
                   (rather than the whole Unicode categories, which is the
                   default).
                   For bytes patterns, this flag is the only available
                   behaviour and needn't be specified.
    I  IGNORECASE  Perform case-insensitive matching.
    L  LOCALE      Make \w, \W, \b, \B, dependent on the current locale.
    M  MULTILINE   "^" matches the beginning of lines (after a newline)
                   as well as the string.
                   "$" matches the end of lines (before a newline) as well
                   as the end of the string.
    S  DOTALL      "." matches any character at all, including the newline.
    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.
    U  UNICODE     For compatibility only. Ignored for string patterns (it
                   is the default), and forbidden for bytes patterns.

This module also defines an exception 'error'.

"""
]]re_doc___spec_char____spec_seq____api_short____flag:end
[[re____api_long
__version__ = "2.2.1"

# public symbols
__all__ = [
    "match", "fullmatch", "search", "sub", "subn", "split",
    "findall", "finditer", "compile", "purge", "template", "escape",
    "error", "Pattern", "Match", "A", "I", "L", "M", "S", "X", "U",
    "ASCII", "IGNORECASE", "LOCALE", "MULTILINE", "DOTALL", "VERBOSE",
    "UNICODE",
]

# sre exception
error = sre_compile.error


def match(pattern, string, flags=0):
    """Try to apply the pattern at the start of the string, returning
    a Match object, or None if no match was found."""

def fullmatch(pattern, string, flags=0):
    """Try to apply the pattern to all of the string, returning
    a Match object, or None if no match was found."""

def search(pattern, string, flags=0):
    """Scan through string looking for a match to the pattern, returning
    a Match object, or None if no match was found."""

def sub(pattern, repl, string, count=0, flags=0):
    """Return the string obtained by replacing the leftmost
    non-overlapping occurrences of the pattern in string by the
    replacement repl.  repl can be either a string or a callable;
    if a string, backslash escapes in it are processed.  If it is
    a callable, it's passed the Match object and must return
    a replacement string to be used."""

def subn(pattern, repl, string, count=0, flags=0):
    """Return a 2-tuple containing (new_string, number).
    new_string is the string obtained by replacing the leftmost
    non-overlapping occurrences of the pattern in the source
    string by the replacement repl.  number is the number of
    substitutions that were made. repl can be either a string or a
    callable; if a string, backslash escapes in it are processed.
    If it is a callable, it's passed the Match object and must
    return a replacement string to be used."""

#re____split
def split(pattern, string, maxsplit=0, flags=0):
    """Split the source string by the occurrences of the pattern,
    returning a list containing the resulting substrings.  If
    capturing parentheses are used in pattern, then the text of all
    groups in the pattern are also returned as part of the resulting
    list.  If maxsplit is nonzero, at most maxsplit splits occur,
    and the remainder of the string is returned as the final element
    of the list."""

def findall(pattern, string, flags=0):
    """Return a list of all non-overlapping matches in the string.

    If one or more capturing groups are present in the pattern, return
    a list of groups; this will be a list of tuples if the pattern
    has more than one group.

    Empty matches are included in the result."""

def finditer(pattern, string, flags=0):
    """Return an iterator over all non-overlapping matches in the
    string.  For each match, the iterator returns a Match object.

    Empty matches are included in the result."""

def compile(pattern, flags=0):
    "Compile a regular expression pattern, returning a Pattern object."

def purge():
    "Clear the regular expression caches"
    _cache.clear()
    _compile_repl.cache_clear()

def template(pattern, flags=0):
    "Compile a template pattern, returning a Pattern object"

# SPECIAL_CHARS
# closing ')', '}' and ']'
# '-' (a range in character set)
# '&', '~', (extended character set operations)
# '#' (comment) and WHITESPACE (ignored) in verbose mode
_special_chars_map = {i: '\\' + chr(i) for i in b'()[]{}?*+-|^$\\.&~# \t\n\r\v\f'}

def escape(pattern):
    """
    Escape special characters in a string.
    """
    if isinstance(pattern, str):
        return pattern.translate(_special_chars_map)
    else:
        pattern = str(pattern, 'latin1')
        return pattern.translate(_special_chars_map).encode('latin1')

Pattern = type(sre_compile.compile('', 0))
Match = type(sre_compile.compile('', 0).match(''))

# --------------------------------------------------------------------
# internals

_cache = {}  # ordered!

_MAXCACHE = 512
def _compile(pattern, flags):
    # internal: compile pattern
    :: (str|bytes) -> flags -> Pattern
    :: Pattern -> 0 -> Pattern
    using _cache, _MAXCACHE

@functools.lru_cache(_MAXCACHE)
def _compile_repl(repl, pattern):
    # internal: compile replacement pattern

def _expand(pattern, match, template):
    # internal: Match.expand implementation hook

def _subx(pattern, template):
    # internal: Pattern.sub/subn implementation helper

# register myself for pickling

import copyreg

def _pickle(p):
    return _compile, (p.pattern, p.flags)

copyreg.pickle(Pattern, _pickle, _compile)

]]re____api_long:end
]]]
[[[
help()
===
help> quit #退出 交互对话式help()
help> math #相当于 help(math)
===
>>> help()

Welcome to Python 3.10's help utility!

If this is your first time using Python, you should definitely check out
the tutorial on the internet at https://docs.python.org/3.10/tutorial/.

Enter the name of any module, keyword, or topic to get help on writing
Python programs and using Python modules.  To quit this help utility and
return to the interpreter, just type "quit".

To get a list of available modules, keywords, symbols, or topics, type
"modules", "keywords", "symbols", or "topics".  Each module also comes
with a one-line summary of what it does; to list the modules whose name
or summary contain a given string such as "spam", type "modules spam".

help> keywords

Here is a list of the Python keywords.  Enter any keyword to get more help.

False               class               from                or
None                continue            global              pass
True                def                 if                  raise
and                 del                 import              return
as                  elif                in                  try
assert              else                is                  while
async               except              lambda              with
await               finally             nonlocal            yield
break               for                 not

help> symbols

Here is a list of the punctuation symbols which Python assigns special meaning
to. Enter any symbol to get more help.

!=                  +                   <=                  __
"                   +=                  <>                  `
"""                 ,                   ==                  b"
%                   -                   >                   b'
%=                  -=                  >=                  f"
&                   .                   >>                  f'
&=                  ...                 >>=                 j
'                   /                   @                   r"
'''                 //                  J                   r'
(                   //=                 [                   u"
)                   /=                  \                   u'
*                   :                   ]                   |
**                  <                   ^                   |=
**=                 <<                  ^=                  ~
*=                  <<=                 _

help> topics

Here is a list of available topics.  Enter any topic name to get more help.

ASSERTION           DELETION            LOOPING             SHIFTING
ASSIGNMENT          DICTIONARIES        MAPPINGMETHODS      SLICINGS
ATTRIBUTEMETHODS    DICTIONARYLITERALS  MAPPINGS            SPECIALATTRIBUTES
ATTRIBUTES          DYNAMICFEATURES     METHODS             SPECIALIDENTIFIERS
AUGMENTEDASSIGNMENT ELLIPSIS            MODULES             SPECIALMETHODS
BASICMETHODS        EXCEPTIONS          NAMESPACES          STRINGMETHODS
BINARY              EXECUTION           NONE                STRINGS
BITWISE             EXPRESSIONS         NUMBERMETHODS       SUBSCRIPTS
BOOLEAN             FLOAT               NUMBERS             TRACEBACKS
CALLABLEMETHODS     FORMATTING          OBJECTS             TRUTHVALUE
CALLS               FRAMEOBJECTS        OPERATORS           TUPLELITERALS
CLASSES             FRAMES              PACKAGES            TUPLES
CODEOBJECTS         FUNCTIONS           POWER               TYPEOBJECTS
COMPARISON          IDENTIFIERS         PRECEDENCE          TYPES
COMPLEX             IMPORTING           PRIVATENAMES        UNARY
CONDITIONAL         INTEGER             RETURNING           UNICODE
CONTEXTMANAGERS     LISTLITERALS        SCOPING
CONVERSIONS         LISTS               SEQUENCEMETHODS
DEBUGGING           LITERALS            SEQUENCES

help> quit

You are now leaving help and returning to the Python interpreter.
If you want to ask for help on a particular object directly from the
interpreter, you can type "help(object)".  Executing "help('string')"
has the same effect as typing a particular string at the help> prompt.
>>>


好久...
help> modules

Please wait a moment while I gather a list of all available modules...

Cython              _weakrefset         hashlib             rlcompleter
PIL                 _xxsubinterpreters  heapq               runpy
__future__          _xxtestfuzz         hmac                sched
__setup__           _zoneinfo           html                secrets
_abc                abc                 http                seed
_aix_support        aifc                idna                select
_ast                antigravity         imageio             selectors
_asyncio            argparse            imaplib             setuptools
_bisect             array               imghdr              shelve
_blake2             asciidoc            imp                 shlex
_bootsubprocess     asgiref             importlib           shutil
_bz2                ast                 inspect             signal
_cffi_backend       asynchat            invoke              site
_codecs             asyncio             io                  six
_codecs_cn          asyncore            ipaddress           smtpd
_codecs_hk          atexit              isympy              smtplib
_codecs_iso2022     audioop             itertools           sndhdr
_codecs_jp          base64              json                socket
_codecs_kr          bdb                 keyword             socketserver
_codecs_tw          binascii            lib2to3             soupsieve
_collections        binhex              linecache           sox
_collections_abc    bisect              locale              sqlite3
_compat_pickle      bs4                 logging             sqlparse
_compression        builtins            lxml                sre_compile
_contextvars        bz2                 lzma                sre_constants
_crypt              cProfile            mailbox             sre_parse
_csv                calendar            mailcap             ssl
_ctypes             certifi             marshal             stat
_ctypes_test        cffi                math                statistics
_curses             cgi                 mimetypes           stopit
_curses_panel       cgitb               mmap                string
_datetime           charset_normalizer  modulefinder        stringprep
_dbm                chunk               mpmath              struct
_decimal            cmath               multiprocessing     subprocess
_distutils_hack     cmd                 nacl                sunau
_elementtree        code                netrc               sympy
_functools          codecs              networkx            symtable
_gdbm               codeop              nn_ns               sys
_hashlib            collections         nntplib             sysconfig
_heapq              colorsys            ntpath              syslog
_imp                compileall          nturl2path          tabnanny
_io                 concurrent          numbers             tarfile
_json               configparser        numpy               telnetlib
_locale             constant_nn         opcode              tempfile
_lsprof             contextlib          openpyxl            termios
_lzma               contextvars         operator            tests
_markupbase         copy                optparse            textwrap
_md5                copyreg             os                  this
_multibytecodec     crypt               ossaudiodev         threading
_multiprocessing    csv                 pandas              time
_opcode             ctypes              pathlib             timeit
_operator           curses              pdb                 tk
_osx_support        cv2                 pgen2               token
_pickle             cython              pickle              tokenize
_posixshmem         dataclasses         pickletools         trace
_posixsubprocess    datetime            pip                 traceback
_py_abc             dateutil            pipes               tracemalloc
_pydecimal          dbm                 pkg_resources       tty
_pyio               decimal             pkgutil             types
_queue              difflib             platform            typing
_random             dis                 plistlib            unicodedata
_sha1               distutils           png                 unittest
_sha256             django              poplib              urllib
_sha3               doctest             posix               urllib3
_sha512             dot_parser          posixpath           uu
_signal             email               pprint              uuid
_sitebuiltins       encodings           profile             venv
_socket             ensurepip           pstats              warnings
_sqlite3            enum                pty                 wave
_sre                errno               pwd                 weakref
_ssl                et_xmlfile          py_compile          webbrowser
_stat               faulthandler        pybind11            wheel
_statistics         fcntl               pyclbr              wsgiref
_string             ffmpeg              pycparser           xdrlib
_strptime           filecmp             pydoc               xlrd
_struct             fileinput           pydoc_data          xlsxwriter
_symtable           fnmatch             pydot               xlutils
_sysconfigdata__linux_ fractions           pyexpat             xlwt
_testbuffer         ftplib              pyparsing           xml
_testcapi           functools           pytz                xmlrpc
_testimportmultiple gc                  pywifi              xxlimited
_testinternalcapi   genericpath         pyximport           xxlimited_35
_testmultiphase     getopt              queue               xxsubtype
_thread             getpass             quopri              zipapp
_threading_local    gettext             random              zipfile
_tkinter            glob                re                  zipimport
_tracemalloc        gmpy2               readline            zlib
_uuid               graphlib            reprlib             zmq
_warnings           grp                 requests            zoneinfo
_weakref            gzip                resource

Enter any module name to get more help.  Or, type "modules spam" to search
for modules whose name or summary contain the string "spam".

help>



]]]
[[[
cmath - complex-math
===
cmp_api_of__math__cmath:goto
===
>>> import cmath
>>> ' '.join(dir(cmath))
'__doc__ __file__ __loader__ __name__ __package__ __spec__ acos acosh asin asinh atan atanh cos cosh e exp inf infj isclose isfinite isinf isnan log log10 nan nanj phase pi polar rect sin sinh sqrt tan tanh tau'
===__all__
e = 2.718281828459045
inf = float('inf')
infj = complex('infj')
nan = float('nan')
nanj = complex('nanj')
pi = 3.141592653589793
tau = 6.283185307179586
  #其余都是float() 并非complex()

acos
acosh
asin
asinh
atan
atanh
cos
cosh
exp
isclose
isfinite
isinf
isnan
log
log10
phase
polar
rect
sin
sinh
sqrt
tan
tanh
===
py -c 'import cmath;help(cmath)' | cat
[[
Help on module cmath:

NAME
    cmath
MODULE REFERENCE                                      https://docs.python.org/3.10/library/cmath.html
    The following documentation is automatically generated from the Python
    source files.  It may be incomplete, incorrect or include features that
    are considered implementation detail and may vary between Python
    implementations.  When in doubt, consult the module reference at the
    location listed above.
DESCRIPTION                                           This module provides access to mathematical functions for complex
    numbers.
FUNCTIONS                                             acos(z, /)
        Return the arc cosine of z.
                                                      acosh(z, /)
        Return the inverse hyperbolic cosine of z.
                                                      asin(z, /)
        Return the arc sine of z.
                                                      asinh(z, /)
        Return the inverse hyperbolic sine of z.
                                                      atan(z, /)
        Return the arc tangent of z.

    atanh(z, /)
        Return the inverse hyperbolic tangent of z.
                                                      cos(z, /)
        Return the cosine of z.
                                                      cosh(z, /)
        Return the hyperbolic cosine of z.

    exp(z, /)
        Return the exponential value e**z.

    isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)
        Determine whether two complex numbers are close in value.

          rel_tol
            maximum difference for being considered "close", relative to the
            magnitude of the input values
          abs_tol
            maximum difference for being considered "close", regardless of the
            magnitude of the input values

        Return True if a is close in value to b, and False otherwise.

        For the values to be considered close, the difference between them must be
        smaller than at least one of the tolerances.

        -inf, inf and NaN behave similarly to the IEEE 754 Standard. That is, NaN is
        not close to anything, even itself. inf and -inf are only close to themselves.

    isfinite(z, /)
        Return True if both the real and imaginary parts of z are finite, else False.

    isinf(z, /)
        Checks if the real or imaginary part of z is infinite.

    isnan(z, /)
        Checks if the real or imaginary part of z not a number (NaN).

    log(...)
        log(z[, base]) -> the logarithm of z to the given base.

        If the base not specified, returns the natural logarithm (base e) of z.

    log10(z, /)
        Return the base-10 logarithm of z.

    phase(z, /)
        Return argument, also known as the phase angle, of a complex.

    polar(z, /)
        Convert a complex from rectangular coordinates to polar coordinates.

        r is the distance from 0 and phi the phase angle.

    rect(r, phi, /)
        Convert from polar coordinates to rectangular coordinates.

    sin(z, /)
        Return the sine of z.

    sinh(z, /)                                            Return the hyperbolic sine of z.

    sqrt(z, /)                                            Return the square root of z.

    tan(z, /)
        Return the tangent of z.

    tanh(z, /)
        Return the hyperbolic tangent of z.

DATA
    e = 2.718281828459045
    inf = inf
    infj = infj
    nan = nan
    nanj = nanj
    pi = 3.141592653589793
    tau = 6.283185307179586

FILE
    /data/data/com.termux/files/usr/lib/python3.10/lib-dynload/cmath.cpython-310.so
]]
]]]
[[[
math
===
cmp_api_of__math__cmath:goto
===
>>> import math
>>> math.__file__
'/data/data/com.termux/files/usr/lib/python3.10/lib-dynload/math.cpython-310.so'
>>> import cmath
>>> cmath.__file__
'/data/data/com.termux/files/usr/lib/python3.10/lib-dynload/cmath.cpython-310.so'
===
import math
help(math)
    交互对话式，太长就难以复制
    使用py_eval输出到文件
    改为使用:
      py -c 'import math;help(math)' | cat
===
py_eval --turnoff_safe4eval --startup 'import math' -i 'help(math)' >>  ../../../tmp/out4py/py_eval/py_eval.py..help-math.out.txt
view ../../../tmp/out4py/py_eval/py_eval.py..help-math.out.txt
  #最后一行:None 显示返回值，不太行
===or:
py -c 'import math;help(math)' | cat
  #只执行，非求值返回，行！
===
>>> import math
>>> ' '.join(dir(math))
'__doc__ __file__ __loader__ __name__ __package__ __spec__ acos acosh asin asinh atan atan2 atanh ceil comb copysign cos cosh degrees dist e erf erfc exp expm1 fabs factorial floor fmod frexp fsum gamma gcd hypot inf isclose isfinite isinf isnan isqrt lcm ldexp lgamma log log10 log1p log2 modf nan nextafter perm pi pow prod radians remainder sin sinh sqrt tan tanh tau trunc ulp'
>>> import cmath
>>> ' '.join(dir(cmath))
'__doc__ __file__ __loader__ __name__ __package__ __spec__ acos acosh asin asinh atan atanh cos cosh e exp inf infj isclose isfinite isinf isnan log log10 nan nanj phase pi polar rect sin sinh sqrt tan tanh tau'

#cmp_api_of__math__cmath
>>> ' '.join(sorted(set(dir(cmath)) - set(dir(math))))
'infj nanj phase polar rect'

>>> ' '.join(sorted(set(dir(math)) - set(dir(cmath))))
'atan2 ceil comb copysign degrees dist erf erfc expm1 fabs factorial floor fmod frexp fsum gamma gcd hypot isqrt lcm ldexp lgamma log1p log2 modf nextafter perm pow prod radians remainder trunc ulp'

>>> ' '.join(sorted(set(dir(math)) & set(dir(cmath))))
'__doc__ __file__ __loader__ __name__ __package__ __spec__ acos acosh asin asinh atan atanh cos cosh e exp inf isclose isfinite isinf isnan log log10 nan pi sin sinh sqrt tan tanh tau'

===__all__
e = 2.718281828459045
inf = float('inf')
nan = float('nan')
pi = 3.141592653589793
tau = 6.283185307179586

acos
acosh
asin
asinh
atan
atan2
atanh
ceil
comb
copysign
cos
cosh
degrees
dist
erf
erfc
exp
expm1
fabs
factorial
floor
fmod
frexp
fsum
gamma
gcd
hypot
isclose
isfinite
isinf
isnan
isqrt
lcm
ldexp
lgamma
log
log10
log1p
log2
modf
nextafter
perm
pow
prod
radians
remainder
sin
sinh
sqrt
tan
tanh
trunc
ulp
===
py -c 'import math;help(math)' | cat
[[
Help on module math:

NAME
    math

MODULE REFERENCE
    https://docs.python.org/3.10/library/math.html

    The following documentation is automatically generated from the Python
    source files.  It may be incomplete, incorrect or include features that
    are considered implementation detail and may vary between Python
    implementations.  When in doubt, consult the module reference at the
    location listed above.

DESCRIPTION
    This module provides access to the mathematical functions
    defined by the C standard.

FUNCTIONS
    acos(x, /)
        Return the arc cosine (measured in radians) of x.

        The result is between 0 and pi.

    acosh(x, /)
        Return the inverse hyperbolic cosine of x.

    asin(x, /)
        Return the arc sine (measured in radians) of x.

        The result is between -pi/2 and pi/2.

    asinh(x, /)
        Return the inverse hyperbolic sine of x.

    atan(x, /)
        Return the arc tangent (measured in radians) of x.

        The result is between -pi/2 and pi/2.

    atan2(y, x, /)
        Return the arc tangent (measured in radians) of y/x.

        Unlike atan(y/x), the signs of both x and y are considered.

    atanh(x, /)
        Return the inverse hyperbolic tangent of x.

    ceil(x, /)
        Return the ceiling of x as an Integral.

        This is the smallest integer >= x.

    comb(n, k, /)
        Number of ways to choose k items from n items without repetition and without order.

        Evaluates to n! / (k! * (n - k)!) when k <= n and evaluates
        to zero when k > n.

        Also called the binomial coefficient because it is equivalent
        to the coefficient of k-th term in polynomial expansion of the
        expression (1 + x)**n.

        Raises TypeError if either of the arguments are not integers.
        Raises ValueError if either of the arguments are negative.

    copysign(x, y, /)
        Return a float with the magnitude (absolute value) of x but the sign of y.

        On platforms that support signed zeros, copysign(1.0, -0.0)
        returns -1.0.

    cos(x, /)
        Return the cosine of x (measured in radians).

    cosh(x, /)
        Return the hyperbolic cosine of x.

    degrees(x, /)
        Convert angle x from radians to degrees.

    dist(p, q, /)
        Return the Euclidean distance between two points p and q.

        The points should be specified as sequences (or iterables) of
        coordinates.  Both inputs must have the same dimension.

        Roughly equivalent to:
            sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q)))

    erf(x, /)
        Error function at x.

    erfc(x, /)
        Complementary error function at x.

    exp(x, /)
        Return e raised to the power of x.

    expm1(x, /)
        Return exp(x)-1.

        This function avoids the loss of precision involved in the direct evaluation of exp(x)-1 for small x.

    fabs(x, /)
        Return the absolute value of the float x.

    factorial(x, /)
        Find x!.

        Raise a ValueError if x is negative or non-integral.

    floor(x, /)
        Return the floor of x as an Integral.

        This is the largest integer <= x.

    fmod(x, y, /)
        Return fmod(x, y), according to platform C.

        x % y may differ.

    frexp(x, /)
        Return the mantissa and exponent of x, as pair (m, e).

        m is a float and e is an int, such that x = m * 2.**e.
        If x is 0, m and e are both 0.  Else 0.5 <= abs(m) < 1.0.

    fsum(seq, /)
        Return an accurate floating point sum of values in the iterable seq.

        Assumes IEEE-754 floating point arithmetic.

    gamma(x, /)
        Gamma function at x.

    gcd(*integers)
        Greatest Common Divisor.

    hypot(...)
        hypot(*coordinates) -> value

        Multidimensional Euclidean distance from the origin to a point.

        Roughly equivalent to:
            sqrt(sum(x**2 for x in coordinates))

        For a two dimensional point (x, y), gives the hypotenuse
        using the Pythagorean theorem:  sqrt(x*x + y*y).

        For example, the hypotenuse of a 3/4/5 right triangle is:

            >>> hypot(3.0, 4.0)
            5.0

    isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)
        Determine whether two floating point numbers are close in value.

          rel_tol
            maximum difference for being considered "close", relative to the
            magnitude of the input values
          abs_tol
            maximum difference for being considered "close", regardless of the
            magnitude of the input values

        Return True if a is close in value to b, and False otherwise.

        For the values to be considered close, the difference between them
        must be smaller than at least one of the tolerances.

        -inf, inf and NaN behave similarly to the IEEE 754 Standard.  That
        is, NaN is not close to anything, even itself.  inf and -inf are
        only close to themselves.

    isfinite(x, /)
        Return True if x is neither an infinity nor a NaN, and False otherwise.

    isinf(x, /)
        Return True if x is a positive or negative infinity, and False otherwise.

    isnan(x, /)
        Return True if x is a NaN (not a number), and False otherwise.

    isqrt(n, /)
        Return the integer part of the square root of the input.

    lcm(*integers)
        Least Common Multiple.

    ldexp(x, i, /)
        Return x * (2**i).

        This is essentially the inverse of frexp().

    lgamma(x, /)
        Natural logarithm of absolute value of Gamma function at x.

    log(...)
        log(x, [base=math.e])
        Return the logarithm of x to the given base.

        If the base not specified, returns the natural logarithm (base e) of x.

    log10(x, /)
        Return the base 10 logarithm of x.

    log1p(x, /)
        Return the natural logarithm of 1+x (base e).

        The result is computed in a way which is accurate for x near zero.

    log2(x, /)
        Return the base 2 logarithm of x.

    modf(x, /)
        Return the fractional and integer parts of x.

        Both results carry the sign of x and are floats.

    nextafter(x, y, /)
        Return the next floating-point value after x towards y.

    perm(n, k=None, /)
        Number of ways to choose k items from n items without repetition and with order.

        Evaluates to n! / (n - k)! when k <= n and evaluates
        to zero when k > n.

        If k is not specified or is None, then k defaults to n
        and the function returns n!.

        Raises TypeError if either of the arguments are not integers.
        Raises ValueError if either of the arguments are negative.

    pow(x, y, /)
        Return x**y (x to the power of y).

    prod(iterable, /, *, start=1)
        Calculate the product of all the elements in the input iterable.

        The default start value for the product is 1.

        When the iterable is empty, return the start value.  This function is
        intended specifically for use with numeric values and may reject
        non-numeric types.

    radians(x, /)
        Convert angle x from degrees to radians.

    remainder(x, y, /)
        Difference between x and the closest integer multiple of y.

        Return x - n*y where n*y is the closest integer multiple of y.
        In the case where x is exactly halfway between two multiples of
        y, the nearest even value of n is used. The result is always exact.

    sin(x, /)
        Return the sine of x (measured in radians).

    sinh(x, /)
        Return the hyperbolic sine of x.

    sqrt(x, /)
        Return the square root of x.

    tan(x, /)
        Return the tangent of x (measured in radians).

    tanh(x, /)
        Return the hyperbolic tangent of x.

    trunc(x, /)
        Truncates the Real x to the nearest Integral toward 0.

        Uses the __trunc__ magic method.

    ulp(x, /)
        Return the value of the least significant bit of the float x.

DATA
    e = 2.718281828459045
    inf = inf
    nan = nan
    pi = 3.141592653589793
    tau = 6.283185307179586

FILE
    /data/data/com.termux/files/usr/lib/python3.10/lib-dynload/math.cpython-310.so

]]

]]]
[[[
fractions
===
view ~/../usr/lib/python3.10/fractions.py
cp ~/../usr/lib/python3.10/fractions.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/fractions.py



math.gcd
fractions.Fraction

显示:
    __repr__
        "-> 'Fraction(0, 1)'"
    __str__
        "-> '3' | '-3/4'"
分量:
    .as_integer_ratio()
    .numerator
    .denominator
构造器:
  cls..from_float
  cls.from_decimal
  Fraction(numerator=0, denominator=None, /)
    :: numerator/Rational -> denominator/Rational -> Fraction
    :: Rational -> Fraction
        .numerator
        .denominator
    :: (Decimal|float) -> Fraction
        .as_integer_ratio()
    :: str -> Fraction
        '3/4'
        '3.4'
        '3e4'
        ===
        '  -3   '
        '  -3/4   '
        ===
        '  -3.4   '
        '  -3.   '
        '  -.4   '
        '  -3.4e-5   '




#limit_denominator
>>> Fraction('3.141592653589793').limit_denominator(10)
Fraction(22, 7)
>>> Fraction('3.141592653589793').limit_denominator(100)
Fraction(311, 99)
>>> Fraction(4321, 8765).limit_denominator(10000)
Fraction(4321, 8765)


#构造器
>>> Fraction(10, -8)
Fraction(-5, 4)
>>> Fraction(Fraction(1, 7), 5)
Fraction(1, 35)
>>> Fraction(Fraction(1, 7), Fraction(2, 3))
Fraction(3, 14)
>>> Fraction('314')
Fraction(314, 1)
>>> Fraction('-35/4')
Fraction(-35, 4)
>>> Fraction('3.1415') # conversion from numeric string
Fraction(6283, 2000)
>>> Fraction('-47e-2') # string may include a decimal exponent
Fraction(-47, 100)
>>> Fraction(1.47)  # direct construction from float (exact conversion)
Fraction(6620291452234629, 4503599627370496)
>>> Fraction(2.25)
Fraction(9, 4)
>>> Fraction(Decimal('1.47'))
Fraction(147, 100)


# Constants related to the hash implementation;  hash(x) is based
# on the reduction of x modulo the prime _PyHASH_MODULUS.
_PyHASH_MODULUS = sys.hash_info.modulus
# Value to be used for rationals that reduce to infinity modulo
# _PyHASH_MODULUS.
_PyHASH_INF = sys.hash_info.inf

bug:效率不对:__floordiv__/__mod__/__divmod__:应当与__mul__/__truediv__类似
not-bug:逻辑无错:__mod__/__divmod__:lhs%rhs = lhs-(lhs//rhs)*rhs = na/da-(na*db)//(nb*da) *nb/db = (na*db-(na*db)//(nb*da) *nb*da)/(da*db) = (na*db)%(nb*da)/(da*db)

class Fraction(numbers.Rational):
    #分数加减乘除囗可以更快点:goto
    def __new__(cls, numerator=0, denominator=None, *, _normalize=True):
    @classmethod
    def from_float(cls, f):
    @classmethod
    def from_decimal(cls, dec):
    def as_integer_ratio(self):
        return (self._numerator, self._denominator)
    def limit_denominator(self, max_denominator=1000000):
        'Closest Fraction to self with denominator at most max_denominator.'
        连分数
    @property
    def numerator(a):
    @property
    def denominator(a):
    def __repr__(self):
        "-> 'Fraction(0, 1)'"
    def __str__(self):
        "-> '3' | '-3/4'"
    def _operator_fallbacks(monomorphic_operator, fallback_operator):
        '辅助 二元运算+反向二元运算'
    ###############################
    #分数加减乘除囗可以更快点:goto
    __add__, __radd__ = _operator_fallbacks(_add, operator.add)
    __sub__, __rsub__ = _operator_fallbacks(_sub, operator.sub)
    __mul__, __rmul__ = _operator_fallbacks(_mul, operator.mul)
    __truediv__, __rtruediv__ = _operator_fallbacks(_div, operator.truediv)
    __floordiv__, __rfloordiv__ = _operator_fallbacks(_floordiv, operator.floordiv)
    __divmod__, __rdivmod__ = _operator_fallbacks(_divmod, divmod)
    __mod__, __rmod__ = _operator_fallbacks(_mod, operator.mod)
    def __pow__(a, b):
    def __rpow__(a, b):
    def __pos__(a):
    def __neg__(a):
    def __abs__(a):
    def __trunc__(a):
    def __floor__(a):
    def __ceil__(a):
    def __round__(self, ndigits=None):
    def __hash__(self):
    def __eq__(a, b):
    def _richcmp(self, other, op):
    def __lt__(a, b):
    def __gt__(a, b):
    def __le__(a, b):
    def __ge__(a, b):
    def __bool__(a):
    def __reduce__(self):
    def __copy__(self):
    def __deepcopy__(self, memo):



    ###############################
    #分数加减乘除囗可以更快点
    # Rational arithmetic algorithms: Knuth, TAOCP, Volume 2, 4.5.1.
    #
    # Assume input fractions a and b are normalized.
    #
    # 1) Consider addition/subtraction.
    #
    # Let g = gcd(da, db). Then
    #
    #              na   nb    na*db ± nb*da
    #     a ± b == -- ± -- == ------------- ==
    #              da   db        da*db
    #
    #              na*(db//g) ± nb*(da//g)    t
    #           == ----------------------- == -
    #                      (da*db)//g         d
    #
    # Now, if g > 1, we're working with smaller integers.
    #
    # Note, that t, (da//g) and (db//g) are pairwise coprime.
    #
    # Indeed, (da//g) and (db//g) share no common factors (they were
    # removed) and da is coprime with na (since input fractions are
    # normalized), hence (da//g) and na are coprime.  By symmetry,
    # (db//g) and nb are coprime too.  Then,
    #
    #     gcd(t, da//g) == gcd(na*(db//g), da//g) == 1
    #     gcd(t, db//g) == gcd(nb*(da//g), db//g) == 1
    #
    # Above allows us optimize reduction of the result to lowest
    # terms.  Indeed,
    #
    #     g2 = gcd(t, d) == gcd(t, (da//g)*(db//g)*g) == gcd(t, g)
    #
    #                       t//g2                   t//g2
    #     a ± b == ----------------------- == ----------------
    #              (da//g)*(db//g)*(g//g2)    (da//g)*(db//g2)
    #
    # is a normalized fraction.  This is useful because the unnormalized
    # denominator d could be much larger than g.
    #
    # We should special-case g == 1 (and g2 == 1), since 60.8% of
    # randomly-chosen integers are coprime:
    # https://en.wikipedia.org/wiki/Coprime_integers#Probability_of_coprimality
    # Note, that g2 == 1 always for fractions, obtained from floats: here
    # g is a power of 2 and the unnormalized numerator t is an odd integer.
    #
    # 2) Consider multiplication
    #
    # Let g1 = gcd(na, db) and g2 = gcd(nb, da), then
    #
    #            na*nb    na*nb    (na//g1)*(nb//g2)
    #     a*b == ----- == ----- == -----------------
    #            da*db    db*da    (db//g1)*(da//g2)
    #
    # Note, that after divisions we're multiplying smaller integers.
    #
    # Also, the resulting fraction is normalized, because each of
    # two factors in the numerator is coprime to each of the two factors
    # in the denominator.
    #
    # Indeed, pick (na//g1).  It's coprime with (da//g2), because input
    # fractions are normalized.  It's also coprime with (db//g1), because
    # common factors are removed by g1 == gcd(na, db).
    #
    # As for addition/subtraction, we should special-case g1 == 1
    # and g2 == 1 for same reason.  That happens also for multiplying
    # rationals, obtained from floats.

    def _add(a, b):
        """a + b"""
        na, da = a.numerator, a.denominator
        nb, db = b.numerator, b.denominator
        g = math.gcd(da, db)
        if g == 1:
            return Fraction(na * db + da * nb, da * db, _normalize=False)
        s = da // g
        t = na * (db // g) + nb * s
        g2 = math.gcd(t, g)
        if g2 == 1:
            return Fraction(t, s * db, _normalize=False)
        return Fraction(t // g2, s * (db // g2), _normalize=False)

    __add__, __radd__ = _operator_fallbacks(_add, operator.add)

    def _sub(a, b):
        """a - b"""
    __sub__, __rsub__ = _operator_fallbacks(_sub, operator.sub)

    def _mul(a, b):
        """a * b"""
        na, da = a.numerator, a.denominator
        nb, db = b.numerator, b.denominator
        g1 = math.gcd(na, db)
        if g1 > 1:
            na //= g1
            db //= g1
        g2 = math.gcd(nb, da)
        if g2 > 1:
            nb //= g2
            da //= g2
        return Fraction(na * nb, db * da, _normalize=False)

    __mul__, __rmul__ = _operator_fallbacks(_mul, operator.mul)

    def _div(a, b):
        """a / b"""
    __truediv__, __rtruediv__ = _operator_fallbacks(_div, operator.truediv)

    def _floordiv(a, b):
        """a // b"""
    __floordiv__, __rfloordiv__ = _operator_fallbacks(_floordiv, operator.floordiv)

    def _divmod(a, b):
        """(a // b, a % b)"""
    __divmod__, __rdivmod__ = _operator_fallbacks(_divmod, divmod)

    def _mod(a, b):
        """a % b"""
    __mod__, __rmod__ = _operator_fallbacks(_mod, operator.mod)

    def __pow__(a, b):
        """a ** b

        If b is not an integer, the result will be a float or complex
        since roots are generally irrational. If b is an integer, the
        result will be rational.

        """
        if isinstance(b, numbers.Rational):
            if b.denominator == 1:
                power = b.numerator
                if power < 0:
                    power = -power
                    a = 1/a
                      #handle sign[+-]
                return Fraction(a._numerator ** power,
                                a._denominator ** power,
                                _normalize=False)
            else:
                # A fractional power will generally produce an
                # irrational number.
                return float(a) ** float(b)
        else:
            return float(a) ** b

    def __rpow__(b, a):
        """a ** b"""
        if b._denominator == 1 and b._numerator >= 0:
            # If a is an int, keep it that way if possible.
            return a ** b._numerator

        if isinstance(a, numbers.Rational):
            return Fraction(a.numerator, a.denominator) ** b

        if b._denominator == 1:
            return a ** b._numerator

        return a ** float(b)

    def __pos__(a):
        """+a: Coerces a subclass instance to Fraction"""
        return Fraction(a._numerator, a._denominator, _normalize=False)

    def __neg__(a):
        """-a"""
        return Fraction(-a._numerator, a._denominator, _normalize=False)

    def __abs__(a):
        """abs(a)"""
        return Fraction(abs(a._numerator), a._denominator, _normalize=False)

    def __trunc__(a):
        """trunc(a)"""
        if a._numerator < 0:
            return -(-a._numerator // a._denominator)
        else:
            return a._numerator // a._denominator

    def __floor__(a):
        """math.floor(a)"""
        return a.numerator // a.denominator

    def __ceil__(a):
        """math.ceil(a)"""
        # The negations cleverly convince floordiv to return the ceiling.
        return -(-a.numerator // a.denominator)

    def __round__(self, ndigits=None):
        """round(self, ndigits)

        Rounds half toward even.
        """
        if ndigits is None:
            floor, remainder = divmod(self.numerator, self.denominator)
            if remainder * 2 < self.denominator:
                return floor
            elif remainder * 2 > self.denominator:
                return floor + 1
            # Deal with the half case:
            elif floor % 2 == 0:
                return floor
            else:
                return floor + 1
        shift = 10**abs(ndigits)
        # See _operator_fallbacks.forward to check that the results of
        # these operations will always be Fraction and therefore have
        # round().
        if ndigits > 0:
            return Fraction(round(self * shift), shift)
        else:
            return Fraction(round(self / shift) * shift)

    def __hash__(self):
        """hash(self)"""

        # To make sure that the hash of a Fraction agrees with the hash
        # of a numerically equal integer, float or Decimal instance, we
        # follow the rules for numeric hashes outlined in the
        # documentation.  (See library docs, 'Built-in Types').

        try:
            dinv = pow(self._denominator, -1, _PyHASH_MODULUS)
        except ValueError:
            # ValueError means there is no modular inverse.
            hash_ = _PyHASH_INF
        else:
            # The general algorithm now specifies that the absolute value of
            # the hash is
            #    (|N| * dinv) % P
            # where N is self._numerator and P is _PyHASH_MODULUS.  That's
            # optimized here in two ways:  first, for a non-negative int i,
            # hash(i) == i % P, but the int hash implementation doesn't need
            # to divide, and is faster than doing % P explicitly.  So we do
            #    hash(|N| * dinv)
            # instead.  Second, N is unbounded, so its product with dinv may
            # be arbitrarily expensive to compute.  The final answer is the
            # same if we use the bounded |N| % P instead, which can again
            # be done with an int hash() call.  If 0 <= i < P, hash(i) == i,
            # so this nested hash() call wastes a bit of time making a
            # redundant copy when |N| < P, but can save an arbitrarily large
            # amount of computation for large |N|.
            hash_ = hash(hash(abs(self._numerator)) * dinv)
        result = hash_ if self._numerator >= 0 else -hash_
        return -2 if result == -1 else result

    def __eq__(a, b):
        """a == b"""
        if type(b) is int:
            return a._numerator == b and a._denominator == 1
        if isinstance(b, numbers.Rational):
            return (a._numerator == b.numerator and
                    a._denominator == b.denominator)
        if isinstance(b, numbers.Complex) and b.imag == 0:
            b = b.real
        if isinstance(b, float):
            if math.isnan(b) or math.isinf(b):
                # comparisons with an infinity or nan should behave in
                # the same way for any finite a, so treat a as zero.
                return 0.0 == b
            else:
                return a == a.from_float(b)
        else:
            # Since a doesn't know how to compare with b, let's give b
            # a chance to compare itself with a.
            return NotImplemented

    def _richcmp(self, other, op):
        """Helper for comparison operators, for internal use only.

        Implement comparison between a Rational instance `self`, and
        either another Rational instance or a float `other`.  If
        `other` is not a Rational instance or a float, return
        NotImplemented. `op` should be one of the six standard
        comparison operators.

        """
        # convert other to a Rational instance where reasonable.
        if isinstance(other, numbers.Rational):
            return op(self._numerator * other.denominator,
                      self._denominator * other.numerator)
        if isinstance(other, float):
            if math.isnan(other) or math.isinf(other):
                return op(0.0, other)
            else:
                return op(self, self.from_float(other))
        else:
            return NotImplemented

    def __lt__(a, b):
        """a < b"""
        return a._richcmp(b, operator.lt)

    def __gt__(a, b):
        """a > b"""
        return a._richcmp(b, operator.gt)

    def __le__(a, b):
        """a <= b"""
        return a._richcmp(b, operator.le)

    def __ge__(a, b):
        """a >= b"""
        return a._richcmp(b, operator.ge)

    def __bool__(a):
        """a != 0"""
        # bpo-39274: Use bool() because (a._numerator != 0) can return an
        # object which is not a bool.
        return bool(a._numerator)

    # support for pickling, copy, and deepcopy

    def __reduce__(self):
        return (self.__class__, (str(self),))

    def __copy__(self):
        if type(self) == Fraction:
            return self     # I'm immutable; therefore I am my own clone
        return self.__class__(self._numerator, self._denominator)

    def __deepcopy__(self, memo):
        if type(self) == Fraction:
            return self     # My components are also immutable
        return self.__class__(self._numerator, self._denominator)



    ###############################
    def limit_denominator(self, max_denominator=1000000):
        """Closest Fraction to self with denominator at most max_denominator.

        >>> Fraction('3.141592653589793').limit_denominator(10)
        Fraction(22, 7)
        >>> Fraction('3.141592653589793').limit_denominator(100)
        Fraction(311, 99)
        >>> Fraction(4321, 8765).limit_denominator(10000)
        Fraction(4321, 8765)

        """
        # Algorithm notes: For any real number x, define a *best upper
        # approximation* to x to be a rational number p/q such that:
        #
        #   (1) p/q >= x, and
        #   (2) if p/q > r/s >= x then s > q, for any rational r/s.
        #
        # Define *best lower approximation* similarly.  Then it can be
        # proved that a rational number is a best upper or lower
        # approximation to x if, and only if, it is a convergent or
        # semiconvergent of the (unique shortest) continued fraction
        # associated to x.
        #
        # To find a best rational approximation with denominator <= M,
        # we find the best upper and lower approximations with
        # denominator <= M and take whichever of these is closer to x.
        # In the event of a tie, the bound with smaller denominator is
        # chosen.  If both denominators are equal (which can happen
        # only when max_denominator == 1 and self is midway between
        # two integers) the lower bound---i.e., the floor of self, is
        # taken.

        if max_denominator < 1:
            raise ValueError("max_denominator should be at least 1")
        if self._denominator <= max_denominator:
            return Fraction(self)

        p0, q0, p1, q1 = 0, 1, 1, 0
        n, d = self._numerator, self._denominator
        while True:
            a = n//d
            q2 = q0+a*q1
            if q2 > max_denominator:
                break
            p0, q0, p1, q1 = p1, q1, p0+a*p1, q2
            n, d = d, n-a*d

        k = (max_denominator-q0)//q1
        bound1 = Fraction(p0+k*p1, q0+k*q1)
        bound2 = Fraction(p1, q1)
        if abs(bound2 - self) <= abs(bound1-self):
            return bound2
        else:
            return bound1

    ###############################
    def _operator_fallbacks(monomorphic_operator, fallback_operator):
        """Generates forward and reverse operators given a purely-rational
        operator and a function from the operator module.

        Use this like:
        __op__, __rop__ = _operator_fallbacks(just_rational_op, operator.op)

        In general, we want to implement the arithmetic operations so
        that mixed-mode operations either call an implementation whose
        author knew about the types of both arguments, or convert both
        to the nearest built in type and do the operation there. In
        Fraction, that means that we define __add__ and __radd__ as:

            def __add__(self, other):
                # Both types have numerators/denominator attributes,
                # so do the operation directly
                if isinstance(other, (int, Fraction)):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                # float and complex don't have those operations, but we
                # know about those types, so special case them.
                elif isinstance(other, float):
                    return float(self) + other
                elif isinstance(other, complex):
                    return complex(self) + other
                # Let the other type take over.
                return NotImplemented

            def __radd__(self, other):
                # radd handles more types than add because there's
                # nothing left to fall back to.
                if isinstance(other, numbers.Rational):
                    return Fraction(self.numerator * other.denominator +
                                    other.numerator * self.denominator,
                                    self.denominator * other.denominator)
                elif isinstance(other, Real):
                    return float(other) + float(self)
                elif isinstance(other, Complex):
                    return complex(other) + complex(self)
                return NotImplemented


        There are 5 different cases for a mixed-type addition on
        Fraction. I'll refer to all of the above code that doesn't
        refer to Fraction, float, or complex as "boilerplate". 'r'
        will be an instance of Fraction, which is a subtype of
        Rational (r : Fraction <: Rational), and b : B <:
        Complex. The first three involve 'r + b':

            1. If B <: Fraction, int, float, or complex, we handle
               that specially, and all is well.
            2. If Fraction falls back to the boilerplate code, and it
               were to return a value from __add__, we'd miss the
               possibility that B defines a more intelligent __radd__,
               so the boilerplate should return NotImplemented from
               __add__. In particular, we don't handle Rational
               here, even though we could get an exact answer, in case
               the other type wants to do something special.
            3. If B <: Fraction, Python tries B.__radd__ before
               Fraction.__add__. This is ok, because it was
               implemented with knowledge of Fraction, so it can
               handle those instances before delegating to Real or
               Complex.

        The next two situations describe 'b + r'. We assume that b
        didn't know about Fraction in its implementation, and that it
        uses similar boilerplate code:

            4. If B <: Rational, then __radd_ converts both to the
               builtin rational type (hey look, that's us) and
               proceeds.
            5. Otherwise, __radd__ tries to find the nearest common
               base ABC, and fall back to its builtin type. Since this
               class doesn't subclass a concrete type, there's no
               implementation to fall back to, so we need to try as
               hard as possible to return an actual value, or the user
               will get a TypeError.

        """
        def forward(a, b):
            if isinstance(b, (int, Fraction)):
                return monomorphic_operator(a, b)
            elif isinstance(b, float):
                return fallback_operator(float(a), b)
            elif isinstance(b, complex):
                return fallback_operator(complex(a), b)
            else:
                return NotImplemented
        forward.__name__ = '__' + fallback_operator.__name__ + '__'
        forward.__doc__ = monomorphic_operator.__doc__

        def reverse(b, a):
            if isinstance(a, numbers.Rational):
                # Includes ints.
                return monomorphic_operator(a, b)
            elif isinstance(a, numbers.Real):
                return fallback_operator(float(a), float(b))
            elif isinstance(a, numbers.Complex):
                return fallback_operator(complex(a), complex(b))
            else:
                return NotImplemented
        reverse.__name__ = '__r' + fallback_operator.__name__ + '__'
        reverse.__doc__ = monomorphic_operator.__doc__

        return forward, reverse
    ###############################


]]]
[[[
io
io__newline__newlines:goto
===
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/io.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/io.html > $my_tmp/out4py/html2text/py_38_doc/io.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/io.html.txt


# only the arguments of open() are intended to be used as keyword arguments.
# calling any method (even inquiries) on a closed stream is undefined.  Implementations may raise ValueError in this case.
#
IOBase
  TextIOBase<BufferedIOBase>
    TextIOWrapper
    StringIO
    open("myfile.txt", "r", encoding="utf-8")
  BufferedIOBase<RawIOBase>
    BufferedWriter
    BufferedReader
    BufferedRWPair
    BufferedRandom
      BytesIO
      open("myfile.jpg", "rb")
  RawIOBase
    FileIO
    open("myfile.jpg", "rb", buffering=0)

io.DEFAULT_BUFFER_SIZE
  open() uses the file’s blksize (as obtained by os.stat()) if possible.
io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)

OSError, IOError, ValueError
BlockingIOError
UnsupportedOperation <: OSError&ValueError
  #or raise ValueError
  istream.write
  ostream.read
  .seek
  ...

sys.stdin
sys.stdout
sys.stderr



ABC <: Inherits
  Stub Methods
  Mixin Methods and Properties

IOBase <: ()
  fileno, seek, truncate
  close, closed, __enter__, __exit__, flush, isatty, __iter__, __next__, readable, readline, readlines, seekable, tell, writable, writelines
  #__iter__/readlines <<== readline -> bytes/str
RawIOBase <: IOBase
  readinto, write
  Inherited IOBase methods, read, readall

BufferedIOBase <: IOBase
  detach, read, read1, write
  Inherited IOBase methods, readinto, readinto1

TextIOBase <: IOBase
  detach, read, readline, write
  Inherited IOBase methods, encoding, errors, newlines


write/read:
    RawIOBase
    BufferedIOBase
    TextIOBase

readinto:
    RawIOBase
    BufferedIOBase
detach:
    BufferedIOBase
    TextIOBase

readall:
    RawIOBase
read1/readinto1:
    BufferedIOBase
encoding/errors/newlines:
    TextIOBase



io__newline__newlines:goto

[[
IOBase <: ()
no public constructor

close()¶
  allow called more than once
closed :: bool
  True => [read()... will undefined/raise ValueError]
fileno() -> file_descriptor|^OSError-not-file|^ValueError-closed
flush() -> None|^BlockingIOError-raw-stream-block|^UnsupportedOperation-not-writable|^ValueError-closed
isatty() -> bool|^ValueError-closed
  [the stream is interactive (i.e., connected to a terminal/tty device)]
  TTY???interactive terminal
  TTY - teletypewriter
    1 电传打字电报机
    2 印刷电信机
    n. 电传打字机

readable() -> bool|^ValueError
  False => [read*() will raise OSError/io.UnsupportedOperation]

readline(size=-1) -> bs_cs|^UnsupportedOperation-not-readable|^ValueError-closed
  at most size (in bytes/characters) will be read
    xxx at most size bytes will be read #???not-(in bytes/characters)
    见下面:TextIOBase.readline，计数单位是字符，非字节
  binary file line_sep===b'\n'
  text file line_sep <<== open(newline=...)
        #readline(1)@<eof change tell()result
        #readline()@>=eof not change tell()result
        #readline(0) not change tell()result
        #readline(<0) <==> readline(None) <==> readline()
        #binary file line_sep===b'\n'
        #text file line_sep <<== open(newline=...)

readlines(hint=-1) -> [bs_cs]/list<xstring>|^UnsupportedOperation-not-readable|^ValueError-closed
  no more lines will be read if the total size (in bytes/characters) of all lines so far exceeds hint.
  #see: __iter__
        #readlines()@>=eof --> []
        #readlines(>0) ==>> readline(-1) until new_location4tell-old_location4tell>=hint
        #readlines() <==> readlines(0) <==> readlines(<0) <==> readlines(None)

seek(offset, whence=SEEK_SET) -> new absolute position|^UnsupportedOperation-not-seekable|^ValueError-closed
        #seek:[new_location4tell>sz4file] is ok
        #seek:[seek:new_location4tell<0]@SEEK_SET ==>> ^ValueError
        #seek:[new_location4tell<0]@SEEK_CUR/SEEK_END <==> [new_location4tell==0]
        #seek:using operator.__index__ to convert 2 input: `offset` & `whence`
  #os.***
  SEEK_SET or 0 – start of the stream (the default);
    offset :: uint
  SEEK_CUR or 1 – current stream position;
    offset :: int
  SEEK_END or 2 – end of the stream;
  offset :: nint

seekable() -> bool|^ValueError
  [stream supports random access]
  False => [seek(), tell(), truncate() will raise OSError/io.UnsupportedOperation]

tell() -> current stream position|^UnsupportedOperation-not-seekable|^ValueError-closed

truncate(size=None)-> new file size|^UnsupportedOperation-not-seekable&writable|^ValueError-closed
  size=None => size=current position
  extend or reduce the current file size
    padding <<== platform specified
        #truncate(None) <==> truncate(tell())
        #truncate(>=sz4file) <==> no-op echo
        #truncate(<0) --> ^ValueError
        #truncate() not change tell()result


writable() -> bool|^ValueError
  False => [write*(), truncate() will raise OSError/io.UnsupportedOperation]



writelines(lines/Iter<xstring>) -> None|^UnsupportedOperation-not-writable|^ValueError-closed
  #writelines() doesnot add line_sep
        #writelines(Iter<bytes_like_object>) -> None
        #writelines(...) no extra newline inserted
        #writelines(...) no padding on write empty bytes
        #writelines(...) padding on write nonempty bytes

__iter__
  return sf
__next__
  return sf.readline(-1) if result else ^StopIteration

__del__()¶
  call .close()
]]
[[
RawIOBase <: IOBase
no public constructor
except readall: read/readinto/write => at most only one system call is ever made

read(size=-1) -> None|bytes{.len<=size}
  default => read all
  nondefault => only one system call is ever made
    ???why???since『raw』???
      yes!BufferedIOBase.read uses multiple system calls
  [result==b''][not size==0] => EOF
  [non-blocking mode][no bytes available] <==> [result is None]
  <<== readall+readinto


readall() -> bytes
  multiple system calls until EOF


readinto(b) -> may num_bytes
  b :: pre-allocated-writable-bytearray
  [non-blocking mode][no bytes available] <==> [result is None]
  only one system call is ever made


write(b) -> may num_bytes
  [non-blocking mode][no single byte could be readily written] <==> [result is None]
  [num_bytes <= len(b)]
  only one system call is ever made


]]
[[
BufferedIOBase <: IOBase
no public constructor
read/readinto/write => multiple system call is made, greedy
  read1/readinto1/no-write1 => at most only one system call is ever made
      相当于 RawIOBase.read/readinto/write
  [raise ^BlockingIOError] <==> [non-blocking mode][non-blocking mode][cannot take or give enough data unless TTY/isatty]
      [数据不足够]#all
        相当于 RawIOBase.read/readinto/write [一点点数据也没消耗]#any
      [raise ^BlockingIOError]
        相当于 RawIOBase.read/readinto/write [return None]

[nonstd].raw :: RawIOBase


detach() -> the underlying raw stream|^UnsupportedOperation-no-raw-stream
  postcondition:[self unusable]


read(size=-1) -> bytes{.len<=size}|^BlockingIOError|^UnsupportedOperation-not-readable|^ValueError-closed
  default => read all
  EOF => [result==b'']
  [size>0][not isatty] => [multiple raw reads until size or EOF]
  [not isatty][len(result) < size)] => EOF
  [isatty] => [at most one raw read]
  [len(result) < size] => [[isatty]or[EOF]]
  [non blocking-mode][no data available] => [raise ^BlockingIOError]
  ==>>:
    [0 == len(result) < size)] => EOF
      !!!OK!!!




read1([size]) -> ?may? bytes|???^BlockingIOError???|^UnsupportedOperation-not-readable|^ValueError-closed
  <==> .raw.read(size)
  ???奇怪！不清楚:是否可能>None，还是^BlockingIOError
    相比readinto1 明确是 ^BlockingIOError 而非>None



readinto(b) -> num_bytes|^BlockingIOError|^UnsupportedOperation-not-readable|^ValueError-closed
  b :: pre-allocated-writable-bytearray
  invariants like read()



readinto1(b) -> num_bytes|^BlockingIOError|^UnsupportedOperation-not-readable|^ValueError-closed
  <==> .raw.readinto(b) 只是 >None变^BlockingIOError



write(b) -> num_bytes{===len(b)}|^OSError-not-write-all|^BlockingIOError-require-blocking|^UnsupportedOperation-not-writable|^ValueError-closed
  [non blocking-mode][couldnot accept all the data without blocking] => [raise ^BlockingIOError]
  #... [non blocking-mode][raw stream block] => [raise ^BlockingIOError]


]]
[[
FileIO <: RawIOBase
FileIO(name, mode='r', closefd=True, opener=None)
  public constructor
  name :: path | fd
    path :: bytes|str|Path?...
      ==>> [closefd==True]
    fd :: int #OS-level file descriptor
    def close():
      if .closefd:
        .fd->close()

.name :: path | fd
.mode :: str
  regex'[rwxa][+]?'
  'r', 'w', 'x' or 'a' for reading (default), writing, exclusive creation or appending
  Add a '+' to the mode to allow simultaneous reading and writing.


]]
[[
BytesIO <: BufferedIOBase
BytesIO([initial_bytes])
  public constructor

getbuffer() -> buffer<byte>/?bytearray?

getvalue() -> bytes
  <==> bytes(.getbuffer())

read1([size]) -> bytes
  <==> .read(size)
  因为不存在更低层，也就无所谓『最多一次系统调用』
readinto1(b) -> num_bytes
  <==> .readinto(size)

]]
[[
BufferedReader <: BufferedIOBase
BufferedReader(raw, buffer_size=DEFAULT_BUFFER_SIZE)
  public constructor
  raw :: readable-sequential-RawIOBase
    #不需要writable,seekable

peek([size]) -> bytes
  [at most one single read on the raw stream is done]
  [without advancing the position]

  [len(result) <???> size]arbitrary
    [The number of bytes returned may be less or more than requested]
    size有什么用？



read([size]) -> bytes{.len<=size}|^UnsupportedOperation-not-readable|^ValueError-closed
  [pseudo_EOF4nonblocking_mode =[def]= the read call would block in non-blocking mode]
  [EOF_ex =[def]= EOF or pseudo_EOF4nonblocking_mode]

  default => read until EOF_ex
  nondefault => [not[len(result)==size]] -> [len(result) < size][EOF_ex]
    #没了:^BlockingIOError



read1([size]) -> ?may? bytes|???^BlockingIOError???|^UnsupportedOperation-not-readable|^ValueError-closed
  [len(cached)>0] => [result:=cached[:size]]
  [len(cached)==0] => [result:=.raw.read(size)]



]]
[[
BufferedWriter <: BufferedIOBase
BufferedWriter(raw, buffer_size=DEFAULT_BUFFER_SIZE)
  public constructor
  raw :: writable-sequential-RawIOBase
    #不需要readable,seekable

flush() -> None|^BlockingIOError-raw-stream-block|^UnsupportedOperation-not-writable|^ValueError-closed
  move cached bytes to raw stream



#完全同上BufferedIOBase.write
write(b) -> num_bytes{===len(b)}|^OSError-not-write-all|^BlockingIOError-require-blocking|^UnsupportedOperation-not-writable|^ValueError-closed
  [non blocking-mode][couldnot accept all the data without blocking] => [raise ^BlockingIOError]
  #... [non blocking-mode][raw stream block] => [raise ^BlockingIOError]


]]
[[
BufferedRandom <: BufferedReader&BufferedWriter <: BufferedIOBase
BufferedRandom(raw, buffer_size=DEFAULT_BUFFER_SIZE)
  public constructor
  raw :: seekable-RawIOBase
    #不需要readable,writable#-sequential
    #   或者说 任意组合readable,writable

seek() and tell() are guaranteed to be implemented.


]]
[[
BufferedRWPair <: BufferedIOBase
BufferedRWPair(reader, writer, buffer_size=DEFAULT_BUFFER_SIZE)
  two unidirectional RawIOBase -> single bidirectional endpoint
  public constructor

detach() -> ^UnsupportedOperation
必须是两个raw_stream，不可seek,tell
  因为不处理两个cache的同步问题
  否则当用BufferedRandom而非BufferedRWPair


]]
[[
TextIOBase <: IOBase
no public constructor

encoding :: may str

errors :: ?str?
  The error setting of the decoder or encoder.

newlines :: None|str|tuple<str>
  this may not be available

[nonstd].buffer :: BufferedIOBase
  the underlying binary buffer

detach() -> buffer/BufferedIOBase|^UnsupportedOperation
  postcondition:[self unusable]

read(size=-1) -> str{.len<=size}
  default => EOF

readline(size=-1) -> str{.len<=size}
  default => read until newline or EOF
  nondefault => read until newline or EOF or size

seek(offset, whence=SEEK_SET) -> new absolute position/opaque_number{#比如说是idx4bytes,而非idx4chars；还可能含有语境敏感的解码信息#}
  SEEK_SET:
    offset :: 0 | result5tell
      otherwise => undefined behaviour
  SEEK_CUR:
    offset === 0
      otherwise => undefined behaviour
    <==> no-operation
  SEEK_END:
    offset === 0
      otherwise => undefined behaviour
    <==> seek to end


tell() -> current stream position/opaque_number
  The number does not usually represent a number of bytes in the underlying binary storage.



write(s) -> num_chars


]]
[[
TextIOWrapper <: TextIOBase
TextIOWrapper(buffer, encoding=None, errors=None, newline=None, line_buffering=False, write_through=False)
  public constructor
  [
  buffer :: BufferedIOBase
    BufferedIOBase:buffered binary stream
    TextIOWrapper:buffered text stream

  encoding :: may str
    default => locale.getpreferredencoding(False)

  errors :: may str
    default => 'strict'
    'strict' to raise a ValueError if encoding error
    'ignore' to ignore errors
    'replace' causes a replacement marker (such as '?') to be inserted where there is malformed data
    'backslashreplace' causes malformed data to be replaced by a backslashed escape sequence

    When writing:
      'xmlcharrefreplace' (replace with the appropriate XML character reference)
      'namereplace' (replace with \N{...} escape sequences)

    other error handling names:
      codecs.register_error()

  newline :: may str
    newline <- [None, '', '\n', '\r', '\r\n']
    [reading][newline=None]:
        enabled universal newlines mode
          lines in the input can end in '\n', '\r', or '\r\n'
        line endings are translated into '\n'

    [reading][newline='']:
        enabled universal newlines mode
          lines in the input can end in '\n', '\r', or '\r\n'
        line endings are returned to the caller untranslated

    [reading][newline <- ['\n', '\r', '\r\n']]:
        input lines are only terminated by newline
        the line ending is returned to the caller untranslated

    [writing][newline=None]:
        '\n' => os.linesep
    [writing][newline <- ['', '\n']]:
        no translation takes place
    [writing][newline <- ['\r', '\r\n']]:
        '\n' => newline

  line_buffering :: bool
    [line_buffering=True]:
      [.write(s)]['\n' in s or '\r' in s] => [.flush()]

  write_through :: bool
    [write_through=True]:
      [.write(s)] => [.flush()]
  ]

.line_buffering
.write_through

.reconfigure(*[, encoding][, errors][, newline][, line_buffering][, write_through])¶
  Parameters not specified keep current settings
    , except errors='strict' is used when encoding is specified but errors is not specified.

  It is not possible to change the encoding or newline if some data has already been read from the stream.
    On the other hand, changing encoding after write is possible.

  This method does an implicit stream flush before setting the new parameters.




]]
[[
StringIO <: TextIOBase
StringIO(initial_value='', newline='\n')
  public constructor
  see:TextIOWrapper().newline

getvalue() -> str
  <==> [
  p = .tell()
  .seek(0)
  s = .read(-1) #entire
  .seek(p)
  return s
  ]
]]
[[
io.IncrementalNewlineDecoder <: codecs.IncrementalDecoder
  public constructor
  #decodes newlines for universal newlines mode
]]

io__newline__newlines:here
[[
io::`newlines` 对象属性 总结:
io::`newline` 构建参数 总结:
===
stream.newlines
    newlines :: None|str|tuple<str>
    不是 构建参数 newline!!
    只在universal_newline模式下起作用:
        只记录连续读操作中，遇到的newline类型
            写操作清零
#test___newlines:goto
#test .newlines
    case param newline of
        None | '' -> None | '\r' | '\n' | '\r\n' | ('\r', '\n', '\r\n') | ('\r', '\n'), ...
        _ -> None
    只在universal_newline模式下起作用:
        #write() null .newlines
        #read() extend .newlines
        #tell() donot change .newlines
        #seek() donot change .newlines
    非universal_newline模式，.newlines恒定为None:
        # [newline=='\r\n'] ==>> [.newlines===None]
        # [newline=='\r'] ==>> [.newlines===None]
        # [newline=='\n'] ==>> [.newlines===None]
.newlines 声明:
 |  newlines
 |      Line endings translated so far.
 |      Only line endings translated during reading are considered.
===
stream.__init__(..., newline, ...):
    StringIO default '\n'
    TextIOWrapper default None
    open() default None
===
构建参数newline:
translated_or_not: read(), write()
both non-translated ==>> '','\n'
===
translated_or_not: read()
    * translated:
        * None:
            ('\r', '\n', '\r\n') --> '\n'
    * not translated:
        * '':
            ('\r', '\n', '\r\n') --> ('\r', '\n', '\r\n')
        * '\r':
            '\r' --> '\r'
        * '\n':
            '\n' --> '\n'
        * '\r\n':
            '\r\n' --> '\r\n'
===
translated_or_not: write()
    * translated:
        * None:
            '\n' --> os.linesep
        * '\r':
            '\n' --> '\r'
        * '\r\n':
            '\n' --> '\r\n'
    * not translated:
        * '':
            ('\r', '\n', '\r\n') --> ('\r', '\n', '\r\n')
        * '\n':
            '\n' --> '\n'
===
py_help io@TextIOWrapper
py_help io@IOBase
 |  encoding
 |      Encoding of the text stream.
 |      Subclasses should override.
 |
 |  errors
 |      The error setting of the decoder or encoder.
 |      Subclasses should override.
 |
 |  newlines
 |      Line endings translated so far.
 |      Only line endings translated during reading are considered.
 |      Subclasses should override.
===
py_help io@TextIOWrapper
    TextIOWrapper(buffer, encoding=None, errors=None, newline=None, line_buffering=False, write_through=False)
===
py_help io@TextIOWrapper.readline
    readline(self, size=-1, /)
        Read until newline or EOF.
===
py_help io@StringIO
    StringIO(initial_value='', newline='\n')
===
py_help @open
help(open):
    [[
open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)

newline controls how universal newlines works (it only applies to text mode). It can be None, '', '\n', '\r', and '\r\n'.  It works as follows:
* On input
    , if newline is None, universal newlines mode is enabled. Lines in the input can end in '\n', '\r', or '\r\n', and these are translated into '\n' before being returned to the caller.
    If it is '', universal newline mode is enabled, but line endings are returned to the caller untranslated.
    If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.
* On output
    , if newline is None, any '\n' characters written are translated to the system default line separator, os.linesep.
    If newline is '' or '\n', no translation takes place.
    If newline is any of the other legal values, any '\n' characters written are translated to the given string.
    ]]

]]
[[[
#test___newlines
#test .newlines
    case param newline of
        None | '' -> None | '\r' | '\n' | '\r\n' | ('\r', '\n', '\r\n') | ('\r', '\n'), ...
        _ -> None
    只在universal_newline模式下起作用:
        #write() null .newlines
        #read() extend .newlines
        #tell() donot change .newlines
        #seek() donot change .newlines
    非universal_newline模式，.newlines恒定为None:
        # [newline=='\r\n'] ==>> [.newlines===None]
        # [newline=='\r'] ==>> [.newlines===None]
        # [newline=='\n'] ==>> [.newlines===None]

>>> ibfile = BytesIO()
>>> ifile = TextIOWrapper(ibfile, encoding='u8', newline='\r\n')
>>> ifile.write('\r\n|\n\r-\r\t\n')
9
>>> ifile.newlines is None
True
>>> __ = ifile.seek(0)
>>> ifile.read()
'\r\r\n|\r\n\r-\r\t\r\n'
>>> ifile.newlines is None # [newline=='\r\n'] ==>> [.newlines===None]
True
>>> __ = ifile.detach()

>>> ibfile = BytesIO()
>>> ifile = TextIOWrapper(ibfile, encoding='u8', newline='\r')
>>> ifile.write('\r\n|\n\r-\r\t\n')
9
>>> ifile.newlines is None
True
>>> __ = ifile.seek(0)
>>> ifile.read()
'\r\r|\r\r-\r\t\r'
>>> ifile.newlines is None # [newline=='\r'] ==>> [.newlines===None]
True
>>> __ = ifile.detach()

>>> ibfile = BytesIO()
>>> ifile = TextIOWrapper(ibfile, encoding='u8', newline='\n')
>>> ifile.write('\r\n|\n\r-\r\t\n')
9
>>> ifile.newlines is None
True
>>> __ = ifile.seek(0)
>>> ifile.read()
'\r\n|\n\r-\r\t\n'
>>> ifile.newlines is None # [newline=='\n'] ==>> [.newlines===None]
True
>>> __ = ifile.detach()

>>> ibfile = BytesIO()
>>> ifile = TextIOWrapper(ibfile, encoding='u8', newline='')
>>> ifile.write('\r\n|\n\r-\r\t\n')
9
>>> ifile.newlines is None
True
>>> __ = ifile.seek(0)
>>> ifile.read()
'\r\n|\n\r-\r\t\n'
>>> ifile.newlines
('\r', '\n', '\r\n')
>>> __ = ifile.detach()




>>> ibfile = BytesIO()
>>> ifile = TextIOWrapper(ibfile, encoding='u8', newline=None)
>>> ifile.write('\r\n|\n\r-\r\t\n')
9
>>> ifile.newlines is None
True
>>> __ = ifile.seek(0)
>>> ifile.read()
'\n|\n\n-\n\t\n'
>>> ifile.newlines
('\r', '\n', '\r\n')
>>> __ = ifile.detach()

>>> ibfile = BytesIO()
>>> ifile = TextIOWrapper(ibfile, encoding='u8', newline=None)
>>> ifile.write('\r\n')
2
>>> ifile.newlines is None
True
>>> __ = ifile.seek(0)
>>> ifile.read(1)
'\n'
>>> ifile.newlines
'\r\n'
>>> ifile.read(1)
''
>>> ifile.newlines
'\r\n'
>>> addr1 = ifile.tell()
>>> ifile.write('\n')
1
>>> ifile.newlines is None
True
>>> __ = ifile.seek(-1,1)
Traceback (most recent call last):
    ...
io.UnsupportedOperation: can't do nonzero cur-relative seeks
>>> __ = ifile.seek(addr1)
>>> ifile.read(1)
'\n'
>>> ifile.newlines
'\n'
>>> ifile.read(1)
''
>>> ifile.newlines
'\n'
>>> addr2 = ifile.tell() #tell() donot change .newlines
>>> ifile.newlines
'\n'
>>> ifile.write('\r') #write() null .newlines
1
>>> ifile.newlines is None
True
>>> __ = ifile.seek(addr2)
>>> ifile.read(1)
'\n'
>>> ifile.newlines
'\r'
>>> ifile.read(1)
''
>>> ifile.newlines
'\r'
>>> __ = ifile.seek(addr1) #seek() donot change .newlines
>>> ifile.newlines
'\r'
>>> ifile.read(1)
'\n'
>>> ifile.newlines  #read() extend .newlines
('\r', '\n')
>>> __ = ifile.detach()

#end-test___newlines
]]]
]]]
[[[
asyncio
===
view ~/../usr/lib/python3.10/asyncio/....py
]]]
[[[
reference__datamodel
===
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/reference/datamodel.html
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/stdtypes.html
  for __iter__

3_4__Coroutines
  abc__Generator_Types
  8_8_1__Coroutine_function_definition
3_3_8__Emulating_numeric_types
3_3_7__Emulating_container_types

3_3_5__Emulating_generic_types
  __class_getitem__
3_3_6__Emulating_callable_objects
3_3_9__With_Statement_Context_Managers
3_3_10__Special_method_lookup
  __getattribute__



3_3_5__Emulating_generic_types
3.3.5. Emulating generic types¶
One can implement the generic class syntax as specified by PEP 484 (for example List[int]) by defining a special method:

classmethod object.__class_getitem__(cls, key)¶
Return an object representing the specialization of a generic class by type arguments found in key.

This method is looked up on the class object itself, and when defined in the class body, this method is implicitly a class method. Note, this mechanism is primarily reserved for use with static type hints, other usage is discouraged.

See also

PEP 560 - Core support for typing module and generic types

3_3_6__Emulating_callable_objects
3.3.6. Emulating callable objects¶
object.__call__(self[, args...])¶
Called when the instance is “called” as a function; if this method is defined, x(arg1, arg2, ...) is a shorthand for x.__call__(arg1, arg2, ...).


3_3_9__With_Statement_Context_Managers
3.3.9. With Statement Context Managers¶
A context manager is an object that defines the runtime context to be established when executing a with statement. The context manager handles the entry into, and the exit from, the desired runtime context for the execution of the block of code. Context managers are normally invoked using the with statement (described in section The with statement), but can also be used by directly invoking their methods.

Typical uses of context managers include saving and restoring various kinds of global state, locking and unlocking resources, closing opened files, etc.

For more information on context managers, see Context Manager Types.

object.__enter__(self)¶
Enter the runtime context related to this object. The with statement will bind this method’s return value to the target(s) specified in the as clause of the statement, if any.

object.__exit__(self, exc_type, exc_value, traceback)¶
Exit the runtime context related to this object. The parameters describe the exception that caused the context to be exited. If the context was exited without an exception, all three arguments will be None.

If an exception is supplied, and the method wishes to suppress the exception (i.e., prevent it from being propagated), it should return a true value. Otherwise, the exception will be processed normally upon exit from this method.

Note that __exit__() methods should not reraise the passed-in exception; this is the caller’s responsibility.

See also

PEP 343 - The “with” statement
The specification, background, and examples for the Python with statement.
3_3_10__Special_method_lookup
3.3.10. Special method lookup¶
For custom classes, implicit invocations of special methods are only guaranteed to work correctly if defined on an object’s type, not in the object’s instance dictionary. That behaviour is the reason why the following code raises an exception:

>>> class C:
...     pass
...
>>> c = C()
>>> c.__len__ = lambda: 5
>>> len(c)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: object of type 'C' has no len()

The rationale behind this behaviour lies with a number of special methods such as __hash__() and __repr__() that are implemented by all objects, including type objects. If the implicit lookup of these methods used the conventional lookup process, they would fail when invoked on the type object itself:

>>> 1 .__hash__() == hash(1)
True
>>> int.__hash__() == hash(int)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: descriptor '__hash__' of 'int' object needs an argument

Incorrectly attempting to invoke an unbound method of a class in this way is sometimes referred to as ‘metaclass confusion’, and is avoided by bypassing the instance when looking up special methods:

>>> type(1).__hash__(1) == hash(1)
True
>>> type(int).__hash__(int) == hash(int)
True
In addition to bypassing any instance attributes in the interest of correctness, implicit special method lookup generally also bypasses the __getattribute__() method even of the object’s metaclass:

>>> class Meta(type):
...     def __getattribute__(*args):
...         print("Metaclass getattribute invoked")
...         return type.__getattribute__(*args)
...
>>> class C(object, metaclass=Meta):
...     def __len__(self):
...         return 10
...     def __getattribute__(*args):
...         print("Class getattribute invoked")
...         return object.__getattribute__(*args)
...
>>> c = C()
>>> c.__len__()                 # Explicit lookup via instance
Class getattribute invoked
10
>>> type(c).__len__(c)          # Explicit lookup via type
Metaclass getattribute invoked
10
>>> len(c)                      # Implicit lookup
10
Bypassing the __getattribute__() machinery in this fashion provides significant scope for speed optimisations within the interpreter, at the cost of some flexibility in the handling of special methods (the special method must be set on the class object itself in order to be consistently invoked by the interpreter).



]]]
[[[
abc__Generator_Types
===
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/stdtypes.html
  Iterator_Types
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/reference/expressions.html
  async_def+yield ==>> asynchronous generator function
  await
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/reference/compound_stmts.html
  async_def => async_for, async_with, await
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/collections.abc.html
  Awaitable/...
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/asyncio.html
  asyncio.run
  asyncio_run





Iterable
  __iter__ :: sf -> Iterator
    yield

Iterator <: Iterable
  __next__ :: sf -> (obj|^StopIteration(return_value))
    py.next(Iterator, *tmay_default)
      default replace raise
  __iter__ :: sf -> sf
    # _collections_abc.py impl this

Reversible <: Iterable
  __reversed__
  __iter__
    #!!!doc no:__iter__ !!!似乎是浏览器的毛病:PrivacyBrowser
    #!!!_collections_abc.py has:__iter__

HGenerator
  send
    raise StopIteration(return_value)
  throw(self, typ, val=None, tb=None):
        if val is None:
            if tb is None:
                raise typ
            val = typ()
        if tb is not None:
            val = val.with_traceback(tb)
        raise val

    close(self):
        try:
            self.throw(GeneratorExit)
        except (GeneratorExit, StopIteration):
            pass
        else:
            raise RuntimeError("hgenerator ignored GeneratorExit")


Generator <: Iterator /\ HGenerator
  send, throw, close
  __iter__, __next__
  ---
  __next__
    return sf.send(None)


Awaitable
  xxx __await__ :: sf -> Iterator xxx
    yield
  __await__ :: sf -> Generator
    yield
      #######
      py -m script.try_python.try_async.try_await
      await ~=~ yield from
      __await__ :: sf -> Generator
      #######

Coroutine <: Awaitable /\ HGenerator
  # <<== _collections_abc.py
#Coroutine <: Awaitable /\ Generator
  send, throw, close
  __await__
  ???: __iter__, __next__
  -----
  __await__ :: sf -> sf
    # !!!_collections_abc.py doesnot impl this
    # !!!but I think (Awaitable->Coroutine)__await__ is like (Iterable->Iterator)__iter__
    # ==>> Coroutine <: Iterator
    # ==>> Coroutine <: Iterator/\HGenerator
    # ==>> Coroutine <: Generator
    # ==>> Coroutine <: Awaitable/\Generator
    # 但实际上:coroutine.__await__ -> coroutine_wrapper



AsyncIterable
  async def __aiter__ :: sf -> AsyncIterator
    yield
AsyncIterator <: AsyncIterable
  async def __anext__
    raise StopAsyncIteration$
  __aiter__ :: sf -> sf
    # _collections_abc.py impl this

AsyncGenerator <: AsyncIterator
  asend, athrow, aclose
  __aiter__, __anext__
  ---
  async def asend
    raise StopAsyncIteration(return_value)

  async def __anext__
    return await sf.asend(None)

  async def athrow
  async def aclose
      try:
          await self.athrow(GeneratorExit)
      except (GeneratorExit, StopAsyncIteration):
          pass
      else:
          raise RuntimeError("asynchronous generator ignored GeneratorExit")


asyncio_run

async_def() :: <class 'coroutine'>
async_def().__await__() :: <class 'coroutine_wrapper'>
dir(async_def()) == [__await__, send, throw, close, ...]
dir(async_def().__await__()) == [__await__, send, throw, close, __iter__, __next__, ...]



]]]
[[[
3_4__Coroutines
3.4. Coroutines¶
===
>>> def f():
...   yield 1
...   return 2
...
>>> it = f()
>>> next(it)
1
>>> next(it)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration: 2


Awaitable r:
  __await__ :: sf -> Iter r x

GenIter r x <: Iter r x =[def]= Iter x /\ raise StopIteration r

asyncio.Future r <: Awaitable r
Coroutine r <: Awaitable r

async def f():...
  :: Coroutine r



types.coroutine :: (... -> GenIter r x) -> (... -> Coroutine r)
asyncio.coroutine :: (... -> GenIter r x) -> (... -> Coroutine r)

Coroutine r(Awaitable r, GenIter r x):
  __await__ :: sf -> GenIter r x
  send :: sf -> v -> ??? 


async_def
coroutine_function
async def f(...):...
    async for ... in ...:...
    async with ... as ...:...
    await ...
    ???no: async yield from ???

8_8_1__Coroutine_function_definition
8.8.1. Coroutine function definition¶
async_funcdef ::=  [decorators] "async" "def" funcname "(" [parameter_list] ")"
                   ["->" expression] ":" suite
Execution of Python coroutines can be suspended and resumed at many points (see coroutine). Inside the body of a coroutine function, await and async identifiers become reserved keywords; await expressions, async for and async with can only be used in coroutine function bodies.

Functions defined with async def syntax are always coroutine functions, even if they do not contain await or async keywords.

It is a SyntaxError to use a yield from expression inside the body of a coroutine function.

An example of a coroutine function:

async def func(param1, param2):
    do_stuff()
    await some_coroutine()

3.4.1. Awaitable Objects¶
An awaitable object generally implements an __await__() method. Coroutine objects returned from async def functions are awaitable.

Note

The generator iterator objects returned from generators decorated with types.coroutine() or asyncio.coroutine() are also awaitable, but they do not implement __await__().

object.__await__(self)¶
Must return an iterator. Should be used to implement awaitable objects. For instance, asyncio.Future implements this method to be compatible with the await expression.

New in version 3.5.

See also

PEP 492 for additional information about awaitable objects.

3.4.2. Coroutine Objects¶
Coroutine objects are awaitable objects. A coroutine’s execution can be controlled by calling __await__() and iterating over the result. When the coroutine has finished executing and returns, the iterator raises StopIteration, and the exception’s value attribute holds the return value. If the coroutine raises an exception, it is propagated by the iterator. Coroutines should not directly raise unhandled StopIteration exceptions.

Coroutines also have the methods listed below, which are analogous to those of generators (see Generator-iterator methods). However, unlike generators, coroutines do not directly support iteration.

Changed in version 3.5.2: It is a RuntimeError to await on a coroutine more than once.

coroutine.send(value)¶
Starts or resumes execution of the coroutine. If value is None, this is equivalent to advancing the iterator returned by __await__(). If value is not None, this method delegates to the send() method of the iterator that caused the coroutine to suspend. The result (return value, StopIteration, or other exception) is the same as when iterating over the __await__() return value, described above.

coroutine.throw(type[, value[, traceback]])¶
Raises the specified exception in the coroutine. This method delegates to the throw() method of the iterator that caused the coroutine to suspend, if it has such a method. Otherwise, the exception is raised at the suspension point. The result (return value, StopIteration, or other exception) is the same as when iterating over the __await__() return value, described above. If the exception is not caught in the coroutine, it propagates back to the caller.

coroutine.close()¶
Causes the coroutine to clean itself up and exit. If the coroutine is suspended, this method first delegates to the close() method of the iterator that caused the coroutine to suspend, if it has such a method. Then it raises GeneratorExit at the suspension point, causing the coroutine to immediately clean itself up. Finally, the coroutine is marked as having finished executing, even if it was never started.

Coroutine objects are automatically closed using the above process when they are about to be destroyed.

3.4.3. Asynchronous Iterators¶
An asynchronous iterator can call asynchronous code in its __anext__ method.

Asynchronous iterators can be used in an async for statement.

object.__aiter__(self)¶
Must return an asynchronous iterator object.

object.__anext__(self)¶
Must return an awaitable resulting in a next value of the iterator. Should raise a StopAsyncIteration error when the iteration is over.

An example of an asynchronous iterable object:

class Reader:
    async def readline(self):
        ...

    def __aiter__(self):
        return self

    async def __anext__(self):
        val = await self.readline()
        if val == b'':
            raise StopAsyncIteration
        return val
New in version 3.5.

Changed in version 3.7: Prior to Python 3.7, __aiter__ could return an awaitable that would resolve to an asynchronous iterator.

Starting with Python 3.7, __aiter__ must return an asynchronous iterator object. Returning anything else will result in a TypeError error.

3.4.4. Asynchronous Context Managers¶
An asynchronous context manager is a context manager that is able to suspend execution in its __aenter__ and __aexit__ methods.

Asynchronous context managers can be used in an async with statement.

object.__aenter__(self)¶
Semantically similar to __enter__(), the only difference being that it must return an awaitable.

object.__aexit__(self, exc_type, exc_value, traceback)¶
Semantically similar to __exit__(), the only difference being that it must return an awaitable.

An example of an asynchronous context manager class:

class AsyncContextManager:
    async def __aenter__(self):
        await log('entering context')

    async def __aexit__(self, exc_type, exc, tb):
        await log('exiting context')
New in version 3.5.

]]]
[[[
3_3_7__Emulating_container_types
3.3.7. Emulating container types¶
===
The following methods can be defined to implement container objects.
Containers usually are sequences (such as lists or tuples) or mappings (like dictionaries), but can represent other containers as well.
  The first set of methods is used either to emulate a sequence or to emulate a mapping; the difference is that for a sequence, the allowable keys should be the integers k for which 0 <= k < N where N is the length of the sequence, or slice objects, which define a range of items.
  It is also recommended that mappings provide the methods keys(), values(), items(), get(), clear(), setdefault(), pop(), popitem(), copy(), and update() behaving similar to those for Python’s standard dictionary objects. The collections.abc module provides a MutableMapping abstract base class to help create those methods from a base set of __getitem__(), __setitem__(), __delitem__(), and keys().
    Mutable sequences should provide methods append(), count(), index(), extend(), insert(), pop(), remove(), reverse() and sort(), like Python standard list objects.
    Finally, sequence types should implement addition (meaning concatenation) and multiplication (meaning repetition) by defining the methods __add__(), __radd__(), __iadd__(), __mul__(), __rmul__() and __imul__() described below; they should not define other numerical operators.
    It is recommended that both mappings and sequences implement the __contains__() method to allow efficient use of the in operator; for mappings, in should search the mapping’s keys; for sequences, it should search through the values.
    It is further recommended that both mappings and sequences implement the __iter__() method to allow efficient iteration through the container; for mappings, __iter__() should iterate through the object’s keys; for sequences, it should iterate through the values.

object.__len__(self)¶
Called to implement the built-in function len(). Should return the length of the object, an integer >= 0. Also, an object that doesn’t define a __bool__() method and whose __len__() method returns zero is considered to be false in a Boolean context.

CPython implementation detail: In CPython, the length is required to be at most sys.maxsize. If the length is larger than sys.maxsize some features (such as len()) may raise OverflowError. To prevent raising OverflowError by truth value testing, an object must define a __bool__() method.

object.__length_hint__(self)¶
Called to implement operator.length_hint(). Should return an estimated length for the object (which may be greater or less than the actual length). The length must be an integer >= 0. The return value may also be NotImplemented, which is treated the same as if the __length_hint__ method didn’t exist at all. This method is purely an optimization and is never required for correctness.

New in version 3.4.

Note

Slicing is done exclusively with the following three methods. A call like

a[1:2] = b
is translated to

a[slice(1, 2, None)] = b
and so forth. Missing slice items are always filled in with None.

object.__getitem__(self, key)¶
Called to implement evaluation of self[key]. For sequence types, the accepted keys should be integers and slice objects. Note that the special interpretation of negative indexes (if the class wishes to emulate a sequence type) is up to the __getitem__() method. If key is of an inappropriate type, TypeError may be raised; if of a value outside the set of indexes for the sequence (after any special interpretation of negative values), IndexError should be raised. For mapping types, if key is missing (not in the container), KeyError should be raised.

Note

for loops expect that an IndexError will be raised for illegal indexes to allow proper detection of the end of the sequence.

object.__setitem__(self, key, value)¶
Called to implement assignment to self[key]. Same note as for __getitem__(). This should only be implemented for mappings if the objects support changes to the values for keys, or if new keys can be added, or for sequences if elements can be replaced. The same exceptions should be raised for improper key values as for the __getitem__() method.

object.__delitem__(self, key)¶
Called to implement deletion of self[key]. Same note as for __getitem__(). This should only be implemented for mappings if the objects support removal of keys, or for sequences if elements can be removed from the sequence. The same exceptions should be raised for improper key values as for the __getitem__() method.

object.__missing__(self, key)¶
Called by dict.__getitem__() to implement self[key] for dict subclasses when key is not in the dictionary.

object.__iter__(self)¶
This method is called when an iterator is required for a container. This method should return a new iterator object that can iterate over all the objects in the container. For mappings, it should iterate over the keys of the container.

Iterator objects also need to implement this method; they are required to return themselves. For more information on iterator objects, see Iterator Types.

object.__reversed__(self)¶
Called (if present) by the reversed() built-in to implement reverse iteration. It should return a new iterator object that iterates over all the objects in the container in reverse order.

If the __reversed__() method is not provided, the reversed() built-in will fall back to using the sequence protocol (__len__() and __getitem__()). Objects that support the sequence protocol should only provide __reversed__() if they can provide an implementation that is more efficient than the one provided by reversed().

The membership test operators (in and not in) are normally implemented as an iteration through a container. However, container objects can supply the following special method with a more efficient implementation, which also does not require the object be iterable.

object.__contains__(self, item)¶
Called to implement membership test operators. Should return true if item is in self, false otherwise. For mapping objects, this should consider the keys of the mapping rather than the values or the key-item pairs.

For objects that don’t define __contains__(), the membership test first tries iteration via __iter__(), then the old sequence iteration protocol via __getitem__(), see this section in the language reference.


]]]
[[[
3_3_8__Emulating_numeric_types
3.3.8. Emulating numeric types
===
__xxx__:goto
__rxxx__:goto
__ixxx__:goto


object.__neg__(self)¶
object.__pos__(self)¶
object.__abs__(self)¶
object.__invert__(self)¶
Called to implement the unary arithmetic operations (-, +, abs() and ~).

object.__complex__(self)¶
object.__int__(self)¶
object.__float__(self)¶
Called to implement the built-in functions complex(), int() and float(). Should return a value of the appropriate type.

object.__index__(self)¶
Called to implement operator.index(), and whenever Python needs to losslessly convert the numeric object to an integer object (such as in slicing, or in the built-in bin(), hex() and oct() functions). Presence of this method indicates that the numeric object is an integer type. Must return an integer.

If __int__(), __float__() and __complex__() are not defined then corresponding built-in functions int(), float() and complex() fall back to __index__().

object.__round__(self[, ndigits])¶
object.__trunc__(self)¶
object.__floor__(self)¶
object.__ceil__(self)¶
Called to implement the built-in function round() and math functions trunc(), floor() and ceil(). Unless ndigits is passed to __round__() all these methods should return the value of the object truncated to an Integral (typically an int).

If __int__() is not defined then the built-in function int() falls back to __trunc__().

]]]
[[[
__xxx__
===
object.__add__(self, other)¶
object.__sub__(self, other)¶
object.__mul__(self, other)¶
object.__matmul__(self, other)¶
object.__truediv__(self, other)¶
object.__floordiv__(self, other)¶
object.__mod__(self, other)¶
object.__divmod__(self, other)¶
object.__pow__(self, other[, modulo])¶
object.__lshift__(self, other)¶
object.__rshift__(self, other)¶
object.__and__(self, other)¶
object.__xor__(self, other)¶
object.__or__(self, other)¶

These methods are called to implement the binary arithmetic operations (+, -, *, @, /, //, %, divmod(), pow(), **, <<, >>, &, ^, |).
  For instance, to evaluate the expression x + y, where x is an instance of a class that has an __add__() method, x.__add__(y) is called. The __divmod__() method should be the equivalent to using __floordiv__() and __mod__(); it should not be related to __truediv__().
  Note that __pow__() should be defined to accept an optional third argument if the ternary version of the built-in pow() function is to be supported.

If one of those methods does not support the operation with the supplied arguments, it should return NotImplemented.

]]]
[[[
__ixxx__
===

object.__iadd__(self, other)¶
object.__isub__(self, other)¶
object.__imul__(self, other)¶
object.__imatmul__(self, other)¶
object.__itruediv__(self, other)¶
object.__ifloordiv__(self, other)¶
object.__imod__(self, other)¶
object.__ipow__(self, other[, modulo])¶
object.__ilshift__(self, other)¶
object.__irshift__(self, other)¶
object.__iand__(self, other)¶
object.__ixor__(self, other)¶
object.__ior__(self, other)¶

These methods are called to implement the augmented arithmetic assignments (+=, -=, *=, @=, /=, //=, %=, **=, <<=, >>=, &=, ^=, |=).
These methods should attempt to do the operation in-place (modifying self) and return the result (which could be, but does not have to be, self). If a specific method is not defined, the augmented assignment falls back to the normal methods.
  For instance, if x is an instance of a class with an __iadd__() method, x += y is equivalent to x = x.__iadd__(y) . Otherwise, x.__add__(y) and y.__radd__(x) are considered, as with the evaluation of x + y. In certain situations, augmented assignment can result in unexpected errors (see Why does a_tuple[i] += [‘item’] raise an exception when the addition works?), but this behavior is in fact part of the data model.

]]]
[[[
__rxxx__
===
bug!!!: why not raise NotImplementedError??:to evaluate the expression x - y, where y is an instance of a class that has an __rsub__() method, y.__rsub__(x) is called if x.__sub__(y) returns NotImplemented.


object.__radd__(self, other)¶
object.__rsub__(self, other)¶
object.__rmul__(self, other)¶
object.__rmatmul__(self, other)¶
object.__rtruediv__(self, other)¶
object.__rfloordiv__(self, other)¶
object.__rmod__(self, other)¶
object.__rdivmod__(self, other)¶
object.__rpow__(self, other[, modulo])¶
object.__rlshift__(self, other)¶
object.__rrshift__(self, other)¶
object.__rand__(self, other)¶
object.__rxor__(self, other)¶
object.__ror__(self, other)¶

These methods are called to implement the binary arithmetic operations (+, -, *, @, /, //, %, divmod(), pow(), **, <<, >>, &, ^, |) with reflected (swapped) operands.
These functions are only called if the left operand does not support the corresponding operation [def__3_Data_model_Footnotes_3] and the operands are of different types. [def__3_Data_model_Footnotes_4]
  For instance, to evaluate the expression x - y, where y is an instance of a class that has an __rsub__() method, y.__rsub__(x) is called if x.__sub__(y) returns NotImplemented.

Note that ternary pow() will not try calling __rpow__() (the coercion rules would become too complicated).

Note

If the right operand’s type is a subclass of the left operand’s type and that subclass provides the reflected method for the operation, this method will be called before the left operand’s non-reflected method. This behavior allows subclasses to override their ancestors’ operations.



Footnotes

1
def__3_Data_model_Footnotes_1
It is possible in some cases to change an object’s type, under certain controlled conditions. It generally isn’t a good idea though, since it can lead to some very strange behaviour if it is handled incorrectly.

2
def__3_Data_model_Footnotes_2
The __hash__(), __iter__(), __reversed__(), and __contains__() methods have special handling for this; others will still raise a TypeError, but may do so by relying on the behavior that None is not callable.

3
def__3_Data_model_Footnotes_3
“Does not support” here means that the class has no such method, or the method returns NotImplemented. Do not set the method to None if you want to force fallback to the right operand’s reflected method—that will instead have the opposite effect of explicitly blocking such fallback.

4
def__3_Data_model_Footnotes_4
For operands of the same type, it is assumed that if the non-reflected method (such as __add__()) fails the operation is not supported, which is why the reflected method is not called.


]]]
[[[
collections_abc
===
view ~/../usr/lib/python3.10/_collections_abc.py
cp ~/../usr/lib/python3.10/_collections_abc.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/_collections_abc.py


Mapping
MappingView
  # not View of Mapping
  # but View about Mapping items/keys/values
  #     since Mapping is readonly not immutable, can be used as View
  #
  MappingView
  KeysView
  ItemsView
  ValuesView
  ===
  now: py.dict has
    __reversed__
      ==>> ordered: __iter__/pop/popitem
      xxx no: ==>> __lt__/__le__/__gt__/__ge__
        #__eq__ but insert order diff cause __lt__

]]]
[[[
dict__update
===
update(...) method of builtins.dict instance
D.update([E, ]**F) -> None.
Update D from dict/iterable E and F.
    If E is present and has a .keys() method, then does:
      for k in E: D[k] = E[k]
    If E is present and lacks a .keys() method, then does:
      for k, v in E: D[k] = v
    In either case, this is followed by:
      for k in F:  D[k] = F[k]
]]]
[[[
enum
===
应当只用Enum/Flag, 避免使用IntEnum/IntFlag
Enum vs Flag: bitwise operators (&, |, ^, ~)
Enum :: name4cls -> (str8names|[name]|[(name,value)]|{name:value}) -> TYPE
  [without values] ==>> [values := [1..]]

Enum(value='NewEnumName', names=<...>, *, module='...', qualname='...', type=<mixed-in class>, start=1)

>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__, qualname='OuterClass.Animal') #"module/qualname" for pickle

===
cp ~/../usr/lib/python3.10/enum.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/enum.py

view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/enum.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/enum.html > $my_tmp/out4py/html2text/py_38_doc/enum.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/enum.html.txt


Enum
  Flag
    IntFlag(int, Flag)
  IntEnum(int, Enum)
auto
unique(enumeration)
  Class decorator for enumerations ensuring unique member values.

@unique
class xxx(Enum):
  aaa = auto()

Functional API
Enum :: name4cls -> (str8names|[name]|[(name,value)]|{name:value}) -> TYPE
  [without values] ==>> [values := [1..]]

Enum(value='NewEnumName', names=<...>, *, module='...', qualname='...', type=<mixed-in class>, start=1)

>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__, qualname='OuterClass.Animal') #"module/qualname" for pickle

>>> Animal = Enum('Animal', 'ANT BEE CAT DOG')
>>> Animal
<enum 'Animal'>
>>> Animal.ANT
<Animal.ANT: 1>
>>> Animal.ANT.value
1
>>> list(Animal)
[<Animal.ANT: 1>, <Animal.BEE: 2>, <Animal.CAT: 3>, <Animal.DOG: 4>]

>>> from enum import Enum, Flag
>>> C = Enum('C', 'x y z')
>>> C.x
<C.x: 1>
>>> C.x in C
True
>>> len(C)
3
>>> [*C]
[<C.x: 1>, <C.y: 2>, <C.z: 3>]
>>>
>>> D = Flag('D', 'a b c')
>>> [*D]
[<D.a: 1>, <D.b: 2>, <D.c: 4>]
>>> len(D)
3
>>> D.a|D.b
<D.b|a: 3>
>>> (D.a|D.b) in D
False
>>> D.a in D
True
>>>

]]]
[[[
pickle
===
dump(object, file)
dumps(object) -> bytes
load(file) -> object
loads(bytes) -> object


view '/data/data/com.termux/files/usr/lib/python3.10/pickle.py'
    view ../../python3_src/seed/types/DictWithNewProtocol.py
      IDictWithNewProtocol.__reduce__::tuple6 fmt

tuple6 = (mk/callabe, args/tuple, may state, may values/iterator, may items/Iterators, may set_state)
def load_(tuple6, /):
    if not type(tuple6) is tuple: raise TypeError
    if not 2 <= len(tuple6) <= 6: raise TypeError
    tuple6 += (None,)*(6-len(tuple6))
    (mk, args, may_state, may_values, may_items, may_set_state)
    if not type(args) is tuple: raise TypeError
    sf = mk(*args)
    ##差不多是这个次序，不一定
    if not may_values is None:
      values = may_values
      for _ in map(sf.append, values): pass
    if not may_items is None:
      items = may_items
      for k,v in items:
        sf[k] = v
    if not may_state is None:
      state = may_state
      if may_set_state is None:
        def set_state(sf, state, /):
          if not type(state) is dict: raise TypeError
          sf.__dict__.update(state)
        else:
          set_state = may_set_state
      set_state(sf, state)
    return sf

__reduce__(self, /) -> (str|tuple6)
__reduce_ex__(self, protocol, /)
#>>> {}.__reduce_ex__(2)
(<function __newobj__ at 0x718f54a0e0>, (<class 'dict'>,), None, None, <dict_itemiterator object at 0x718f7c1580>)
#>>> [].__reduce_ex__(2)
(<function __newobj__ at 0x718f54a0e0>, (<class 'list'>,), None, <list_iterator object at 0x718f787b20>, None)
#>>> 1 .__reduce_ex__(2)
(<function __newobj__ at 0x718f54a0e0>, (<class 'int'>, 1), None, None, None)
#>>> '' .__reduce_ex__(2)
(<function __newobj__ at 0x718f54a0e0>, (<class 'str'>, ''), None, None, None)
#>>> None .__reduce_ex__(2)
(<function __newobj__ at 0x718f54a0e0>, (<class 'NoneType'>,), None, None, None)
>>> ... .__reduce_ex__(2)
'Ellipsis'


__newobj__ = None.__reduce_ex__(2)[0]
class IDictWithNewProtocol(Mapping, ABC, tuple):
    def __reduce__(sf, /):
        #pickle
        cls = type(sf)
        arg = (*sf.iter_storage_items(),)
        return (__newobj__, (cls, arg))


]]]
[[[
colorsys
===
see:
  view ../../python3_src/seed/for_libs/for_colorsys/color_names_impl/colors_in_css2_1.py
===
view ~/../usr/lib/python3.10/colorsys.py
mkdir /sdcard/0my_files/tmp/out4py/py_src/
cp ~/../usr/lib/python3.10/colorsys.py /sdcard/0my_files/tmp/out4py/py_src/
view /sdcard/0my_files/tmp/out4py/py_src/colorsys.py

hls_to_rgb(h, l, s)
rgb_to_hls(r, g, b)

hsv_to_rgb(h, s, v)
rgb_to_hsv(r, g, b)

rgb_to_yiq(r, g, b)
yiq_to_rgb(y, i, q)

All inputs and outputs are triples of floats in the range [0.0...1.0]
  (with the exception of I and Q, which covers a slightly larger range).
  Inputs outside the valid range may cause exceptions or invalid outputs.

Supported color systems:
  RGB: Red, Green, Blue components
  YIQ: Luminance, Chrominance (used by composite video signals)
  HLS: Hue, Luminance, Saturation
  HSV: Hue, Saturation, Value

# HSV: Hue, Saturation, Value
# H: position in the spectrum
# S: color saturation ("purity")
# V: color brightness
def rgb_to_hsv(r, g, b):
    maxc = max(r, g, b)
    minc = min(r, g, b)
    v = maxc
    if minc == maxc:
        return 0.0, 0.0, v
    s = (maxc-minc) / maxc
    rc = (maxc-r) / (maxc-minc)
    gc = (maxc-g) / (maxc-minc)
    bc = (maxc-b) / (maxc-minc)
    if r == maxc:
        h = bc-gc
    elif g == maxc:
        h = 2.0+rc-bc
    else:
        h = 4.0+gc-rc
    h = (h/6.0) % 1.0
    return h, s, v

# HLS: Hue, Luminance, Saturation
# H: position in the spectrum
# L: color lightness
# S: color saturation
def rgb_to_hls(r, g, b):
    maxc = max(r, g, b)
    minc = min(r, g, b)
    sumc = (maxc+minc)
    rangec = (maxc-minc)
    l = sumc/2.0
    if minc == maxc:
        return 0.0, l, 0.0
    if l <= 0.5:
        s = rangec / sumc
    else:
        s = rangec / (2.0-sumc)
    rc = (maxc-r) / rangec
    gc = (maxc-g) / rangec
    bc = (maxc-b) / rangec
    if r == maxc:
        h = bc-gc
    elif g == maxc:
        h = 2.0+rc-bc
    else:
        h = 4.0+gc-rc
    h = (h/6.0) % 1.0
    return h, l, s




# YIQ: used by composite video signals (linear combinations of RGB)
# Y: perceived grey level (0.0 == black, 1.0 == white)
# I, Q: color components
#
# There are a great many versions of the constants used in these formulae.
# The ones in this library uses constants from the FCC version of NTSC.
def rgb_to_yiq(r, g, b):
    y = 0.30*r + 0.59*g + 0.11*b
    i = 0.74*(r-y) - 0.27*(b-y)
    q = 0.48*(r-y) + 0.41*(b-y)
    return (y, i, q)




]]]
[[super(__class__, ...obj/cls)
class super(object)
 |  super() -> same as super(__class__, <first argument>)
 |  super(type) -> unbound super object
 |  super(type, obj) -> bound super object; requires isinstance(obj, type)
 |  super(type, type2) -> bound super object; requires issubclass(type2, type)
 |  Typical use to call a cooperative superclass m
ethod:
 |  class C(B):
 |      def meth(self, arg):
 |          super().meth(arg)
 |  This works for class methods too:
 |  class C(B):
 |      @classmethod
 |      def cmeth(cls, arg):
 |          super().cmeth(arg)
]]

[[
import heapq

nlargest(n, iterable, key=None)
nsmallest(n, iterable, key=None)
    Find the n smallest elements in a dataset.
    Equivalent to:  sorted(iterable, key=key)[:n]

merge(*iterables, key=None, reverse=False)
    Merge multiple sorted inputs into a single sorted output.

heapify(heap, /)
    Transform list into a heap, in-place, in O(len(heap)) time.

heappop(heap, /)
    Pop the smallest item off the heap, maintaining the heap invariant.

heappush(heap, item, /)
    Push item onto heap, maintaining the heap invariant.

heappushpop(heap, item, /)
    Push item on the heap, then pop and return the smallest item from the heap.

heapreplace(heap, item, /)
    Pop and return the current smallest value, and add the new item.

]]

[[
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/decimal.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/decimal.html > $my_tmp/out4py/html2text/py_38_doc/decimal.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/decimal.html.txt

>>> from decimal import *
>>> import decimal as d
>>> dir(d)
['BasicContext', 'Clamped', 'Context', 'ConversionSyntax', 'Decimal', 'DecimalException', 'DecimalTuple', 'DefaultContext', 'DivisionByZero', 'DivisionImpossible', 'DivisionUndefined', 'ExtendedContext', 'FloatOperation', 'HAVE_CONTEXTVAR', 'HAVE_THREADS', 'Inexact', 'InvalidContext', 'InvalidOperation', 'MAX_EMAX', 'MAX_PREC', 'MIN_EMIN', 'MIN_ETINY', 'Overflow', 'ROUND_05UP', 'ROUND_CEILING', 'ROUND_DOWN', 'ROUND_FLOOR', 'ROUND_HALF_DOWN', 'ROUND_HALF_EVEN', 'ROUND_HALF_UP', 'ROUND_UP', 'Rounded', 'Subnormal', 'Underflow', '__builtins__', '__cached__', '__doc__', '__file__', '__libmpdec_version__', '__loader__', '__name__', '__package__', '__spec__', '__version__', 'getcontext', 'localcontext', 'setcontext']
>>> dir(Decimal)
['__abs__', '__add__', '__bool__', '__ceil__', '__class__', '__complex__', '__copy__', '__deepcopy__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__int__', '__le__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__pos__', '__pow__', '__radd__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmod__', '__rmul__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', 'adjusted', 'as_integer_ratio', 'as_tuple', 'canonical', 'compare', 'compare_signal', 'compare_total', 'compare_total_mag', 'conjugate', 'copy_abs', 'copy_negate', 'copy_sign', 'exp', 'fma', 'from_float', 'imag', 'is_canonical', 'is_finite', 'is_infinite', 'is_nan', 'is_normal', 'is_qnan', 'is_signed', 'is_snan', 'is_subnormal', 'is_zero', 'ln', 'log10', 'logb', 'logical_and', 'logical_invert', 'logical_or', 'logical_xor', 'max', 'max_mag', 'min', 'min_mag', 'next_minus', 'next_plus', 'next_toward', 'normalize', 'number_class', 'quantize', 'radix', 'real', 'remainder_near', 'rotate', 'same_quantum', 'scaleb', 'shift', 'sqrt', 'to_eng_string', 'to_integral', 'to_integral_exact', 'to_integral_value']
>>> Decimal('2').logb()
Decimal('0')
>>> Decimal('2')**Decimal('2.12316463')
Decimal('4.356485163789795294212506525')
>>> getcontext().prec
28
>>> Decimal('2')**Decimal('-2.12316463')
Decimal('0.2295428452991860082601533507')
>>>

]]

[[
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/argparse.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/argparse.html > $my_tmp/out4py/html2text/py_38_doc/argparse.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/argparse.html.txt

class argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True)
ArgumentParser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest])

[[我的:
import argparse

parser = argparse.ArgumentParser(
    description=''
    , epilog=''
    , formatter_class=argparse.RawDescriptionHelpFormatter
    )
parser.add_argument(...)
]]


py -m seed.for_libs.for_doctest -h

]]
[[
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/operator.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/operator.html > $my_tmp/out4py/html2text/py_38_doc/operator.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/operator.html.txt

operator.attrgetter(attr)(x) -> x.attr
operator.attrgetter(attr, attr, *attrs)(x) -> [x.attr]
  attr <- {'xxx', 'a.b', ...}

attrgetter
    h = attrgetter('name.first', 'name.last')
    h(r) === (r.name.first, r.name.last)

itemgetter
    g = itemgetter(2, 5, 3)
    g(r) === (r[2], r[5], r[3])

methodcaller
    g = methodcaller('name', 'date', foo=1)
    g(r) === r.name('date', foo=1)


!!! no operator.__call__ !!!
    from seed.for_libs.for_operator.__call__ import caller, __call__, call

__contains__ = contains(a, b, /)
    Same as b in a (note reversed operands).
    !!!!!!!!!!!!!!!!!!!!!!!!!!!
    !!!!!!!!!!!!!!!!!!!!!!!!!!!
    !!!!!!!!!!!!!!!!!!!!!!!!!!!
    args order is same as method

__concat__ = concat(a, b, /)
    Same as a + b, for a and b sequences.

__index__ = index(a, /)
    Same as a.__index__()
index(a, /)
    Same as a.__index__()

indexOf(a, b, /)
    Return the first index of b in a.



import operator
operator.__all__
>>> operator.__all__
['abs', 'add', 'and_', 'attrgetter', 'concat', 'contains', 'countOf', 'delitem', 'eq', 'floordiv', 'ge', 'getitem', 'gt', 'iadd', 'iand', 'iconcat', 'ifloordiv', 'ilshift', 'imatmul', 'imod', 'imul', 'index', 'indexOf', 'inv', 'invert', 'ior', 'ipow', 'irshift', 'is_', 'is_not', 'isub', 'itemgetter', 'itruediv', 'ixor', 'le', 'length_hint', 'lshift', 'lt', 'matmul', 'methodcaller', 'mod', 'mul', 'ne', 'neg', 'not_', 'or_', 'pos', 'pow', 'rshift', 'setitem', 'sub', 'truediv', 'truth', 'xor']

help(operator)


py_help operator > ~/my_tmp/out4py/py_help.operator.out.txt
view /sdcard/0my_files/tmp/out4py/py_help.operator.out.txt
  [[[
  ===
__abs__ = abs(a, /)
    Same as abs(a).

__add__ = add(a, b, /)
    Same as a + b.

__and__ = and_(a, b, /)
    Same as a & b.

__concat__ = concat(a, b, /)
    Same as a + b, for a and b sequences.

__contains__ = contains(a, b, /)
    Same as b in a (note reversed operands).

__delitem__ = delitem(a, b, /)
    Same as del a[b].

__eq__ = eq(a, b, /)
    Same as a == b.

__floordiv__ = floordiv(a, b, /)
    Same as a // b.

__ge__ = ge(a, b, /)
    Same as a >= b.

__getitem__ = getitem(a, b, /)
    Same as a[b].

__gt__ = gt(a, b, /)
    Same as a > b.

__iadd__ = iadd(a, b, /)
    Same as a += b.

__iand__ = iand(a, b, /)
    Same as a &= b.

__iconcat__ = iconcat(a, b, /)
    Same as a += b, for a and b sequences.

__ifloordiv__ = ifloordiv(a, b, /)
    Same as a //= b.

__ilshift__ = ilshift(a, b, /)
    Same as a <<= b.

__imatmul__ = imatmul(a, b, /)
    Same as a @= b.

__imod__ = imod(a, b, /)
    Same as a %= b.

__imul__ = imul(a, b, /)
    Same as a *= b.

__index__ = index(a, /)
    Same as a.__index__()

__inv__ = inv(a, /)
    Same as ~a.

__invert__ = invert(a, /)
    Same as ~a.

__ior__ = ior(a, b, /)
    Same as a |= b.

__ipow__ = ipow(a, b, /)
    Same as a **= b.

__irshift__ = irshift(a, b, /)
    Same as a >>= b.

__isub__ = isub(a, b, /)
    Same as a -= b.

__itruediv__ = itruediv(a, b, /)
    Same as a /= b.

__ixor__ = ixor(a, b, /)
    Same as a ^= b.

__le__ = le(a, b, /)
    Same as a <= b.

__lshift__ = lshift(a, b, /)
    Same as a << b.

__lt__ = lt(a, b, /)
    Same as a < b.

__matmul__ = matmul(a, b, /)
    Same as a @ b.

__mod__ = mod(a, b, /)
    Same as a % b.

__mul__ = mul(a, b, /)
    Same as a * b.

__ne__ = ne(a, b, /)
    Same as a != b.

__neg__ = neg(a, /)
    Same as -a.

__not__ = not_(a, /)
    Same as not a.

__or__ = or_(a, b, /)
    Same as a | b.

__pos__ = pos(a, /)
    Same as +a.

__pow__ = pow(a, b, /)
    Same as a ** b.

__rshift__ = rshift(a, b, /)
    Same as a >> b.

__setitem__ = setitem(a, b, c, /)
    Same as a[b] = c.

__sub__ = sub(a, b, /)
    Same as a - b.

__truediv__ = truediv(a, b, /)
    Same as a / b.

__xor__ = xor(a, b, /)
    Same as a ^ b.

abs(a, /)
    Same as abs(a).

add(a, b, /)
    Same as a + b.

and_(a, b, /)
    Same as a & b.

concat(a, b, /)
    Same as a + b, for a and b sequences.

contains(a, b, /)
    Same as b in a (note reversed operands).

countOf(a, b, /)
    Return the number of items in a which are, or which equal, b.

delitem(a, b, /)
    Same as del a[b].

eq(a, b, /)
    Same as a == b.

floordiv(a, b, /)
    Same as a // b.

ge(a, b, /)
    Same as a >= b.

getitem(a, b, /)
    Same as a[b].

gt(a, b, /)
    Same as a > b.

iadd(a, b, /)
    Same as a += b.

iand(a, b, /)
    Same as a &= b.

iconcat(a, b, /)
    Same as a += b, for a and b sequences.

ifloordiv(a, b, /)
    Same as a //= b.

ilshift(a, b, /)
    Same as a <<= b.

imatmul(a, b, /)
    Same as a @= b.

imod(a, b, /)
    Same as a %= b.

imul(a, b, /)
    Same as a *= b.

index(a, /)
    Same as a.__index__()

indexOf(a, b, /)
    Return the first index of b in a.

inv(a, /)
    Same as ~a.

invert(a, /)
    Same as ~a.

ior(a, b, /)
    Same as a |= b.

ipow(a, b, /)
    Same as a **= b.

irshift(a, b, /)
    Same as a >>= b.

is_(a, b, /)
    Same as a is b.

is_not(a, b, /)
    Same as a is not b.

isub(a, b, /)
    Same as a -= b.

itruediv(a, b, /)
    Same as a /= b.

ixor(a, b, /)
    Same as a ^= b.

le(a, b, /)
    Same as a <= b.

length_hint(obj, default=0, /)
    Return an estimate of the number of items in obj.
    
    This is useful for presizing containers when building from an iterable.
    
    If the object supports len(), the result will be exact.
    Otherwise, it may over- or under-estimate by an arbitrary amount.
    The result will be an integer >= 0.

lshift(a, b, /)
    Same as a << b.

lt(a, b, /)
    Same as a < b.

matmul(a, b, /)
    Same as a @ b.

mod(a, b, /)
    Same as a % b.

mul(a, b, /)
    Same as a * b.

ne(a, b, /)
    Same as a != b.

neg(a, /)
    Same as -a.

not_(a, /)
    Same as not a.

or_(a, b, /)
    Same as a | b.

pos(a, /)
    Same as +a.

pow(a, b, /)
    Same as a ** b.

rshift(a, b, /)
    Same as a >> b.

setitem(a, b, c, /)
    Same as a[b] = c.

sub(a, b, /)
    Same as a - b.

truediv(a, b, /)
    Same as a / b.

truth(a, /)
    Return True if a is true, False otherwise.

xor(a, b, /)
    Same as a ^ b.


  ]]]



]]
[[
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/importlib.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/importlib.html > $my_tmp/out4py/html2text/py_38_doc/importlib.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/importlib.html.txt



!mkdir /sdcard/0my_files/tmp/out4py/py_src/importlib/
cp ~/../usr/lib/python3.10/importlib/__init__.py /sdcard/0my_files/tmp/out4py/py_src/importlib/
view /sdcard/0my_files/tmp/out4py/py_src/importlib/__init__.py

cp ~/../usr/lib/python3.10/importlib/util.py /sdcard/0my_files/tmp/out4py/py_src/importlib/
view /sdcard/0my_files/tmp/out4py/py_src/importlib/util.py

cp ~/../usr/lib/python3.10/importlib/_bootstrap.py /sdcard/0my_files/tmp/out4py/py_src/importlib/
view /sdcard/0my_files/tmp/out4py/py_src/importlib/_bootstrap.py

cp ~/../usr/lib/python3.10/importlib/_bootstrap_external.py /sdcard/0my_files/tmp/out4py/py_src/importlib/
view /sdcard/0my_files/tmp/out4py/py_src/importlib/_bootstrap_external.py

cp ~/../usr/lib/python3.10/importlib/machinery.py /sdcard/0my_files/tmp/out4py/py_src/importlib/
view /sdcard/0my_files/tmp/out4py/py_src/importlib/machinery.py

cp ~/../usr/lib/python3.10/importlib/resources.py /sdcard/0my_files/tmp/out4py/py_src/importlib/
view /sdcard/0my_files/tmp/out4py/py_src/importlib/resources.py


[importlib___contents]#goto
[自定义模块导入囗囗概要]#goto
  view ../../python3_src/seed/types/SeqPrefixRegister.py







[importlib__xxx]#goto
importlib.import_module(name, package=None)
importlib.reload(module_obj)->module_obj
importlib.invalidate_caches()

reload(sys.modules[qname])
    #File "/data/data/com.termux/files/usr/lib/python3.10/importlib/__init__.py", line 168, in reload
    #ModuleNotFoundError: spec not found for the module 'm'
    没有直接使用module_obj.__spec__
    而是直接使用module_obj.__name__
      若sys.meta_path不支持module_obj.__name__，则出错
        因为我是直接sys.modules[module_obj.__name__]=module_obj
        所以无法使用reload









[importlib__resources]#goto
  重新封装:
  from seed.pkg_tools.load_resource import open_under_pkg_, read_under_pkg_
  from seed.pkg_tools.load_resource import list_potential_basenames_under_pkg_, sorted_potential_basenames_under_pkg_, iter_potential_basenames_under_pkg_, does_exist_under_pkg_, with_path_under_pkg_
  虚拟路径、基本文件名
  枚举子文件子文件夹、过滤掉子文件夹、临时文件
importlib.resources.open_binary(package, resource)->BinaryIO
importlib.resources.open_text(package, resource, encoding='utf-8', errors='strict')->TextIO
importlib.resources.read_binary(package, resource)->bytes
importlib.resources.read_text(package, resource, encoding='utf-8', errors='strict')->str
  虚拟路径、基本文件名
  package = pkg_qname|pkg_obj
  resource :: basename
      it may not contain path separators
      it may not have sub-resources (i.e. it cannot be a directory).

importlib.resources.path(package, resource)->context_manager<tmp_path>
importlib.resources.is_resource(package, name)->bool
importlib.resources.contents(package)->Iter<name/resource-or-not>#目录
  枚举子文件子文件夹、过滤掉子文件夹、临时文件








######################
[[[
[importlib__xxx]#here
importlib.import_module(name, package=None)->module_obj
importlib.reload(module_obj)->module_obj
importlib.invalidate_caches()

######################
importlib.invalidate_caches()
    for finder in sys.meta_path:
        if hasattr(finder, 'invalidate_caches'):
            finder.invalidate_caches()
  ######################
  This function should be called if any modules are created/installed while your program is running to guarantee all finders will notice the new module’s existence.




######################
importlib.reload(module_obj)->module_obj
[旧的属性不被覆盖则保留#属性名集合-单调增
This is useful if you have edited the module source file using an external editor and want to try out the new version without leaving the Python interpreter.
The return value is the module object (which can be different if re-importing causes a different object to be placed in sys.modules).

When reload() is executed:
Python module’s code is recompiled and the module-level code re-executed,
  defining a new set of objects which are bound to names in the module’s dictionary by reusing the loader which originally loaded the module.
The init function of extension modules is not called a second time.
As with all other objects in Python the old objects are only reclaimed after their reference counts drop to zero.
The names in the module namespace are updated to point to any new or changed objects.
Other references to the old objects (such as names external to the module) are not rebound to refer to the new objects and must be updated in each namespace where they occur if that is desired.

There are a number of other caveats:
When a module is reloaded, its dictionary (containing the module’s global variables) is retained.
Redefinitions of names will override the old definitions, so this is generally not a problem.
If the new version of a module does not define a name that was defined by the old version, the old definition remains.
This feature can be used to the module’s advantage if it maintains a global table or cache of objects
— with a try statement it can test for the table’s presence and skip its initialization if desired:
try:
    cache
except NameError:
    cache = {}


It is generally not very useful to reload built-in or dynamically loaded modules.
Reloading sys, __main__, builtins and other key modules is not recommended.
In many cases extension modules are not designed to be initialized more than once, and may fail in arbitrary ways when reloaded.
If a module imports objects from another module using from …import …,
    calling reload() for the other module does not redefine the objects imported from it
      — one way around this is to re-execute the from statement
      , another is to use import and qualified names (module.name) instead.
If a module instantiates instances of a class, reloading the module that defines the class does not affect the method definitions of the instances —they continue to use the old class definition.  The same is true for derived classes.

New in version 3.4.
Changed in version 3.7: ModuleNotFoundError is raised when the module being reloaded lacks a ModuleSpec.
]




######################
Deprecated:importlib.find_loader(qname, path=None)
  * -> ValueError|sys.modules[name].__loader__
  * -> None|search using sys.meta_path, optionally within the specified path
  Use importlib.util.find_spec() instead.

######################

]]]




######################
######################
######################
######################
[[[
importlib.abc – Abstract base classes related to import¶

[importlib__abc]#here
fullname===qname===module_obj.__name__
######################
ResourceReader
######################
Loader
  InspectLoader
    ExecutionLoader
  ResourceLoader (deprecated)
      #Deprecated by ResourceReader
      (^ExecutionLoader)
          FileLoader
          SourceLoader
            [SourceLoader__vs__FileLoader]#goto
######################
Finder (deprecated)
  #Deprecated by MetaPathFinder, PathEntryFinder
  MetaPathFinder
  PathEntryFinder

######################
*MetaPathFinder
  BuiltinImporter <: MetaPathFinder&InspectLoader
  FrozenImporter <: MetaPathFinder&InspectLoader
  PathFinder :: MetaPathFinder
    #not#PathFinder <: MetaPathFinder
*PathEntryFinder
  FileFinder <: PathEntryFinder

*FileLoader
  SourceFileLoader <: SourceLoader&FileLoader
  SourcelessFileLoader <: FileLoader
  ExtensionFileLoader <: ExecutionLoader

######################
未过气:
  sys.meta_path :: [MetaPathFinder/meta path finder]
    PathFinder :: MetaPathFinder
      类型 当作 实例 用
      classmethod替代 实例方法
      ===PathFinder:使用:
      sys.path :: [(str|bytes|???)]
      sys.path_hooks :: [((str|bytes)->(PathEntryFinder|^ImportError))]
        ...->PathEntryFinder/path entry finder

>>> sys.meta_path
[<class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
>>> sys.path_hooks
[<class 'zipimport.zipimporter'>, <function FileFinder.path_hook.<locals>.path_hook_for_FileFinder at 0x77deca8af0>]

######################
[def____spec__ModuleSpec]#goto
  [spec :: ModuleSpec]
  [module_obj :: types.ModuleType]
  [importlib____mk____spec]#goto
  importlib.util.module_from_spec(spec)->module_obj/types.ModuleType#已有基本属性，但未exec
  importlib.util.spec_from_file_location(name, location, *, loader=None, submodule_search_locations=None)->spec
  importlib.util.spec_from_loader(name, loader, *, origin=None, is_package=None)->spec
      #.ModuleSpec(name, loader, *, origin=None, loader_state=None, is_package=None)

######################
[[
[自定义模块导入囗囗概要]#here
  see:自定义模块导入#[importlib_____usage]#goto
  ===
  *MetaPathFinder
    a_MetaPathFinder :: MetaPathFinder
      具象化抽象类<<==[importlib____mk____spec]#goto
    sys.meta_path.append(a_MetaPathFinder)
  *PathFinder
    sys.path_hooks.append(a_path_hook)
    a_path_hook :: (str|bytes) -> (PathEntryFinder|^ImportError)
      *PathEntryFinder
        具象化抽象类<<==[importlib____mk____spec]#goto
      *FileFinder
        [importlib__machinery]#goto
        FileFinder.path_hook :: *loader_details -> (path->PathEntryFinder|^ImportError)
        loader_details :: [(mk_loader,[suffix])]
        +mk_loader :: qname -> path -> Loader
          *Loader
            具象化抽象类<<==
              types.ModuleType
              .read_binary#[importlib__resources]#goto
                  InspectLoader.source_to_code
              exec(code, module_obj.__dict__)
          *SourceFileLoader/SourcelessFileLoader/ExtensionFileLoader
        +suffixes
          BYTECODE_SUFFIXES = ['.pyc']
          EXTENSION_SUFFIXES = ['.cpython-310.so', '.abi3.so', '.so']
          SOURCE_SUFFIXES = ['.py']
]]

######################
MetaPathFinder
  .find_spec(fullname, may __path__, target=None)->may spec
  .invalidate_caches()
######################
PathEntryFinder
  .find_spec(fullname, target=None)->may spec
  .invalidate_caches()
######################
Loader
  .?get_resource_reader(fullname)->ResourceReader
  .create_module(spec)->may module_obj
  .exec_module(module_obj)
    #初始化|重载
######################
ResourceReader
  #resource::basename?
  .open_resource(resource)->ibfile|^FileNotFoundError
  .resource_path(resource)->path|^FileNotFoundError
  .is_resource(name)->bool|^FileNotFoundError
  .contents()->Iter<name>
######################
InspectLoader
  .get_code(fullname)->may pycode_obj|^ImportError
  .get_source(fullname)->may str|^ImportError
  .is_package(fullname)->bool|^ImportError
  .source_to_code(data/src:str/bytes, path='<string>')->pycode_obj
######################
ExecutionLoader
  .get_filename(fullname)->str/Path?|^ImportError
######################








######################
class importlib.abc.MetaPathFinder¶

@abstractmethod
MetaPathFinder.find_spec(fullname, may __path__, target=None)->may spec
  An abstractmethod for finding a spec for the specified module.
  If this is a top-level import, path will be None.
      Otherwise, this is a search for a subpackage or module and path will be the value of __path__ from the parent package.
  If a spec cannot be found, None is returned.
  When passed in, target is a module object that the finder may use to make a more educated guess about what spec to return.
  importlib.util.spec_from_loader() may be useful for implementing concrete MetaPathFinders.


MetaPathFinder.invalidate_caches()
  An optional method
  Used by importlib.invalidate_caches()

Deprecated:MetaPathFinder.find_module(fullname, path)
  Deprecated since version 3.4: Use find_spec() instead.







######################
class importlib.abc.PathEntryFinder¶
  Though it bears some similarities to MetaPathFinder, PathEntryFinder is meant for use only within the path-based import subsystem provided by PathFinder.
  就是说，PathEntryFinder是sys.meta_path中某个特定MetaPathFinder(xxx.PathFinder)自定义的协议所开的扩展插槽

@abstractmethod
PathEntryFinder.find_spec(fullname, target=None)->may spec
  An abstract method for finding a spec for the specified module.
  The finder will search for the module only within the path entry to which it is assigned.
  If a spec cannot be found, None is returned.
  When passed in, target is a module object that the finder may use to make a more educated guess about what spec to return.
  importlib.util.spec_from_loader() may be useful for implementing concrete PathEntryFinders.

PathEntryFinder.invalidate_caches()
  An optional method
  Used by PathFinder.invalidate_caches()

Deprecated:PathEntryFinder.find_loader(fullname)
  Use find_spec() instead.
Deprecated:PathEntryFinder.find_module(fullname)
  Use find_spec() instead.





######################
class importlib.abc.Loader¶
Loader.?get_resource_reader(fullname)->ResourceReader
@abstractmethod
Loader.create_module(spec)->may module_obj
  A method that returns the module object to use when importing a module.
  This method may return None, indicating that default module creation semantics should take place.

@abstractmethod
Loader.exec_module(module_obj)
  An abstract method that executes the module in its own namespace when a module is imported or reloaded.
  The module should already be initialized when exec_module() is called.
      #大概是指:__name__之类，其他属性再说



Deprecated:Loader.load_module(fullname)->module_obj|^ImportError
  The recommended API for loading a module is exec_module() (and create_module()).
  A legacy method for loading a module.
    module_obj = sys.modules.setdefault(fullname, sf.create_module...)
    #init or reload
    try:
      ...
    except:
      if create_module:
        del sys.modules[fullname]
      raise

  The loader should set several attributes on the module.  (Note that some of these attributes can change when a module is reloaded):
    (see importlib.util.module_for_loader())
    ######################
    [def____module__attributes]
    [def____spec__ModuleSpec]#goto
      __name__:xxx if yyy==__init__ else xxx.yyy
              The name of the module.
      __file__:xxx/yyy.py
              The path to where the module data is stored (not set for built-in modules).
      __cached__:N/A or xxx/__pycache__/yyy.pyc
              The path to where a compiled version of the module is/should be stored (not set when the attribute would be inappropriate).
      __path__:N/A if not pkg else [path...]
              A list of strings specifying the search path within a package. This attribute is not set on modules.
              [def____is_pkg___is_ns_pkg]#here
              [is_pkg(module_obj) == hasattr(module_obj, '__path__') == (module_obj.__name__==_module_obj._package__) == (module_obj.__spec__.submodule_search_locations is not None)]
               namespace_package:
              [is_ns_pkg(module_obj) == (module_obj.__loader__ is None) == (module_obj.__spec__.loader is None)]
      __package__:'' or 'xxx'
              The parent package for the module/package. If the module is top-level then it has a value of the empty string. The importlib.util.module_for_loader() decorator can handle the details for __package__.
      __loader__:
              The loader used to load the module.
              The importlib.util.module_for_loader() decorator can handle the details for __package__.
                [Deprecated]module_for_loader::((loader,module_obj,...)->module_obj) -> ((loader,qname,...)->module_obj)





######################
class importlib.abc.ResourceReader¶
  #resource::basename?
  An abstract base class to provide the ability to read resources.
  From the perspective of this ABC, a resource is a binary artifact that is shipped within a package.
      Typically this is something like a data file that lives next to the __init__.py file of the package.
  The purpose of this class is to help abstract out the accessing of such data files so that it does not matter if the package and its data file(s) are stored in a e.g. zip file versus on the file system.
  For any of methods of this class, a resource argument is expected to be a path-like object which represents conceptually just a file name.
      This means that no subdirectory paths should be included in the resource argument.
      This is because the location of the package the reader is for, acts as the“directory”.
      Hence the metaphor for directories and file names is packages and resources, respectively.
      This is also why instances of this class are expected to directly correlate to a specific package (instead of potentially representing multiple packages or a module).
  Loaders that wish to support resource reading are expected to provide a method called get_resource_reader(fullname) which returns an object implementing this ABC’s interface.
      If the module specified by fullname is not a package, this method should return None.
      An object compatible with this ABC should only be returned when the specified module is a package.




@abstractmethod
ResourceReader.open_resource(resource)->ibfile|^FileNotFoundError
  Returns an opened, file-like object for binary reading of the resource.
  If the resource cannot be found, FileNotFoundError is raised.



@abstractmethod
ResourceReader.resource_path(resource)->path|^FileNotFoundError
  Returns the file system path to the resource.
  If the resource does not concretely exist on the file system, raise FileNotFoundError.



@abstractmethod
ResourceReader.is_resource(name)->bool|^FileNotFoundError
  ??????????????????????
  ???下面.contents()又说:is_resource() would be false
  ??????????????????????
  Returns True if the named name is considered a resource.
  FileNotFoundError is raised if name does not exist.



@abstractmethod
ResourceReader.contents()->Iter<name>
  Returns an iterable of strings over the contents of the package.
  Do note that it is not required that all names returned by the iterator be actual resources
      , e.g. it is acceptable to return names for which is_resource() would be false.
  Allowing non-resource names to be returned is to allow for situations where how a package and its resources are stored are known a priori and the non-resource names would be useful.
  For instance, returning subdirectory names is allowed so that when it is known that the package and resources are stored on the file system then those subdirectory names can be used directly.
  The abstract method returns an iterable of no items.








Deprecated:class importlib.abc.ResourceLoader¶







######################
class importlib.abc.InspectLoader¶
    for loaders that inspect modules.
InspectLoader.get_code(fullname)->may pycode_obj|^ImportError
    Return the code object for a module, or None if the module does not have a code object (as would be the case, for example, for a built-in module).
    Raise an ImportError if loader cannot find the requested module.

    Note
    While the method has a default implementation, it is suggested that it be overridden if possible for performance.






@abstractmethod
InspectLoader.get_source(fullname)->may str|^ImportError
  ===
  可使用:importlib.util.decode_source(source_bytes)->str
  ===
  An abstract method to return the source of a module.
  It is returned as a text string using universal newlines, translating all recognized line separators into '\n' characters.
  Returns None if no source is available (e.g. a built-in module).
  Raises ImportError if the loader cannot find the module specified.





@abstractmethod
InspectLoader.is_package(fullname)->bool|^ImportError
  An abstract method to return a true value if the module is a package, a false value otherwise.
  ImportError is raised if the loader cannot find the module.




#不是?@abstractmethod
@staticmethod
InspectLoader.source_to_code(data/src:str/bytes, path='<string>')->pycode_obj
  Create a code object from Python source.
  The data argument can be whatever the compile() function supports (i.e. string or bytes).
  The path argument should be the “path” to where the source code originated from, which can be an abstract concept (e.g. location in a zip file).
  With the subsequent code object one can execute it in a module by running exec(code, module.__dict__).






######################
class importlib.abc.ExecutionLoader(InspectLoader)¶
  helps a module to be executed as a script.

@abstractmethod
ExecutionLoader.get_filename(fullname)->str/Path?|^ImportError
  An abstract method that is to return the value of __file__ for the specified module.
  If no path is available, ImportError is raised.
  If source code is available, then the method should return the path to the source file, regardless of whether a bytecode was used to load the module.




######################
class importlib.abc.FileLoader(ResourceLoader, ExecutionLoader)¶
  [SourceLoader__vs__FileLoader]#goto
  providing concrete implementations of ResourceLoader.get_data() and ExecutionLoader.get_filename().
.FileLoader(fullname, path)
FileLoader.name
    The name of the module the loader can handle.
FileLoader.path
    Path to the file of the module.
只有一个抽象方法:get_source
    InspectLoader.get_source(fullname)->may str|^ImportError



######################
class importlib.abc.SourceLoader(ResourceLoader, ExecutionLoader)¶
  [SourceLoader__vs__FileLoader]#goto
  An abstract base class for implementing source (and optionally bytecode) file loading.
  requiring the implementation of:
      ResourceLoader.get_data()
      ExecutionLoader.get_filename()
          Should only return the path to the source file
          sourceless loading is not supported.




  The abstract methods defined by this class are to add optional bytecode file support.
  Not implementing these optional methods (or causing them to raise NotImplementedError) causes the loader to only work with source code.
  Implementing the methods allows the loader to work with source and bytecode files; it does not allow for sourceless loading where only bytecode is provided.
  Bytecode files are an optimization to speed up loading by removing the parsing step of Python’s compiler, and so no bytecode-specific API is exposed.

######################
]]]









######################
######################
######################
######################

[[[
importlib.resources – Resources¶

>>> import importlib.resources
>>> import pkg_resources
>>> help(importlib.resources)
>>> help(pkg_resources)
  不是标准库: /data/data/com.termux/files/usr/lib/python3.10/site-packages/pkg_resources/__init__.py



This module leverages Python’s import system to provide access to resources within packages.  If you can import a package, you can access resources within that package.  Resources can be opened or read, in either binary or text mode.
Resources are roughly akin to files inside directories, though it’s important to keep in mind that this is just a metaphor.
    Resources and packages do not have to exist as physical files and directories on the file system.

Note
This module provides functionality similar to pkg_resources Basic Resource Access without the performance overhead of that package.
This makes reading resources included in packages easier, with more stable and consistent semantics.
The standalone backport of this module provides more information on using importlib.resources and migrating from pkg_resources to importlib.resources.

Loaders that wish to support resource reading should implement a get_resource_reader(fullname) method as specified by importlib.abc.ResourceReader.




The following types are defined.
*importlib.resources.Package¶
  The Package type is defined as Union[str, ModuleType].
    This means that where the function describes accepting a Package, you can pass in either a string or a module.
      Module objects must have a resolvable __spec__.submodule_search_locations that is not None.



*importlib.resources.Resource¶
  This type describes the resource names passed into the various functions in this package.
      This is defined as Union[str, os.PathLike].
      #basename?



[importlib__resources]#here
  重新封装:
  from seed.pkg_tools.load_resource import open_under_pkg_, read_under_pkg_
  from seed.pkg_tools.load_resource import list_potential_basenames_under_pkg_, sorted_potential_basenames_under_pkg_, iter_potential_basenames_under_pkg_, does_exist_under_pkg_, with_path_under_pkg_
The following functions are available.

importlib.resources.open_binary(package, resource)->BinaryIO
importlib.resources.open_text(package, resource, encoding='utf-8', errors='strict')->TextIO
importlib.resources.read_binary(package, resource)->bytes
importlib.resources.read_text(package, resource, encoding='utf-8', errors='strict')->str
  虚拟路径、基本文件名
  package = pkg_qname|pkg_obj
  resource :: basename
      it may not contain path separators
      it may not have sub-resources (i.e. it cannot be a directory).












importlib.resources.path(package, resource)->context_manager<tmp_path>
  Return the path to the resource as an actual file system path.
  This function returns a context manager for use in a with statement.
  The context manager provides a pathlib.Path object.
  Exiting the context manager cleans up any temporary file created when the resource needs to be extracted from e.g. a zip file.



importlib.resources.is_resource(package, name)->bool
  Return True if there is a resource named name in the package, otherwise False.
  Remember that directories are not resources!



importlib.resources.contents(package)->Iter<name/resource-or-not>#目录
  Return an iterable over the named items within the package.
  The iterable returns str resources (e.g. files) and non-resources (e.g. directories).
  The iterable does not recurse into subdirectories.
  枚举子文件子文件夹、过滤掉子文件夹、临时文件
]]]
[[[
[importlib_____usage]
模块导入
查询模块存在性#只需加载父包
加载源文件
自定义模块导入
近似模拟import_module()
===
import importlib
import importlib.util
import sys

===
模块导入
itertools = importlib.import_module('itertools')

===
查询模块存在性#只需加载父包
name = 'itertools'

if name in sys.modules:
    print(f"{name!r} already in sys.modules")
elif (spec := importlib.util.find_spec(name)) is not None:
    # If you chose to perform the actual import ...
    module = importlib.util.module_from_spec(spec)
    sys.modules[name] = module
    spec.loader.exec_module(module)
    print(f"{name!r} has been imported")
else:
    print(f"can't find the {name!r} module")

import tokenize
file_path = tokenize.__file__
module_name = tokenize.__name__

===
加载源文件
spec = importlib.util.spec_from_file_location(module_name, file_path)
module = importlib.util.module_from_spec(spec)
sys.modules[module_name] = module
spec.loader.exec_module(module)

===
自定义模块导入
未过气:
  sys.meta_path :: [MetaPathFinder/meta path finder]
    PathFinder :: MetaPathFinder
      类型 当作 实例 用
      classmethod替代 实例方法
      ===PathFinder:使用:
      sys.path :: [(str|bytes|???)]
      sys.path_hooks :: [((str|bytes)->(PathEntryFinder|^ImportError))]
        ...->PathEntryFinder/path entry finder

      sys.path_importer_cache :: {qname:may PathEntryFinder}
      sys.modules :: {qname:module_obj}

      [importlib____PathFinder____find_spec]#goto
      [importlib____FileFinder____path_hook]#goto

SpamMetaPathFinder = importlib.machinery.PathFinder
SpamPathEntryFinder = importlib.machinery.FileFinder
loader_details = [(importlib.machinery.SourceFileLoader,
                  importlib.machinery.SOURCE_SUFFIXES)
                  ]

# Setting up a meta path finder.
sys.meta_path.append(SpamMetaPathFinder)

# Setting up a path entry finder.
sys.path_hooks.append(SpamPathEntryFinder.path_hook(*loader_details))

===
近似模拟import_module()
def import_module(name, package=None):
    """An approximate implementation of import."""
    absolute_name = importlib.util.resolve_name(name, package)
    try:
        return sys.modules[absolute_name]
    except KeyError:
        pass

    path = None
    if '.' in absolute_name:
        parent_name, _, child_name = absolute_name.rpartition('.')
        parent_module = import_module(parent_name)
        path = parent_module.__spec__.submodule_search_locations
    for finder in sys.meta_path:
        spec = finder.find_spec(absolute_name, path)
        if spec is not None:
            break
    else:
        msg = f'No module named {absolute_name!r}'
        raise ModuleNotFoundError(msg, name=absolute_name)
    module = importlib.util.module_from_spec(spec)
    sys.modules[absolute_name] = module
    spec.loader.exec_module(module)
    if path is not None:
        setattr(parent_module, child_name, module)
    return module
===
]]]
[[[
importlib.util – Utility code for importers¶
[importlib__util]
===
help in the construction of an importer.


importlib.util.MAGIC_NUMBER¶
The bytes which represent the bytecode version number. If you need help with loading/writing bytecode then consider importlib.abc.SourceLoader.





importlib.util.cache_from_source(path4py, deprecated debug_override=None, *, optimization=None)->path4pyc|^ValueError|^TypeError
  ('/foo/bar/baz.py', op...=None)
      <==>('/foo/bar/baz.py', op...=get_tag()未找到)
  ('/foo/bar/baz.py', op...='') -> '/foo/bar/__pycache__/baz.cpython-32.pyc'
  ('/foo/bar/baz.py', op...='2') -> '/foo/bar/__pycache__/baz.cpython-32.opt-2.pyc'
      多了'.opt-2'
  ===
  Return the PEP 3147/PEP 488 path to the byte-compiled file associated with the source path.
    For example, if path is /foo/bar/baz.py the return value would be /foo/bar/__pycache__/baz.cpython-32.pyc for Python 3.2.
        The cpython-32 string comes from the current magic tag 
        (see get_tag(); if sys.implementation.cache_tag is not defined then NotImplementedError will be raised).
          没找到:get_tag()
  ===
  The optimization parameter is used to specify the optimization level of the bytecode file.
    An empty string represents no optimization, so /foo/bar/baz.py with an optimization of '' will result in a bytecode path of /foo/bar/__pycache__/baz.cpython-32.pyc.
      None causes the interpreter’s optimization level to be used.
    Any other value’s string representation is used, so /foo/bar/baz.py with an optimization of 2 will lead to the bytecode path of /foo/bar/__pycache__/baz.cpython-32.opt-2.pyc.
    The string representation of optimization can only be alphanumeric, else ValueError is raised.
  ===
  The debug_override parameter is deprecated and can be used to override the system’s value for __debug__.
    A True value is the equivalent of setting optimization to the empty string.
    A False value is the same as setting optimization to 1.
    If both debug_override an optimization are not None then TypeError is raised.
  ===







importlib.util.source_from_cache(path4pyc)->path4py|^ValueError|^NotImplementedError
  /foo/bar/__pycache__/baz.cpython-32.pyc ---> /foo/bar/baz.py
  ===
  Given the path to a PEP 3147 file name, return the associated source code file path.
  path need not exist, however if it does not conform to PEP 3147 or PEP 488 format, a ValueError is raised.
  If sys.implementation.cache_tag is not defined, NotImplementedError is raised.





importlib.util.decode_source(source_bytes)->str
  Decode the given bytes representing source code and return it as a string with universal newlines
      (as required by importlib.abc.InspectLoader.get_source()).





importlib.util.resolve_name(name, package)->qname|^ValueError
  Resolve a relative module name to an absolute one.
  ===
  If  name has no leading dots, then name is simply returned.
  This allows for usage such as
    importlib.util.resolve_name('sys', __package__)
    without doing a check to see if the package argument is needed.
  ===
  ValueError is raised if name is a relative module name but package is a false value (e.g. None or the empty string).
  ValueError is also raised a relative name would escape its containing package (e.g. requesting ..bacon from within the spam package).





importlib.util.find_spec(name, package=None)->may spec|^ValueError|^ModuleNotFoundError
  ===
  for finder in sys.meta_path:
      spec = finder.find_spec(name, path)
      if spec is not None:
          return spec
  else:
      return None
  ===
  Find the spec for a module, optionally relative to the specified package name.
  If the module is in sys.modules, then sys.modules[name].__spec__ is returned
    (unless the spec would be None or is not set, in which case ValueError is raised).
  Otherwise a search using sys.meta_path is done.
  None is returned if no spec is found.
  If name is for a submodule (contains a dot), the parent module is automatically imported.
  name and package work the same as for import_module().

  Raises ModuleNotFoundError instead of AttributeError if package is in fact not a package (i.e. lacks a __path__ attribute).

  [[
import importlib._bootstrap
===
from ._bootstrap import _find_spec
#importlib.util.find_spec
def find_spec(name, package=None):
    fullname = resolve_name(name, package)
    if fullname not in sys.modules:
        parent_name = fullname.rpartition('.')[0]
        if parent_name:
            parent = __import__(parent_name, fromlist=['__path__'])
            try:
                parent_path = parent.__path__
            except AttributeError as e:
                raise ModuleNotFoundError from e
        else:
            parent_path = None
        return _find_spec(fullname, parent_path)
    else:
        module = sys.modules[fullname]
        if module is None:
            return None
        try:
            spec = module.__spec__
        except AttributeError:
            raise ValueError from None
        else:
            if spec is None:
                raise ValueError
            return spec

===
#importlib._bootstrap._find_spec
def _find_spec(name, path, target=None):
    meta_path = sys.meta_path
    if meta_path is None:
        # PyImport_Cleanup() is running or has been called.
        raise ImportError("sys.meta_path is None, Python is likely shutting down")

    if not meta_path:
        _warnings.warn('sys.meta_path is empty', ImportWarning)

    # We check sys.modules here for the reload case.  While a passed-in
    # target will usually indicate a reload there is no guarantee, whereas
    # sys.modules provides one.
    is_reload = name in sys.modules
    for finder in meta_path:
        with _ImportLockContext():
            try:
                find_spec = finder.find_spec
            except AttributeError:
                spec = _find_spec_legacy(finder, name, path)
                if spec is None:
                    continue
            else:
                spec = find_spec(name, path, target)
        if spec is not None:
            # The parent import may have already imported this module.
            if not is_reload and name in sys.modules:
                module = sys.modules[name]
                try:
                    __spec__ = module.__spec__
                except AttributeError:
                    # We use the found spec since that is the one that
                    # we would have used if the parent module hadn't
                    # beaten us to the punch.
                    return spec
                else:
                    if __spec__ is None:
                        return spec
                    else:
                        return __spec__
            else:
                return spec
    else:
        return None


===
  ]]


importlib.util.module_from_spec(spec)->module_obj/types.ModuleType#已有基本属性，但未exec
  ===
  spec.loader.create_module()+设置基本属性
    未调用:spec.loader.exec_module()
  ===
  Create a new module based on spec and spec.loader.create_module.
  If spec.loader.create_module does not return None, then any pre-existing attributes will not be reset.
  Also, no AttributeError will be raised if triggered while accessing spec or setting an attribute on the module.
  This function is preferred over using types.ModuleType to create a new module as spec is used to set as many import-controlled attributes on the module as possible.


  [[
from ._bootstrap import module_from_spec
===
#importlib._bootstrap.module_from_spec
def module_from_spec(spec):
    # Typically loaders will not implement create_module().
    module = None
    if hasattr(spec.loader, 'create_module'):
        # If create_module() returns `None` then it means default
        # module creation should be used.
        module = spec.loader.create_module(spec)
    elif hasattr(spec.loader, 'exec_module'):
        raise ImportError('loaders that define exec_module() must also define create_module()')
    if module is None:
        module = _new_module(spec.name)
    _init_module_attrs(spec, module)
    return module


===
def _new_module(name):
    return type(sys)(name)
===
def _init_module_attrs(spec, module, *, override=False):
    # The passed-in module may be not support attribute assignment,
    # in which case we simply don't set the attributes.
    # __name__
    if (override or getattr(module, '__name__', None) is None):
        try:
            module.__name__ = spec.name
        except AttributeError:
            pass
    # __loader__
    if override or getattr(module, '__loader__', None) is None:
        loader = spec.loader
        if loader is None:
            # A backward compatibility hack.
            if spec.submodule_search_locations is not None:
                if _bootstrap_external is None:
                    raise NotImplementedError
                _NamespaceLoader = _bootstrap_external._NamespaceLoader

                loader = _NamespaceLoader.__new__(_NamespaceLoader)
                loader._path = spec.submodule_search_locations
                spec.loader = loader
                # While the docs say that module.__file__ is not set for
                # built-in modules, and the code below will avoid setting it if
                # spec.has_location is false, this is incorrect for namespace
                # packages.  Namespace packages have no location, but their
                # __spec__.origin is None, and thus their module.__file__
                # should also be None for consistency.  While a bit of a hack,
                # this is the best place to ensure this consistency.
                #
                # See # https://docs.python.org/3/library/importlib.html#importlib.abc.Loader.load_module
                # and bpo-32305
                module.__file__ = None
        try:
            module.__loader__ = loader
        except AttributeError:
            pass
    # __package__
    if override or getattr(module, '__package__', None) is None:
        try:
            module.__package__ = spec.parent
        except AttributeError:
            pass
    # __spec__
    try:
        module.__spec__ = spec
    except AttributeError:
        pass
    # __path__
    if override or getattr(module, '__path__', None) is None:
        if spec.submodule_search_locations is not None:
            try:
                module.__path__ = spec.submodule_search_locations
            except AttributeError:
                pass
    # __file__/__cached__
    if spec.has_location:
        if override or getattr(module, '__file__', None) is None:
            try:
                module.__file__ = spec.origin
            except AttributeError:
                pass

        if override or getattr(module, '__cached__', None) is None:
            if spec.cached is not None:
                try:
                    module.__cached__ = spec.cached
                except AttributeError:
                    pass
    return module


===
  ]]




Deprecated:@importlib.util.set_loader¶
Deprecated:@importlib.util.set_package¶
Deprecated:@importlib.util.module_for_loader¶
  [Deprecated]module_for_loader::((loader,module_obj,...)->module_obj) -> ((loader,qname,...)->module_obj)
  Deprecated since version 3.4: The import machinery now directly performs all the functionality provided by this function.
  ===
  A decorator for importlib.abc.Loader.load_module() to handle selecting the proper module object to load with.
  The decorated method is expected to have a call signature taking two positional arguments
    (e.g. 输入的函数load_module(self, module))
    for which the second argument will be the module object to be used by the loader.
    #输入的函数fi:第二参数是module_obj
    #返回的函数fo:第二参数是fullname
    #也就是说，包办了.create_module()
    #     返回的函数Deprecated:Loader.load_module(fullname)->module_obj|^ImportError
  Note that the decorator will not work on static methods because of the assumption of two arguments.
  The decorated method will take in the name of the module to be loaded as expected for a loader.
  If the module is not found in sys.modules then a new one is constructed.
  Regardless of where the module came from, __loader__ set to self and __package__ is set based on what importlib.abc.InspectLoader.is_package() returns (if available).
  These attributes are set unconditionally to support reloading.
    #无条件支持重载
  If an exception is raised by the decorated method and a module was added to sys.modules, then the module will be removed to prevent a partially initialized module from being in left in sys.modules.
      If the module was already in sys.modules then it is left alone.
      #出错，移除新加的失败模块







#[importlib____mk____spec]
#   .ModuleSpec(name, loader, *, origin=None, loader_state=None, is_package=None)
importlib.util.spec_from_file_location(name, location, *, loader=None, submodule_search_locations=None)->spec
  A factory function for creating a ModuleSpec instance based on the path to a file.
importlib.util.spec_from_loader(name, loader, *, origin=None, is_package=None)->spec
  A factory function for creating a ModuleSpec instance based on a loader.
  The parameters have the same meaning as they do for ModuleSpec.
  The function uses available loader APIs, such as InspectLoader.is_package(), to fill in any missing information on the spec.
  [[
from ._bootstrap_external import spec_from_file_location
from ._bootstrap import spec_from_loader
===
#importlib._bootstrap.spec_from_loader
def spec_from_loader(name, loader, *, origin=None, is_package=None):
    """Return a module spec based on various loader methods."""
    if hasattr(loader, 'get_filename'):
        if _bootstrap_external is None:
            raise NotImplementedError
        spec_from_file_location = _bootstrap_external.spec_from_file_location

        if is_package is None:
            return spec_from_file_location(name, loader=loader)
        search = [] if is_package else None
        return spec_from_file_location(name, loader=loader, submodule_search_locations=search)

    if is_package is None:
        if hasattr(loader, 'is_package'):
            try:
                is_package = loader.is_package(name)
            except ImportError:
                is_package = None  # aka, undefined
        else:
            # the default
            is_package = False

    return ModuleSpec(name, loader, origin=origin, is_package=is_package)
===
#importlib._bootstrap_external.spec_from_file_location
_POPULATE = object()
def spec_from_file_location(name, location=None, *, loader=None, submodule_search_locations=_POPULATE):
    """Return a module spec based on a file location.

    To indicate that the module is a package, set
    submodule_search_locations to a list of directory paths.  An
    empty list is sufficient, though its not otherwise useful to the
    import system.

    The loader must take a spec as its only __init__() arg.

    """
    if location is None:
        # The caller may simply want a partially populated location-
        # oriented spec.  So we set the location to a bogus value and
        # fill in as much as we can.
        location = '<unknown>'
        if hasattr(loader, 'get_filename'):
            # ExecutionLoader
            try:
                location = loader.get_filename(name)
            except ImportError:
                pass
    else:
        location = _os.fspath(location)
        if not _path_isabs(location):
            try:
                location = _path_join(_os.getcwd(), location)
            except OSError:
                pass

    # If the location is on the filesystem, but doesn't actually exist,
    # we could return None here, indicating that the location is not
    # valid.  However, we don't have a good way of testing since an
    # indirect location (e.g. a zip file or URL) will look like a
    # non-existent file relative to the filesystem.

    spec = _bootstrap.ModuleSpec(name, loader, origin=location)
    spec._set_fileattr = True

    # Pick a loader if one wasn't provided.
    if loader is None:
        for loader_class, suffixes in _get_supported_file_loaders():
            if location.endswith(tuple(suffixes)):
                loader = loader_class(name, location)
                spec.loader = loader
                break
        else:
            return None

    # Set submodule_search_paths appropriately.
    if submodule_search_locations is _POPULATE:
        # Check the loader.
        if hasattr(loader, 'is_package'):
            try:
                is_package = loader.is_package(name)
            except ImportError:
                pass
            else:
                if is_package:
                    spec.submodule_search_locations = []
    else:
        spec.submodule_search_locations = submodule_search_locations
    if spec.submodule_search_locations == []:
        if location:
            dirname = _path_split(location)[0]
            spec.submodule_search_locations.append(dirname)

    return spec


===
===
  ]]









importlib.util.source_hash(source_bytes)¶
  Return the hash of source_bytes as bytes.
      A hash-based .pyc file embeds the source_hash() of the corresponding source file’s contents in its header.





class importlib.util.LazyLoader¶
  A class which postpones the execution of the loader of a module until the module has an attribute accessed.
  This class only works with loaders that define exec_module() as control over what module type is used for the module is required.
    For those same reasons, the loader’s create_module() method must return None or a type for which its __class__ attribute can be mutated along with not using slots.
  Finally, modules which substitute the object placed into sys.modules will not work as there is no way to properly replace the module references throughout the interpreter safely;
  ValueError is raised if such a substitution is detected.

  Note
    For projects where startup time is critical, this class allows for potentially minimizing the cost of loading a module if it is never used.
    For projects where startup time is not essential then use of this class is heavily discouraged due to error messages created during loading being postponed and thus occurring out of context.

.LazyLoader(loader)

@classmethod
LazyLoader.factory(loader)¶
  A static method which returns a callable that creates a lazy loader. This is meant to be used in situations where the loader is passed by class instead of by instance.





===
suffixes = importlib.machinery.SOURCE_SUFFIXES
loader = importlib.machinery.SourceFileLoader
lazy_loader = importlib.util.LazyLoader.factory(loader)
finder = importlib.machinery.FileFinder(path, (lazy_loader, suffixes))
===
]]]





######################
######################
######################
[[[
[importlib__machinery]
importlib.machinery – Importers and path hooks¶
  This module contains the various objects that help import find and load modules.

all_suffixes()->[suffix]
  used by inspect.getmodulename()

DATA
    BYTECODE_SUFFIXES = ['.pyc']
    EXTENSION_SUFFIXES = ['.cpython-310.so', '.abi3.so', '.so']
    SOURCE_SUFFIXES = ['.py']

importlib.machinery.SOURCE_SUFFIXES¶
importlib.machinery.BYTECODE_SUFFIXES¶
importlib.machinery.EXTENSION_SUFFIXES¶
importlib.machinery.all_suffixes()¶







######################
from ._bootstrap import ModuleSpec
from ._bootstrap import BuiltinImporter
from ._bootstrap import FrozenImporter
from ._bootstrap_external import PathFinder
from ._bootstrap_external import FileFinder
from ._bootstrap_external import SourceFileLoader
from ._bootstrap_external import SourcelessFileLoader
from ._bootstrap_external import ExtensionFileLoader
######################



BuiltinImporter <: MetaPathFinder&InspectLoader
FrozenImporter <: MetaPathFinder&InspectLoader
PathFinder :: MetaPathFinder
  #not#PathFinder <: MetaPathFinder
FileFinder <: PathEntryFinder
SourceFileLoader <: SourceLoader&FileLoader
SourcelessFileLoader <: FileLoader
ExtensionFileLoader <: ExecutionLoader




######################
class importlib.machinery.BuiltinImporter(MetaPathFinder,InspectLoader)¶
  An importer for built-in modules.
  All known built-in modules are listed in sys.builtin_module_names.
  Only class methods are defined by this class to alleviate the need for instantiation.
  ===
  BuiltinImporter <: MetaPathFinder&InspectLoader
######################
class importlib.machinery.FrozenImporter(MetaPathFinder,InspectLoader)¶
  Only class methods are defined by this class to alleviate the need for instantiation.
  ===
  FrozenImporter <: MetaPathFinder&InspectLoader
######################
######################
######################
[[[
[[
sys.path :: [(str|bytes|???)]
sys.path_hooks :: [((str|bytes)->(PathEntryFinder|^ImportError))]
PathFinder :: MetaPathFinder
  #not#PathFinder <: MetaPathFinder

sys.path_importer_cache :: {qname:may PathEntryFinder}
sys.modules :: {qname:module_obj}

[importlib____PathFinder____find_spec]
  [importlib_____usage]#goto
class PathFinder:
    def find_spec(cls, fullname, path=None, target=None)->may_spec:
        #大体轮廓:外循环sys.path，内循环sys.path_hooks
        if path is None:
            path = sys.path
        namespace_path = []
        for entry in path:
            if not isinstance(entry, (str, bytes)):
                continue
            for hook in sys.path_hooks:
                try:
                    finder = hook(path)
                except ImportError:
                    continue
                else:
                    may_finder = finder
                    break
            else:
                may_finder = None

            ######################
            if may_finder is not None:
                finder = may_finder
                may_spec = finder.find_spec(fullname, target)
                if may_spec is None:
                    continue
                spec = may_spec
                if spec.loader is not None:
                    break
                portions = spec.submodule_search_locations
                namespace_path.extend(portions)
            continue
        else:
            spec = _bootstrap.ModuleSpec(fullname, None)
            spec.submodule_search_locations = namespace_path
            may_spec = spec
        return may_spec
]]
[[
path :: str | dirpath
loader_details :: [(mk_loader,[suffix])]
  mk_loader :: qname -> path -> Loader
    see:SourceFileLoader
FileFinder <: PathEntryFinder
FileFinder.path_hook :: *loader_details -> (path->PathEntryFinder|^ImportError)
.FileFinder :: path -> *loader_details -> FileFinder

[importlib____FileFinder____path_hook]
  [importlib_____usage]#goto
class FileFinder:
    def __init__(self, path, *loader_details):
        for loader, suffixes in loader_details:
    @classmethod
    def path_hook(cls, *loader_details):
        '*loader_details -> (path->PathEntryFinder)'
]]
class PathFinder:
    """Meta path finder for sys.path and package __path__ attributes."""

    @staticmethod
    def invalidate_caches():
        """Call the invalidate_caches() method on all path entry finders
        stored in sys.path_importer_caches (where implemented)."""
        for name, finder in list(sys.path_importer_cache.items()):
            if finder is None:
                del sys.path_importer_cache[name]
            elif hasattr(finder, 'invalidate_caches'):
                finder.invalidate_caches()
        # Also invalidate the caches of _NamespacePaths
        # https://bugs.python.org/issue45703
        _NamespacePath._epoch += 1

    @staticmethod
    def _path_hooks(path):
        """Search sys.path_hooks for a finder for 'path'."""
        if sys.path_hooks is not None and not sys.path_hooks:
            _warnings.warn('sys.path_hooks is empty', ImportWarning)
        for hook in sys.path_hooks:
            try:
                return hook(path)
            except ImportError:
                continue
        else:
            return None

    @classmethod
    def _path_importer_cache(cls, path):
        """Get the finder for the path entry from sys.path_importer_cache.

        If the path entry is not in the cache, find the appropriate finder
        and cache it. If no finder is available, store None.

        """
        if path == '':
            try:
                path = _os.getcwd()
            except FileNotFoundError:
                # Don't cache the failure as the cwd can easily change to
                # a valid directory later on.
                return None
        try:
            finder = sys.path_importer_cache[path]
        except KeyError:
            finder = cls._path_hooks(path)
            sys.path_importer_cache[path] = finder
        return finder

    @classmethod
    def _legacy_get_spec(cls, fullname, finder):
        # This would be a good place for a DeprecationWarning if
        # we ended up going that route.
        if hasattr(finder, 'find_loader'):
            msg = (f"{_bootstrap._object_name(finder)}.find_spec() not found; "
                    "falling back to find_loader()")
            _warnings.warn(msg, ImportWarning)
            loader, portions = finder.find_loader(fullname)
        else:
            msg = (f"{_bootstrap._object_name(finder)}.find_spec() not found; "
                    "falling back to find_module()")
            _warnings.warn(msg, ImportWarning)
            loader = finder.find_module(fullname)
            portions = []
        if loader is not None:
            return _bootstrap.spec_from_loader(fullname, loader)
        spec = _bootstrap.ModuleSpec(fullname, None)
        spec.submodule_search_locations = portions
        return spec

    @classmethod
    def _get_spec(cls, fullname, path, target=None):
        """Find the loader or namespace_path for this module/package name."""
        # If this ends up being a namespace package, namespace_path is
        #  the list of paths that will become its __path__
        namespace_path = []
        for entry in path:
            if not isinstance(entry, (str, bytes)):
                continue
            finder = cls._path_importer_cache(entry)
            if finder is not None:
                if hasattr(finder, 'find_spec'):
                    spec = finder.find_spec(fullname, target)
                else:
                    spec = cls._legacy_get_spec(fullname, finder)
                if spec is None:
                    continue
                if spec.loader is not None:
                    return spec
                portions = spec.submodule_search_locations
                if portions is None:
                    raise ImportError('spec missing loader')
                # This is possibly part of a namespace package.
                #  Remember these path entries (if any) for when we
                #  create a namespace package, and continue iterating
                #  on path.
                namespace_path.extend(portions)
        else:
            spec = _bootstrap.ModuleSpec(fullname, None)
            spec.submodule_search_locations = namespace_path
            return spec

    @classmethod
    def find_spec(cls, fullname, path=None, target=None):
        """Try to find a spec for 'fullname' on sys.path or 'path'.

        The search is based on sys.path_hooks and sys.path_importer_cache.
        """
        if path is None:
            path = sys.path
        spec = cls._get_spec(fullname, path, target)
        if spec is None:
            return None
        elif spec.loader is None:
            namespace_path = spec.submodule_search_locations
            if namespace_path:
                # We found at least one namespace path.  Return a spec which
                # can create the namespace package.
                spec.origin = None
                spec.submodule_search_locations = _NamespacePath(fullname, namespace_path, cls._get_spec)
                return spec
            else:
                return None
        else:
            return spec

    @classmethod
    def find_module(cls, fullname, path=None):
        """find the module on sys.path or 'path' based on sys.path_hooks and
        sys.path_importer_cache.

        This method is deprecated.  Use find_spec() instead.

        """
        _warnings.warn("PathFinder.find_module() is deprecated and "
                       "slated for removal in Python 3.12; use find_spec() instead",
                       DeprecationWarning)
        spec = cls.find_spec(fullname, path)
        if spec is None:
            return None
        return spec.loader

    @staticmethod
    def find_distributions(*args, **kwargs):
        """
        Find distributions.

        Return an iterable of all Distribution instances capable of
        loading the metadata for packages matching ``context.name``
        (or all names if ``None`` indicated) along the paths in the list
        of directories ``context.path``.
        """
        from importlib.metadata import MetadataPathFinder
        return MetadataPathFinder.find_distributions(*args, **kwargs)
]]]
######################
[[[
class FileFinder:

    """File-based finder.

    Interactions with the file system are cached for performance, being
    refreshed when the directory the finder is handling has been modified.

    """

    def __init__(self, path, *loader_details):
        """Initialize with the path to search on and a variable number of
        2-tuples containing the loader and the file suffixes the loader
        recognizes."""
        loaders = []
        for loader, suffixes in loader_details:
            loaders.extend((suffix, loader) for suffix in suffixes)
        self._loaders = loaders
        # Base (directory) path
        self.path = path or '.'
        if not _path_isabs(self.path):
            self.path = _path_join(_os.getcwd(), self.path)
        self._path_mtime = -1
        self._path_cache = set()
        self._relaxed_path_cache = set()

    def invalidate_caches(self):
        """Invalidate the directory mtime."""
        self._path_mtime = -1

    find_module = _find_module_shim

    def find_loader(self, fullname):
        """Try to find a loader for the specified module, or the namespace
        package portions. Returns (loader, list-of-portions).

        This method is deprecated.  Use find_spec() instead.

        """
        _warnings.warn("FileFinder.find_loader() is deprecated and "
                       "slated for removal in Python 3.12; use find_spec() instead",
                       DeprecationWarning)
        spec = self.find_spec(fullname)
        if spec is None:
            return None, []
        return spec.loader, spec.submodule_search_locations or []

    def _get_spec(self, loader_class, fullname, path, smsl, target):
        loader = loader_class(fullname, path)
        return spec_from_file_location(fullname, path, loader=loader,
                                       submodule_search_locations=smsl)

    def find_spec(self, fullname, target=None):
        """Try to find a spec for the specified module.

        Returns the matching spec, or None if not found.
        """
        is_namespace = False
        tail_module = fullname.rpartition('.')[2]
        try:
            mtime = _path_stat(self.path or _os.getcwd()).st_mtime
        except OSError:
            mtime = -1
        if mtime != self._path_mtime:
            self._fill_cache()
            self._path_mtime = mtime
        # tail_module keeps the original casing, for __file__ and friends
        if _relax_case():
            cache = self._relaxed_path_cache
            cache_module = tail_module.lower()
        else:
            cache = self._path_cache
            cache_module = tail_module
        # Check if the module is the name of a directory (and thus a package).
        if cache_module in cache:
            base_path = _path_join(self.path, tail_module)
            for suffix, loader_class in self._loaders:
                init_filename = '__init__' + suffix
                full_path = _path_join(base_path, init_filename)
                if _path_isfile(full_path):
                    return self._get_spec(loader_class, fullname, full_path, [base_path], target)
            else:
                # If a namespace package, return the path if we don't
                #  find a module in the next section.
                is_namespace = _path_isdir(base_path)
        # Check for a file w/ a proper suffix exists.
        for suffix, loader_class in self._loaders:
            try:
                full_path = _path_join(self.path, tail_module + suffix)
            except ValueError:
                return None
            _bootstrap._verbose_message('trying {}', full_path, verbosity=2)
            if cache_module + suffix in cache:
                if _path_isfile(full_path):
                    return self._get_spec(loader_class, fullname, full_path,
                                          None, target)
        if is_namespace:
            _bootstrap._verbose_message('possible namespace for {}', base_path)
            spec = _bootstrap.ModuleSpec(fullname, None)
            spec.submodule_search_locations = [base_path]
            return spec
        return None

    def _fill_cache(self):
        """Fill the cache of potential modules and packages for this directory."""
        path = self.path
        try:
            contents = _os.listdir(path or _os.getcwd())
        except (FileNotFoundError, PermissionError, NotADirectoryError):
            # Directory has either been removed, turned into a file, or made
            # unreadable.
            contents = []
        # We store two cached versions, to handle runtime changes of the
        # PYTHONCASEOK environment variable.
        if not sys.platform.startswith('win'):
            self._path_cache = set(contents)
        else:
            # Windows users can import modules with case-insensitive file
            # suffixes (for legacy reasons). Make the suffix lowercase here
            # so it's done once instead of for every import. This is safe as
            # the specified suffixes to check against are always specified in a
            # case-sensitive manner.
            lower_suffix_contents = set()
            for item in contents:
                name, dot, suffix = item.partition('.')
                if dot:
                    new_name = '{}.{}'.format(name, suffix.lower())
                else:
                    new_name = name
                lower_suffix_contents.add(new_name)
            self._path_cache = lower_suffix_contents
        if sys.platform.startswith(_CASE_INSENSITIVE_PLATFORMS):
            self._relaxed_path_cache = {fn.lower() for fn in contents}

    @classmethod
    def path_hook(cls, *loader_details):
        """A class method which returns a closure to use on sys.path_hook
        which will return an instance using the specified loaders and the path
        called on the closure.

        If the path called on the closure is not a directory, ImportError is
        raised.

        """
        def path_hook_for_FileFinder(path):
            """Path hook for importlib.machinery.FileFinder."""
            if not _path_isdir(path):
                raise ImportError('only directories are supported', path=path)
            return cls(path, *loader_details)

        return path_hook_for_FileFinder

    def __repr__(self):
        return 'FileFinder({!r})'.format(self.path)
]]]

######################
######################


######################
Deprecated: class importlib.machinery.WindowsRegistryFinder¶
  Finder for modules declared in the Windows registry.
  Use site configuration instead. Future versions of Python may not enable this finder by default.

######################
class importlib.machinery.PathFinder¶
  A Finder for sys.path and package __path__ attributes.
  PathFinder :: MetaPathFinder
    #not#PathFinder <: MetaPathFinder
      类型 当作 实例 用
      classmethod替代 实例方法

[importlib____PathFinder____find_spec]#goto
@classmethod
PathFinder.find_spec(fullname, path=None, target=None)->may spec
  Class method that attempts to find a spec for the module specified by fullname on 输入的参数path缺省sys.path.
  For each path entry that is searched, sys.path_importer_cache is checked.
  If a non-false object is found then it is used as the path entry finder to look for the module being searched for.
  If no entry is found in sys.path_importer_cache, then sys.path_hooks is searched for a finder for the path entry and
      , if found, is stored in sys.path_importer_cache along with being queried about the module.
  If no finder is ever found then None is both stored in the cache and returned.
    Changed in version 3.5: If the current working directory – represented by an empty string –is no longer valid then None is returned but no value is cached in sys.path_importer_cache.

sys.path_importer_cache :: {qname:may PathEntryFinder}

@classmethod
classmethod PathFinder.invalidate_caches()¶
  Calls importlib.abc.PathEntryFinder.invalidate_caches() on all finders stored in sys.path_importer_cache that define the method.
  Otherwise entries in sys.path_importer_cache set to None are deleted.
  ???Changed in version 3.4: Calls objects in sys.path_hooks with the current working directory for '' (i.e. the empty string).

@classmethod
Deprecated:PathFinder.find_module(fullname, path=None)¶
  Use find_spec() instead.



######################
class importlib.machinery.FileFinder(PathEntryFinder)¶
  A concrete implementation of importlib.abc.PathEntryFinder which caches results from the file system.
  FileFinder <: PathEntryFinder
  path :: str | dirpath
  loader_details :: [(mk_loader,[suffix])]
    mk_loader :: qname -> path -> Loader
      see:SourceFileLoader
  ######################
  The finder will cache the directory contents as necessary, making stat calls for each module search to verify the cache is not outdated.
  Because cache staleness relies upon the granularity of the operating system’s state information of the file system
      , there is a potential race condition of searching for a module, creating a new file, and then searching for the module the new file represents.
      If the operations happen fast enough to fit within the granularity of stat calls, then the module search will fail.
      To prevent this from happening, when you create a module dynamically, make sure to call importlib.invalidate_caches().



.FileFinder(path, *loader_details)

FileFinder.path¶

FileFinder.find_spec(fullname, target=None)->may spec

Deprecated:FileFinder.find_loader(fullname)¶

FileFinder.invalidate_caches()¶



[importlib____FileFinder____path_hook]#goto
@classmethod
FileFinder.path_hook(*loader_details) -> (path->PathEntryFinder|^ImportError)
  A class method which returns a closure for use on sys.path_hooks.
  If the argument to the closure is not an existing directory, ImportError is raised.




######################
######################
class importlib.machinery.SourceFileLoader(SourceLoader,FileLoader)¶
  A concrete implementation of importlib.abc.SourceLoader by subclassing importlib.abc.FileLoader and providing some concrete implementations of other methods.
  ===
  [SourceLoader__vs__FileLoader]
  SourceFileLoader <: SourceLoader&FileLoader
      SourceLoader <: ResourceLoader&ExecutionLoader
      FileLoader <: ResourceLoader&ExecutionLoader
      ???这SourceLoader,FileLoader到底是啥区别？
        *有源代码，但不一定有文件，虚拟文件'<string>'
            see:InspectLoader.source_to_code(data/src:str/bytes, path='<string>')->pycode_obj
        *有文件，但不一定有源代码，编译生成的二进制文件xxx.dll,xxx.so,xxx.pyc
            see:SourcelessFileLoader
            see:ExtensionFileLoader

.SourceFileLoader(fullname, path)
  #see:loader_details.mk_loader :: qname -> path -> Loader

SourceFileLoader.name¶
  The name of the module that this loader will handle.

SourceFileLoader.path¶
  The path to the source file.

@override
SourceFileLoader.is_package(fullname)¶
  Return True if path appears to be for a package.
  #InspectLoader.is_package
  SourceFileLoader <: SourceLoader&FileLoader <: ExecutionLoader <: InspectLoader


@override
SourceFileLoader.path_stats(path)¶
  importlib.abc.SourceLoader.path_stats().

@override
SourceFileLoader.set_data(path, data)¶
    importlib.abc.SourceLoader.set_data().

@override
Deprecated:SourceFileLoader.load_module(name=None)¶
  Use importlib.abc.Loader.exec_module() instead.


######################
class importlib.machinery.SourcelessFileLoader(FileLoader)¶
  A concrete implementation of importlib.abc.FileLoader which can import bytecode files (i.e. no source code files exist).
  Please note that direct use of bytecode files (and thus not source code files) inhibits your modules from being usable by all Python implementations or new versions of Python which change the bytecode format.

.SourcelessFileLoader(fullname, path)
    SourcelessFileLoader <: FileLoader

SourcelessFileLoader.name¶
  The name of the module the loader will handle.

SourcelessFileLoader.path¶
  The path to the bytecode file.

@override
SourcelessFileLoader.is_package(fullname)¶
  Determines if the module is a package based on path.

@override
SourcelessFileLoader.get_code(fullname)¶
  Returns the code object for name created from path.

@override
SourcelessFileLoader.get_source(fullname)->None
  Returns None as bytecode files have no source when this loader is used.

@override
Deprecated:SourcelessFileLoader.load_module(name=None)¶
  Use importlib.abc.Loader.exec_module() instead.




######################
class importlib.machinery.ExtensionFileLoader(ExecutionLoader)¶
  A concrete implementation of importlib.abc.ExecutionLoader for extension modules.

.ExtensionFileLoader(fullname, path)
  ExtensionFileLoader <: ExecutionLoader

ExtensionFileLoader.name¶
  Name of the module the loader supports.

ExtensionFileLoader.path¶
  Path to the extension module.

@override
ExtensionFileLoader.create_module(spec)¶
  Creates the module object from the given specification in accordance with PEP 489.

@override
ExtensionFileLoader.exec_module(module)¶
  Initializes the given module object in accordance with PEP 489.

@override
ExtensionFileLoader.is_package(fullname)¶
  Returns True if the file path points to a package’s __init__ module based on EXTENSION_SUFFIXES.
  ???'xxx.__init__.dll'->True???动态链接库也可以会包！

@override
ExtensionFileLoader.get_code(fullname)->None
  Returns None as extension modules lack a code object.

@override
ExtensionFileLoader.get_source(fullname)->None
  Returns None as extension modules do not have source code.

@override
ExtensionFileLoader.get_filename(fullname)->path
  ExecutionLoader.get_filename(fullname)->str/Path?|^ImportError




######################
######################
class importlib.machinery.ModuleSpec¶
  A specification for a module’s import-system-related state.
    This is typically exposed as the module’s __spec__ attribute.
  In the descriptions below, the names in parentheses give the corresponding attribute available directly on the module object.
    E.g. module.__spec__.origin == module.__file__.
    Note
      however that while the values are usually equivalent, they can differ since there is no synchronization between the two objects.
        Thus it is possible to update the module’s __path__ at runtime, and this will not be automatically reflected in __spec__.submodule_search_locations.



.ModuleSpec(name, loader, *, origin=None, loader_state=None, is_package=None)

[def____spec__ModuleSpec]
  [spec :: ModuleSpec]
  [def____module__attributes]#goto

ModuleSpec.loader_state¶
  Container of extra module-specific data for use during loading (or None).

ModuleSpec.has_location¶
  Boolean indicating whether or not the module’s “origin” attribute refers to a loadable location.

ModuleSpec.name¶
  (~=module_obj.__name__)
  A string for the fully-qualified name of the module.

ModuleSpec.loader¶
  (~=module_obj.__loader__)
  The loader to use for loading.
  For namespace packages this should be set to None.
    [def____is_pkg___is_ns_pkg]#goto

ModuleSpec.origin¶
  (~=module_obj.__file__)
  Name of the place from which the module is loaded
    , e.g. “builtin” for built-in modules
          and the filename for modules loaded from source.
  Normally “origin” should be set, but it may be None (the default)
    which indicates it is unspecified (e.g. for namespace packages).

ModuleSpec.submodule_search_locations¶
  (~=module_obj.__path__)
  List of strings for where to find submodules, if a package (None otherwise).
    [def____is_pkg___is_ns_pkg]#goto

ModuleSpec.cached¶
  (~=module_obj.__cached__)
  String for where the compiled module should be stored (or None).

ModuleSpec.parent¶
  (~=module_obj.__package__)
  (Read-only) Fully-qualified name of the package to which the module belongs as a submodule (or None).






######################
]]]
######################
######################
######################
######################













######################
===
_frozen_importlib_external.FileLoader(builtins.object)
    FileLoader(_frozen_importlib_external.FileLoader, ResourceLoader, ExecutionLoader)
===
_frozen_importlib_external.SourceLoader(_frozen_importlib_external._LoaderBasics)
    SourceLoader(_frozen_importlib_external.SourceLoader, ResourceLoader, ExecutionLoader)
===
builtins.object
    !Finder(过气，被子类替代)
        MetaPathFinder
        PathEntryFinder
    ResourceReader
        TraversableResources
===
importlib._abc.Loader(builtins.object)
    InspectLoader
        ExecutionLoader
    Deprecated:ResourceLoader
        FileLoader(_frozen_importlib_external.FileLoader, ResourceLoader, ExecutionLoader)
        SourceLoader(_frozen_importlib_external.SourceLoader, ResourceLoader, ExecutionLoader)
===
typing.Protocol(typing.Generic)
    Traversable
===

######################

]]
[[
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/unittest.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/unittest.html > $my_tmp/out4py/html2text/py_38_doc/unittest.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/unittest.html.txt
Command-Line Interface
python -m unittest test_module1 test_module2
python -m unittest test_module.TestClass
python -m unittest test_module.TestClass.test_method
python -m unittest tests/test_something.py
  # <==> python -m unittest tests.test_something
  # If you want to execute a test file that isn’t importable as a module you should execute the file directly instead.
  # 仅用于 利用 终端壳路径补全


Test Discovery
cd project_directory
python -m unittest discover
  <==> python -m unittest
  ???显然，用户不能有名为discover的模块

python -m unittest discover -s . -p 'test*.py' -t .
-s, --start-directory directory
    Directory to start discovery (. default)
-p, --pattern pattern
    Pattern to match test files (test*.py default)
-t, --top-level-directory directory
    Top level directory of project (defaults to start directory)



load_tests Protocol
If a test module defines load_tests it will be called by TestLoader.loadTestsFromModule() with the following arguments:
    load_tests(loader, standard_tests, pattern) -> TestSuite

def load_tests(loader, tests, pattern):
    suite = TestSuite()
    for test_class in test_cases:
        tests = loader.loadTestsFromTestCase(test_class)
        suite.addTests(tests)
    return suite
def load_tests(loader, standard_tests, pattern):
    # top level directory cached on loader instance
    this_dir = os.path.dirname(__file__)
    package_tests = loader.discover(start_dir=this_dir, pattern=pattern)
    standard_tests.addTests(package_tests)
    return standard_tests




]]
[[
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/doctest.html
mkdir $my_tmp/out4py/html2text/
mkdir $my_tmp/out4py/html2text/py_38_doc/
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/doctest.html > $my_tmp/out4py/html2text/py_38_doc/doctest.html.txt
view /sdcard/0my_files/tmp/out4py/html2text/py_38_doc/doctest.html.txt

example.py:
  ...
  if __name__ == "__main__":
      import doctest
      doctest.testmod()

python example.py
python example.py -v
python -m doctest -v example.py


example.txt:
    >>> from example import factorial
    ...

import doctest
doctest.testfile("example.txt")


显式指定搜索使用哪些__doc__
module.__test__ :: {name:(func|type|str)}
  ???module.__doc__
  func.__doc__
  type.__doc__
    recur:nested_type.__doc__


[没有测试单个指定对象文档字符串的选项
$ python -m doctest -h
usage: doctest.py [-h] [-v]
                  [-o {DONT_ACCEPT_TRUE_FOR_1,DONT_ACCEPT_BLANKLINE,NORMALIZE_WHITESPACE,ELLIPSIS,SKIP,IGNORE_EXCEPTION_DETAIL,REPORT_UDIFF,REPORT_CDIFF,REPORT_NDIFF,REPORT_ONLY_FIRST_FAILURE,FAIL_FAST}]
                  [-f]
                  file [file ...]

doctest runner
]


Basic API
doctest.testfile(filename, module_relative=True, name=None, package=None, globs=None, verbose=None, report=True, optionflags=0, extraglobs=None, raise_on_error=False, parser=DocTestParser(), encoding=None)
  #name并非对象名:Optional argument name gives the name of the test; by default, or if None, os.path.basename(filename) is used.
doctest.testmod(m=None, name=None, globs=None, verbose=None, report=True, optionflags=0, extraglobs=None, raise_on_error=False, exclude_empty=False)
  #name并非对象名:Optional argument name gives the name of the module; by default, or if None, m.__name__ is used.
doctest.run_docstring_examples(f, globs, verbose=False, name="NoName", compileflags=None, optionflags=0)¶
  #Test examples associated with object f; for example, f may be a string, a module, a function, or a class object.
  #name并非对象名:Optional argument name is used in failure messages, and defaults to "NoName".

Unittest API
import unittest
import doctest
import my_module_with_doctests

def load_tests(loader, tests, ignore):
    tests.addTests(doctest.DocTestSuite(my_module_with_doctests))
    return tests
      #能否拆成单对象？
doctest.DocFileSuite(*paths, module_relative=True, package=None, setUp=None, tearDown=None, globs=None, optionflags=0, parser=DocTestParser(), encoding=None)
doctest.DocTestSuite(module=None, globs=None, extraglobs=None, test_finder=None, setUp=None, tearDown=None, checker=None)
doctest.set_unittest_reportflags(flags)



Advanced API


]]

[[
view /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/bisect.html
html2text -i /sdcard/0my_files/unzip/py_doc/python-3.8.1-docs-html/library/bisect.html
bisect.bisect_left(a, x, lo=0, hi=len(a)) -> i
  all(val < x for val in a[lo:i])
  all(val >= x for val in a[i:hi])
bisect.bisect_right(a, x, lo=0, hi=len(a)) -> i
  all(val <= x for val in a[lo:i])
  all(val > x for val in a[i:hi])


view ../../python3_src/seed/seq_tools/bisearch.py
from seed.seq_tools.bisearch import bisearch
from bisect import bisect_left, bisect_right
    assert bisearch(x, array) == (bisect_left(array, x), bisect_right(array, x))
      #等价索引值范围的左右边界

bisect.insort_left(a, x, lo=0, hi=len(a))
  a.insert(bisect.bisect_left(a, x, lo, hi), x)
bisect.insort_right(a, x, lo=0, hi=len(a))
  a.insert(bisect.bisect_right(a, x, lo, hi), x)

]]

[[
generator_iterator
return ==>> StopIteration.value
g.send(yield_return)
next(it, default)

]]
[[
view ../../python3_src/seed/func_tools/recur5yield.py
    #generator_iterator 并没有保留 返回值
    #   返回值 在 StopIteration.value!!
def _get_return_value_of_null_generator_iterator(it0, /):
    try:
        next(it0)
    except StopIteration as exc:
        r = exc.value
    else:
        raise logic-err
    return r

def _t():
    def f():
        return 1; yield
    it = f()
    print(_get_return_value_of_null_generator_iterator(it))
        # => 1
    print(_get_return_value_of_null_generator_iterator(it))
        # => None
    #不可重复取值！

    def f():
        while 1:
            return 1
        yield
    it = f()
    print(_get_return_value_of_null_generator_iterator(it))
        # => 1
    print(_get_return_value_of_null_generator_iterator(it))
        # => None
    #不可重复取值！
]]
[[[

class collections.abc.Generator


generator

    A function which returns a generator iterator. It looks like a normal function except that it contains yield expressions for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function.

    Usually refers to a generator function, but may refer to a generator iterator in some contexts. In cases where the intended meaning isn’t clear, using the full terms avoids ambiguity.

generator iterator

    An object created by a generator function.

    Each yield temporarily suspends processing, remembering the location execution state (including local variables and pending try-statements). When the generator iterator resumes, it picks up where it left off (in contrast to functions which start fresh on every invocation).


file:///storage/72A2-151D/000edt/0my_files/unzip/py_doc/python-3.8.1-docs-html/reference/expressions.html#generator.send

When the underlying iterator is complete, the value attribute of the raised StopIteration instance becomes the value of the yield expression. It can be either set explicitly when raising StopIteration, or automatically when the subiterator is a generator (by returning a value from the subgenerator).

    Changed in version 3.3: Added yield from <expr> to delegate control flow to a subiterator.

6.2.9.1. Generator-iterator methods

This subsection describes the methods of a generator iterator. They can be used to control the execution of a generator function.

Note that calling any of the generator methods below when the generator is already executing raises a ValueError exception.

generator.__next__()

    Starts the execution of a generator function or resumes it at the last executed yield expression. When a generator function is resumed with a __next__() method, the current yield expression always evaluates to None. The execution then continues to the next yield expression, where the generator is suspended again, and the value of the expression_list is returned to __next__()’s caller. If the generator exits without yielding another value, a StopIteration exception is raised.

    This method is normally called implicitly, e.g. by a for loop, or by the built-in next() function.

generator.send(value)

    Resumes the execution and “sends” a value into the generator function. The value argument becomes the result of the current yield expression. The send() method returns the next value yielded by the generator, or raises StopIteration if the generator exits without yielding another value. When send() is called to start the generator, it must be called with None as the argument, because there is no yield expression that could receive the value.

generator.throw(type[, value[, traceback]])

    Raises an exception of type type at the point where the generator was paused, and returns the next value yielded by the generator function. If the generator exits without yielding another value, a StopIteration exception is raised. If the generator function does not catch the passed-in exception, or raises a different exception, then that exception propagates to the caller.

generator.close()

    Raises a GeneratorExit at the point where the generator function was paused. If the generator function then exits gracefully, is already closed, or raises GeneratorExit (by not catching the exception), close returns to its caller. If the generator yields a value, a RuntimeError is raised. If the generator raises any other exception, it is propagated to the caller. close() does nothing if the generator has already exited due to an exception or normal exit.

]]]

[[str__bytes__float__int
help(str.isspace)
help(bytes.isspace)
isspace(...)
    B.isspace() -> bool

    Return True if all characters in B are whitespace and there is at least one character in B, False otherwise.

help(bytes.split)
split(self, /, sep=None, maxsplit=-1)
    Return a list of the sections in the bytes, using sep as the delimiter.

    sep
        The delimiter according which to split the bytes.
        None (the default value) means split on ASCII whitespace characters (space, tab, return, newline, formfeed, vertical tab).
    maxsplit
        Maximum number of splits to do.
        -1 (the default value) means no limit.

help(bytes.replace)
replace(self, old, new, count=-1, /)
    Return a copy with all occurrences of substring old replaced by new.

      count
        Maximum number of occurrences to replace.
        -1 (the default value) means replace all occurrences.

    If the optional argument count is given, only the first count occurrences are replaced.


help(bytes.translate)
translate(self, table, /, delete=b'')
    :: old2new/bytes{len=256} -> (delete=b'') -> bytes
    Return a copy with each character mapped by the given translation table.

      table
        Translation table, which must be a bytes object of length 256.

    All characters occurring in the optional argument delete are removed.
    The remaining characters are mapped through the given translation table.


help(bytes.maketrans)
maketrans(frm, to, /)
    :: olds/bytes -> news/bytes{.len=len(olds)} -> old2new/bytes{len=256}
    Return a translation table useable for the bytes or bytearray translate method.

    The returned table will be one where each byte in frm is mapped to the byte at the same position in to.

    The bytes objects frm and to must be of the same length.


help(str.translate)
translate(self, table, /)
    :: old2new/(Map uint (may uint)) -> str
    Replace each character in the string using the given translation table.

    table
        Translation table, which must be a mapping of Unicode ordinals to Unicode ordinals, strings, or None.

    The table must implement lookup/indexing via _ _getitem__, for instance a dictionary or list.
        If this operation raises LookupError, the character is left untouched.
        Characters mapped to None are deleted.


help(str.maketrans)
maketrans(...)
    :: Map (uint|char) (None|uint|str) -> old2new/(Map uint (may uint))
    :: olds/str -> news/str{.len=len(olds)} -> (dels/str='') -> old2new/(Map uint (may uint))
    Return a translation table usable for str.translate().

    If there is only one argument, it must be a dictionary mapping Unicode ordinals (integers) or characters to Unicode ordinals, strings or None.
      Character keys will be then converted to ordinals.
    If there are two arguments, they must be strings of equal length, and in the resulting dictionary, each character in x will be mapped to the character at the same position in y.
    If there is a third argument, it must be a string, whose characters will be mapped to None in the result.



help(memoryview.hex)
help(bytes.hex)
hex(...)
    Create a string of hexadecimal numbers from a
bytes object.                                                                                             sep
        An optional single character or byte to separate hex bytes.
    bytes_per_sep
        How many bytes between separators.  Positive values count from the right, negative values count from the left.

    Example:
    >>> value = b'\xb9\x01\xef'
    >>> value.hex()
    'b901ef'
    >>> value.hex(':')
    'b9:01:ef'
    >>> value.hex(':', 2)
    'b9:01ef'
    >>> value.hex(':', -2)
    'b901:ef'

help(bytes.fromhex)
fromhex(string, /)
    Create a bytes object from a string of hexadecimal numbers.

    Spaces between two numbers are accepted.
    Example: bytes.fromhex('B9 01EF') -> b'\\xb9\\x01\\xef'.

help(float.hex)
hex(self, /)
    Return a hexadecimal representation of a floating-point number.
                                      >>> (-0.1).hex()
    '-0x1.999999999999ap-4'
    >>> 3.14159.hex()
    '0x1.921f9f01b866ep+1'

help(float.fromhex)
fromhex(string, /)
    Create a floating-point number from a hexadecimal string.

    >>> float.fromhex('0x1.ffffp10')
    2047.984375
    >>> float.fromhex('-0x1p-1074')
    -5e-324

_int2hex_ :: int->hex
  '{:X}'.format(i)
  f'{i:X}'
_int5hex_ :: hex->int
  int(hex_str, 16)
  literal_eval('0x'+hex_str)

help(memoryview)
  with memoryview(xxx) as bs:
    ...
help(int.from_bytes)
from_bytes(bytes, byteorder, *, signed=False)
    # bs :: memoryview_able|Iter memoryview_able
    # byteorder <- {'big', 'little', sys.byteorder}
    Return the integer represented by the given array of bytes.

    bytes
      Holds the array of bytes to convert.  The argument must either support the buffer protocol or be an iterable object producing bytes.
      Bytes and bytearray are examples of built-in objects that support the buffer protocol.

    byteorder
      The byte order used to represent the integer.
      If byteorder is 'big', the most significant byte is at the beginning of the byte array.
      If byteorder is 'little', the most significant byte is at the end of the byte array.
      To request the native byte order of the host system, use `sys.byteorder' as the byte order value.

    signed
      Indicates whether two's complement is used to represent the integer.


help(int.to_bytes)
to_bytes(self, /, length, byteorder, *, signed=False)
    Return an array of bytes representing an integer.

    length
      Length of bytes object to use.
      An OverflowError is raised if the integer is not representable with the given number of bytes.

    byteorder
      见上面『help(int.from_bytes)』

    signed
      Determines whether two's complement is used to represent the integer.
      If signed is False and a negative integer is given, an OverflowError is raised.


]]

from collections import deque
#deque([iterable[, maxlen]]) --> deque object

[[
from functools import reduce
reduce(function, iterable[, initial]) -> value

import functools
functools.__all__
['update_wrapper', 'wraps', 'WRAPPER_ASSIGNMENTS', 'WRAPPER_UPDATES', 'total_ordering', 'cache', 'cmp_to_key', 'lru_cache', 'reduce', 'partial', 'partialmethod', 'singledispatch', 'singledispatchmethod', 'cached_property']
help(functools)

py_help functools > ~/my_tmp/out4py/py_help.functools.out.txt
view /sdcard/0my_files/tmp/out4py/py_help.functools.out.txt


wraps(wrapped, ...)(wrapper)
  <==> update_wrapper(wrapper, wrapped, ...)
  i.e. wraps() is 『decorator factory』
  def decorator_xxx(f, /):
      @wraps(f)
      def f(...):...
      return f
  @decorator_xxx
  def f(...):...



cache(user_function, /)
    Simple lightweight unbounded cache.  Sometimes called "memoize".

cmp_to_key(...)
    Convert a cmp= function into a key= function.

lru_cache(maxsize=128, typed=False)
    Least-recently-used cache decorator.
    
    If *maxsize* is set to None, the LRU features are disabled and the cache can grow without bound.
    
    If *typed* is True, arguments of different types will be cached separately.
    For example, f(3.0) and f(3) will be treated as distinct calls with distinct results.
    
    Arguments to the cached function must be hashable.
    
    View the cache statistics named tuple (hits, misses, maxsize, currsize) with f.cache_info().  Clear the cache and statistics with f.cache_clear().
    Access the underlying function with f.__wrapped__.

reduce(...)
    reduce(function, iterable[, initial]) -> value
    
    Apply a function of two arguments cumulatively to the items of a sequence or iterable, from left to right, so as to reduce the iterable to a single value.
    For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates ((((1+2)+3)+4)+5).
    If initial is present, it is placed before the items of the iterable in the calculation, and serves as a default when the iterable is empty.

singledispatch(func)
    Single-dispatch generic function decorator.
    
    Transforms a function into a generic function, which can have different
    behaviours depending upon the type of its first argument. The decorated
    function acts as the default implementation, and additional
    implementations can be registered using the register() attribute of the
    generic function.

total_ordering(cls)
    Class decorator that fills in missing ordering methods


]]


[[
from itertools import accumulate
accumulate(iterable, func=None, *, initial=None)

NAME
  itertools - Functional tools for creating and using iterators.

DESCRIPTION
  Infinite iterators:
    count(start=0, step=1) --> start, start+step, start+2*step, ...
    cycle(p) --> p0, p1, ... plast, p0, p1, ...
    repeat(elem [,n]) --> elem, elem, elem, ... endlessly or up to n times

  Iterators terminating on the shortest input sequence:
    accumulate(p[, func]) --> p0, p0+p1, p0+p1+p2
    chain(p, q, ...) --> p0, p1, ... plast, q0, q1, ...
    chain.from_iterable([p, q, ...]) --> p0, p1, ... plast, q0, q1, ...
    compress(data, selectors) --> (d[0] if s[0]), (d[1] if s[1]), ...
    dropwhile(pred, seq) --> seq[n], seq[n+1], starting when pred fails
    groupby(iterable[, keyfunc]) --> sub-iterators grouped by value of keyfunc(v)
    filterfalse(pred, seq) --> elements of seq where pred(elem) is False
    islice(seq, [start,] stop [, step]) --> elements from seq[start:stop:step]
    pairwise(s) --> (s[0],s[1]), (s[1],s[2]), (s[2], s[3]), ...
    starmap(fun, seq) --> fun(*seq[0]), fun(*seq[1]), ...
    tee(it, n=2) --> (it1, it2 , ... itn) splits one iterator into n
    takewhile(pred, seq) --> seq[0], seq[1], until pred fails
    zip_longest(p, q, ...) --> (p[0], q[0]), (p[1], q[1]), ...

  Combinatoric generators:
    product(p, q, ... [repeat=1]) --> cartesian product
    permutations(p[, r])
    combinations(p, r)
    combinations_with_replacement(p, r)

===
]
>>> [(k, [*it]) for (k,it) in groupby([1,1,2,3,3])]
[(1, [1, 1]), (2, [2]), (3, [3, 3])]
>>> [*combinations([1,2,3,4], 2)]
[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]



]]
