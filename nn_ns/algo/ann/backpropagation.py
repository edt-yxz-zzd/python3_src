
import math, random


def sigmoid(x):
    if x < 0:
        return math.exp(x) / (1+math.exp(x))
                
    return 1.0 / (1+math.exp(-x))
def 向量点积(u, v):
    return sum(a*b for a, b in zip(u,v))
def 求单层输出(本层权值, 输入):
    单层输出 = []
    for 下一层某结点的输入权值 in 本层权值:
        输出 = 向量点积(下一层某结点的输入权值[:-1], 输入) + 下一层某结点的输入权值[-1]
        输出 = sigmoid(输出)
        单层输出.append(输出)
        
    return 单层输出
def 求各结点输出(各权值, 输入):
    各结点输出 = [输入]
    for 本层权值 in 各权值:
        输出 = 求单层输出(本层权值, 输入)
        各结点输出.append(输出)
        
        输入 = 输出
    return 各结点输出

def 求末层结点误差(目标输出, 末层输出):
    末层结点误差 = []
    for 本结点目标输出, 本结点输出 in zip(目标输出, 末层输出):
        本结点误差项 = 本结点输出 * (1-本结点输出) * (本结点目标输出 - 本结点输出)
        末层结点误差.append(本结点误差项)
    return 末层结点误差

def 求隐藏结点误差(各结点误差, 各结点输出, 各权值):
    L = len(各结点误差)
    for 本层序号 in range(L-2, 0, -1):
        本层输出 = 各结点输出[本层序号]
        本层权值 = 各权值[本层序号]
        下一层误差 = 各结点误差[本层序号+1]
        本层误差 = 各结点误差[本层序号]
        for 本结点序号 in range(len(本层输出)):
            本结点输出 = 本层输出[本结点序号]
            本结点输出权值 = [下一层某结点输入权值[本结点序号] for 下一层某结点输入权值 in 本层权值]
            本结点误差 = 本结点输出 * (1-本结点输出) * 向量点积(本结点输出权值, 下一层误差)

            本层误差[本结点序号] = 本结点误差

    return

def 更新各权值(各权值, 各结点误差, 各结点输出, 学习速率, 权冲量, 各权值上一次改变量):
    L = len(各权值)
    for 本层序号 in range(L):
        本层输出 = 各结点输出[本层序号]
        本层权值 = 各权值[本层序号]
        本层各权值上一次改变量 = 各权值上一次改变量[本层序号]
        下一层误差 = 各结点误差[本层序号+1]
        assert len(本层权值[0]) == len(本层输出) + 1
        for 下一层结点序号 in range(len(本层权值)):
            k = 学习速率*下一层误差[下一层结点序号]
            #print(k, 本层权值[下一层结点序号])
            for 本结点序号 in range(len(本层权值[0])):
                if 本结点序号 < len(本层输出):
                    本结点输出 = 本层输出[本结点序号]
                else:
                    本结点输出 = 1.0
                本权值输入 = 本结点输出
                本权值上一次改变量 = 本层各权值上一次改变量[下一层结点序号][本结点序号]
                本权值改变量 = k*本权值输入 + 权冲量*本权值上一次改变量
                
                本层权值[下一层结点序号][本结点序号] += 本权值改变量
                
                本层各权值上一次改变量[下一层结点序号][本结点序号] = 本权值改变量
            #print('         ', 本层权值[下一层结点序号])
                
def 样例训练(各权值, 各结点误差, 学习速率, 样例, 权冲量, 各权值上一次改变量):
    输入, 目标输出 = 样例
    各结点输出 = 求各结点输出(各权值, 输入)
    #print('各权值', 各权值)
    #print('各结点输出', 各结点输出)

    末层输出 = 各结点输出[-1]
    各结点误差[-1] = 求末层结点误差(目标输出, 末层输出)

    求隐藏结点误差(各结点误差, 各结点输出, 各权值)
    #print('各结点误差', 各结点误差)

    更新各权值(各权值, 各结点误差, 各结点输出, 学习速率, 权冲量, 各权值上一次改变量)

    更新前各结点输出 = 各结点输出
    return 更新前各结点输出

def 初始化权值(各层结点数, 权值初始化函数):
    各权值 = []
    for L in range(len(各层结点数) - 1):
        本层权值 = []
        各权值.append(本层权值)
        for out in range(各层结点数[L+1]):
            本结点的输入权值 = [权值初始化函数(out, i) for i in range(各层结点数[L]+1)]
            本层权值.append(本结点的输入权值)
    return 各权值


    
def 反向传播算法(训练集, 各层结点数,
           学习速率=0.3, 终止误差=0.1,
           最大训练次数=2000, 权冲量=0,
           权值初始化函数 = lambda i,j:random.uniform(-0.1, 0.1),
           各权值 = None):
    # 初始化 权值
    if 各权值 == None:
        各权值 = 初始化权值(各层结点数, 权值初始化函数)
    
    各权值上一次改变量 = [[[0]*(各层结点数[L]+1) for out in range(各层结点数[L+1])] for L in range(len(各层结点数) - 1)]
    
    # 初始化 各层结点误差 储存空间
    各结点误差 = [[None]*本层结点数 for 本层结点数 in 各层结点数]

    try:
        训练次数 = 0
        for 训练次数 in range(最大训练次数):
            stop = True
            for 输入, 目标输出 in 训练集:
                assert len(输入) == 各层结点数[0]
                assert len(目标输出) == 各层结点数[-1]

                更新前各结点输出 = 样例训练(各权值, 各结点误差, 学习速率, (输入, 目标输出), 权冲量, 各权值上一次改变量)
                #print(各权值)

                if stop:
                    更新前末层结点输出 = 更新前各结点输出[-1]
                    for 某末层结点输出, 目标 in zip(更新前末层结点输出, 目标输出):
                        if abs(某末层结点输出-目标) >= 终止误差:
                            stop = False
                            break
            if stop:
                break
    except:
        print('训练次数', 训练次数)
        raise


    return {'各权值':各权值, '训练次数':训练次数}


def _set_ith(i, n):
    ls = [0]*n
    ls[i] = 1
    return ls
测试隐藏层编码 = {
    '各层结点数':(8, 3, 8),
    '训练集':tuple((_set_ith(i, 8), _set_ith(i, 8)) for i in range(8))
    }
测试隐藏层编码能否表示 = {
    '各层结点数':(8, 1, 8),
    '训练集':tuple((_set_ith(i, 8), _set_ith(i, 8)) for i in range(8))
    }

测试_与 = {
    '各层结点数':(2, 1),
    '训练集':(
        [(0,0),[0]],
        [(0,1),[0]],
        [(1,0),[0]],
        [(1,1),[1]])
    }
测试未确定泛化 = {
    '各层结点数':(2, 1, 1),
    '训练集':(
        [(0,1),[0]],
        [(1,0),[1]],
        ),
    '权冲量': .9, 
    '权值初始化函数': (lambda i,j: 0.1),
    '学习速率': .3
    }


def test(数据, n=None):
    if n:
        return 反向传播算法(最大训练次数=n, **数据)
    return 反向传播算法(**数据)

def test_测试隐藏层编码(数据 = 测试隐藏层编码, n=5000):
    #数据 = 测试隐藏层编码
    r = 反向传播算法(最大训练次数=n, **数据)
    各权值 = r['各权值']
    训练次数 = r['训练次数']
    print('训练次数', 训练次数)
    print('各权值', 各权值)
    for 输入, 目标输出 in 数据['训练集']:
        各结点输出 = 求各结点输出(各权值, 输入)
        print(各结点输出)
    return
def test_测试隐藏层编码能否表示():
    test_测试隐藏层编码(测试隐藏层编码能否表示, 10000)

    
def test_测试_与():
    r = test(测试_与, 10000)
    print(r)

def test_测试未确定泛化():
    r = test(测试未确定泛化, 10000)
    print(r)

t = test_测试隐藏层编码
#t()











